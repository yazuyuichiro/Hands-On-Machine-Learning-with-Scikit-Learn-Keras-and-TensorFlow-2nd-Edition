{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KerasのSequential APIを使ったニューラルネットワークの構築例をまとめる。<br>\n",
    "分類問題と回帰問題の例をそれぞれ1モデル作成する。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類問題：Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fashion MNISTはファッション商品（写真）の画像データセットである。\n",
    "* ラベル「0」： T-shirt/top（Tシャツ／トップス）\n",
    "* ラベル「1」： Trouser（ズボン）\n",
    "* ラベル「2」： Pullover（プルオーバー、頭から被って着る服）\n",
    "* ラベル「3」： Dress（ドレス）\n",
    "* ラベル「4」： Coat（コート）\n",
    "* ラベル「5」： Sandal（サンダル）\n",
    "* ラベル「6」： Shirt（シャツ）\n",
    "* ラベル「7」： Sneaker（スニーカー）\n",
    "* ラベル「8」： Bag（バッグ）\n",
    "* ラベル「9」： Ankle boot（アンクルブーツ、かかとが隠れる丈のブーツ）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パッケージインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow ver.2.8.0\n",
      "keras ver.2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(f'tensorflow ver.{tf.__version__}')\n",
    "print(f'keras ver.{keras.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データロード及び前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_full, y_train_full), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape : (55000, 28, 28)\n",
      "y_train.shape : (55000,)\n",
      "x_valid.shape : (5000, 28, 28)\n",
      "y_valid.shape : (5000,)\n"
     ]
    }
   ],
   "source": [
    "valid_size = 5000\n",
    "x_valid, x_train = x_train_full[:valid_size], x_train_full[valid_size:]\n",
    "y_valid, y_train = y_train_full[:valid_size], y_train_full[valid_size:]\n",
    "\n",
    "print(f'x_train.shape : {x_train.shape}')\n",
    "print(f'y_train.shape : {y_train.shape}')\n",
    "print(f'x_valid.shape : {x_valid.shape}')\n",
    "print(f'y_valid.shape : {y_valid.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スケーリング0~255を0~1に変換する\n",
    "x_valid, x_train = x_valid/225.0, x_train/225.0\n",
    "\n",
    "# クラス名を定義（データ加工ではないが準備作業としてこちらに記載)\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "# サンプルで1枚目のクラウス名を出力\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### レイヤ構成を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequentialモデル生成\n",
    "model = keras.models.Sequential()\n",
    "# 平滑化層\n",
    "model.add(keras.layers.Flatten(input_shape=x_train.shape[1:]))\n",
    "# 全結合層\n",
    "model.add(keras.layers.Dense(units=300, activation='relu'))\n",
    "# 全結合層\n",
    "model.add(keras.layers.Dense(units=100, activation='relu'))\n",
    "# 全結合層（出力層）\n",
    "model.add(keras.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "# レイヤ構成を表示\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ※モデルの直接操作することもできる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レイヤを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.flatten.Flatten at 0x7fa634adacd0>,\n",
       " <keras.layers.core.dense.Dense at 0x7fa632dadf70>,\n",
       " <keras.layers.core.dense.Dense at 0x7fa616f2e490>,\n",
       " <keras.layers.core.dense.Dense at 0x7fa60bae3310>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第1中間レイヤのパラメータを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04944597  0.07349831  0.01990774 ...  0.02750799 -0.03978248\n",
      "   0.06560838]\n",
      " [-0.07312918  0.06113352  0.0139228  ...  0.06875364  0.0067235\n",
      "   0.03491949]\n",
      " [ 0.01352143  0.04283768  0.00900155 ... -0.05407209  0.02654656\n",
      "  -0.02947026]\n",
      " [ 0.06204033 -0.07152744 -0.01059729 ... -0.00289328  0.01441121\n",
      "   0.06374431]\n",
      " [ 0.04045644 -0.03840212  0.00438145 ... -0.02346853 -0.0705626\n",
      "  -0.0361634 ]]\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "hidden_1_weights, hidden_1_biases = model.layers[1].get_weights()\n",
    "print(hidden_1_weights[:5])\n",
    "print(hidden_1_biases[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第1中間レイヤのパラメータを設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 重みとバイアスをすべて1に設定\n",
    "model.layers[1].set_weights([np.ones_like(model.layers[1].get_weights()[0]), np.ones_like(model.layers[1].get_weights()[1])])\n",
    "print(model.layers[1].get_weights()[0][:5])\n",
    "print(model.layers[1].get_weights()[1][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04944597  0.07349831  0.01990774 ...  0.02750799 -0.03978248\n",
      "   0.06560838]\n",
      " [-0.07312918  0.06113352  0.0139228  ...  0.06875364  0.0067235\n",
      "   0.03491949]\n",
      " [ 0.01352143  0.04283768  0.00900155 ... -0.05407209  0.02654656\n",
      "  -0.02947026]\n",
      " [ 0.06204033 -0.07152744 -0.01059729 ... -0.00289328  0.01441121\n",
      "   0.06374431]\n",
      " [ 0.04045644 -0.03840212  0.00438145 ... -0.02346853 -0.0705626\n",
      "  -0.0361634 ]]\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 重みとバイアスを元に戻す\n",
    "model.layers[1].set_weights([hidden_1_weights, hidden_1_biases])\n",
    "print(model.layers[1].get_weights()[0][:5])\n",
    "print(model.layers[1].get_weights()[1][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルのコンパイル\n",
    "モデルの学習プロセスを設定する。<br>\n",
    "ここで損失関数、オプティマイザ、評価関数を指定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [損失関数](https://keras.io/api/losses/)\n",
    "こちらも参考：[tf.keras.losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses)\n",
    "\n",
    "|分類|キー|損失関数名|説明|\n",
    "|-|-|-|-|\n",
    "|確率的<br>損失関数|binary_crossentropy|2値交差エントロピー|2値分類問題で使用|\n",
    "||categorical_crossentropy|カテゴリカル交差エントロピー|多クラス分類問題で使用。使用する場合はラベルがone-hot表現である必要がある。|\n",
    "||sparse_categorical_crossentropy|スパースカテゴリカル交差エントロピー|多クラス分類問題で使用。基本はカテゴリカル交差エントロピーと同じだが、スパースな？ラベルを取る点が異なる。使用するにはラベルと出力の次元が同じである必要がある。|\n",
    "||KLdivergence|KLダイバージェンス|予測した確率分布と真の確率分布との分布の距離|\n",
    "||poisson|ピアソン損失|予測値-正解値*log(予測値)の平均|\n",
    "|回帰損失関数|mean_squared_error|平均二乗誤差|2点間の距離の平均。スケールが2乗になる。|\n",
    "||mean_absolute_error|平均絶対誤差|差の絶対値の平均|\n",
    "||mean_absolute_percentage_error|平均絶対パーセント誤差|パーセント誤差（=(予測値-正解値)/正解値）の絶対値の平均。正解に対して何パーセント誤差があるかを測る指標として用いる。|\n",
    "||mean_squared_logarithmic_error|平均二乗対数誤差|予測値と正解値の対数の平均二乗誤差。対数の引き算は割り算に変換できるため、予測値/正解値を測る指標と解釈できる。|\n",
    "||logcosh|||\n",
    "||cosine_similarity|||\n",
    "||huber|||\n",
    "|最大マージンの<br>ヒンジ損失関数|hinge|||\n",
    "||squared_hinge|||\n",
    "||categorical_hinge|||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [オプティマイザ](https://keras.io/ja/losses/)\n",
    "こちらも参考：[tf.keras.optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)\n",
    "\n",
    "|オプティマイザ|説明|\n",
    "|-|-|\n",
    "|SGD|確率的勾配降下法。モーメンタム，学習率減衰，Nesterov momentumをサポートしている。|\n",
    "|RMSprop|RNNと好相性らしい。|\n",
    "|Adagrad||\n",
    "|Adadelta||\n",
    "|Adam|RMSPropとmomumtumを組み合わせたもの。|\n",
    "|Adamax|無限ノルムに基づく拡張版Adamらしい。|\n",
    "|Nadam|RMSPropとNesterov momentumを組み合わせたもの。|\n",
    "|Ftrl||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [評価関数](https://keras.io/api/metrics/)\n",
    "こちらも参考：[tf.keras.metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)\n",
    "\n",
    "|分類|クラス名|説明|\n",
    "|-|-|-|\n",
    "|正解率|Accuracy||\n",
    "||BinaryAccuracy||\n",
    "||CategoricalAccuracy||\n",
    "||SparseCategoricalAccuracy||\n",
    "||TopKCategoricalAccuracy||\n",
    "||SparseTopKCategoricalAccuracy||\n",
    "|確率|BinaryCrossentropy||\n",
    "||CategoricalCrossentropy||\n",
    "||SparseCategoricalCrossentropy||\n",
    "||KLDivergence||\n",
    "||Poisson||\n",
    "|回帰|MeanSquaredError||\n",
    "||RootMeanSquaredError||\n",
    "||MeanAbsoluteError||\n",
    "||MeanAbsolutePercentageError||\n",
    "||MeanSquaredLogarithmicError||\n",
    "||CosineSimilarity||\n",
    "||LogCoshError||\n",
    "|正誤問題に基づく分類|AUC||\n",
    "||Precision||\n",
    "||Recall||\n",
    "||TruePositives||\n",
    "||TrueNegatives||\n",
    "||FalsePositives||\n",
    "||FalseNegatives||\n",
    "||PrecisionAtRecall||\n",
    "||SensitivityAtSpecificity||\n",
    "||SpecificityAtSensitivity||\n",
    "|画像セグメンテーション|MeanIoU||\n",
    "|最大マージンのヒンジ分類|Hinge||\n",
    "||SquaredHinge||\n",
    "||CategoricalHinge||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習と評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コールバックによる学習中のチェックポイント保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コールバックは訓練中で適用される関数の集合である。\n",
    "訓練中にモデル内部の状態と統計量を可視化するためにコールバックを使う。\n",
    "\n",
    "SequentialとModelクラスの.fit()メソッドに（キーワード引数callbacksとして）コールバックのリストを渡すことができる。<br>\n",
    "これを使って学習中のチェックポイントを保存することが出来る。\n",
    "\n",
    "大規模データや層が深いモデルを扱うときには学習に時間がかかるため、google colabなどクラウド実行時にセッションが切れてしまうような場合にこのような設定が有効である。\n",
    "\n",
    "今回はsave_best_only=Trueとしてvalidationに対して性能が最高のモデルの時に保存する（早期打ち切り）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各エポック終了時のモデルを保存するコールバック関数\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_sequential_classification_model.h5', save_best_only=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6942 - accuracy: 0.7713 - val_loss: 0.5054 - val_accuracy: 0.8252\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4804 - accuracy: 0.8316 - val_loss: 0.4870 - val_accuracy: 0.8314\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4358 - accuracy: 0.8471 - val_loss: 0.4187 - val_accuracy: 0.8506\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4093 - accuracy: 0.8555 - val_loss: 0.3867 - val_accuracy: 0.8674\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3886 - accuracy: 0.8618 - val_loss: 0.4725 - val_accuracy: 0.8228\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3727 - accuracy: 0.8678 - val_loss: 0.3809 - val_accuracy: 0.8690\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3596 - accuracy: 0.8717 - val_loss: 0.3760 - val_accuracy: 0.8720\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3473 - accuracy: 0.8766 - val_loss: 0.3674 - val_accuracy: 0.8660\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3385 - accuracy: 0.8798 - val_loss: 0.3494 - val_accuracy: 0.8792\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3291 - accuracy: 0.8829 - val_loss: 0.3390 - val_accuracy: 0.8814\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3205 - accuracy: 0.8846 - val_loss: 0.3407 - val_accuracy: 0.8820\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3131 - accuracy: 0.8866 - val_loss: 0.3275 - val_accuracy: 0.8838\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3049 - accuracy: 0.8906 - val_loss: 0.3314 - val_accuracy: 0.8808\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2986 - accuracy: 0.8920 - val_loss: 0.3241 - val_accuracy: 0.8846\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2921 - accuracy: 0.8951 - val_loss: 0.3372 - val_accuracy: 0.8796\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2856 - accuracy: 0.8969 - val_loss: 0.3228 - val_accuracy: 0.8846\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2805 - accuracy: 0.8990 - val_loss: 0.3127 - val_accuracy: 0.8870\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2747 - accuracy: 0.9001 - val_loss: 0.3281 - val_accuracy: 0.8836\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2692 - accuracy: 0.9032 - val_loss: 0.3155 - val_accuracy: 0.8896\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2639 - accuracy: 0.9049 - val_loss: 0.3116 - val_accuracy: 0.8880\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2589 - accuracy: 0.9065 - val_loss: 0.3045 - val_accuracy: 0.8898\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2545 - accuracy: 0.9084 - val_loss: 0.3004 - val_accuracy: 0.8944\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2499 - accuracy: 0.9102 - val_loss: 0.3157 - val_accuracy: 0.8892\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2458 - accuracy: 0.9106 - val_loss: 0.2974 - val_accuracy: 0.8954\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2406 - accuracy: 0.9140 - val_loss: 0.3130 - val_accuracy: 0.8876\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2376 - accuracy: 0.9138 - val_loss: 0.2960 - val_accuracy: 0.8948\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2334 - accuracy: 0.9166 - val_loss: 0.2900 - val_accuracy: 0.8946\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2289 - accuracy: 0.9166 - val_loss: 0.2944 - val_accuracy: 0.8974\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2252 - accuracy: 0.9193 - val_loss: 0.2954 - val_accuracy: 0.8942\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2214 - accuracy: 0.9205 - val_loss: 0.3028 - val_accuracy: 0.8944\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=30, validation_data=(x_valid, y_valid), callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABQNElEQVR4nO3dd5xU1f3/8deZvnW294VdkN5lAUWliEEUu8byNRYSNaZooonRFI2/aBKjUb9JNBpjT/RrjEZjFBUsC8FGUZAmiEvZ3ttsmXp+f9zZ2cIs7MLCLLuf5+NxH7fMnTtnjiPvPfeee67SWiOEEEKIyDFFugBCCCHEcCdhLIQQQkSYhLEQQggRYRLGQgghRIRJGAshhBARJmEshBBCRNhBw1gp9aRSqkoptaWX15VS6o9KqV1Kqc+VUscPfDGFEEKIoasvLeOngSUHeP0MYExwug545PCLJYQQQgwfBw1jrfVqoO4Au5wLPKsNHwMJSqnMgSqgEEIIMdQNxDXjbKC4y3pJcJsQQggh+sAyAMdQYbaFHWNTKXUdxqlsoqKiZubm5g7AxxsCgQAmk/RH60nqJTypl/CkXsKTeglP6iW8A9XLzp07a7TWqT23D0QYlwBdUzUHKAu3o9b6MeAxgIKCAr1+/foB+HhDYWEhCxYsGLDjDRVSL+FJvYQn9RKe1Et4Ui/hHahelFJ7w20fiD9pXgOuDPaqPgFo1FqXD8BxhRBCiGHhoC1jpdT/AQuAFKVUCfBLwAqgtX4UWA6cCewCWoFlR6qwQgghxFB00DDWWl92kNc18L0BK5EQQggxzMiVdyGEECLCJIyFEEKICJMwFkIIISJMwlgIIYSIMAljIYQQIsIkjIUQQogIkzAWQgghIkzCWAghhIgwCWMhhBAiwiSMhRBCiAiTMBZCCCEiTMJYCCGEiDAJYyGEECLCJIyFEEKICJMwFkIIISLsoM8zFkIIIYa0gB/8HvC5we8Fv9tY93sheQyYjny7VcJYCCHE0aE1eFvB0wro/r8/4AO3CzzNwbnrAOtdtnlag+EaDNtQ6Aa36UDvn3lbMTjiD/kr95WEsRBCDBeBALiboL0B2ho65x5XcAcFSh1gTrf11KotsGFvMPg6pqYe683BkAxuP1DwHTYF9jiwxYI9tnMelQQWO5htxmSxdS4fbJvFfgTL20nCWAghjhatwdcO3rbOedfl0DzYWtMBQHcud5t0cOqyze+B9sb9w7Zj7m4a0DCcBLCtywZbrBGGXae4dLDHd99mje4M9/5QJrDFdQ9ae3zn8qEedxCQMBZCDE+BgHGK0tduhF/Xube923pa5WdGCzBskLYF9w+uh5a7bgu+x9d+5L+X2QaOBIhKMOaxaZAytnO929xpLNtjAYUR/LrLnB7r3edr169n9smndrZGTeYj//2GKAljIcTg5HNDe5PR0nM3dlkOnu7saEH6gvOugRcK03DrwcD1e/pclIkA23tsNNvAEgXWKLA6gssOo3XmSIC4KLA4urwWnCyO7nNrVOd7Q3OH0QoMTarHei+vmSzB9x6d1mFrTBU4c47KZw11EsZCiL7xe8HTYnTA8bZ1LntaOsPN7zPmAW+wg4w3zHJwv4DXeJ+7OXhqtSl4PTO47Hf3oVAqGGZ2I8gs9s6gsziMFltMamfwmW1d9nf0YW4sf/LpJubMnW8EbUdYSitQDCAJYyGGgkDA6EHa0Xr0uIKh2fOUadd5z+uU7UytKoOv7EbvU29rZ89Xb4vRk/VwmSxgsgY7yFjAbDd6qtrjIToJkvKN5Y5tDqcxhZbjO68/WqPBbD0qrcC26FpIyO3Xe7TWaK8Xk812hEoV/JxAAF91Nd7SMgLNTVhzcrDl5qKO8Of6XS2YKypwFxVhdOgCpYIdvbpOqOCsy7ZAgEBLC36Xi4CrhUCLi4DL1bnuchFo6bHucqE9HkxxcZjj4zDFxWOKi8UcFx9aN+ZxmOPjQ3NzXBwqOhqlFDp0nb37pCH8dg2mGOO9R5qEsRBHQ8AfvJ3CDT5Pj7m7yz2Onu77+dqDrcUup2jDtSLdTfTrVhFlCnNqNAqz3wMWp9H71BZtBJ4tJng6NSa4retyxxTVpRdqz8C1BdePTnAeSdrvx9/QgK+mFn9tDb7aWny1tfhra/HV1OKrrcFfY2zz1dWB14spLg5LWhqWtFQsqalY09KC68Ep1dhucjjCfmbA48FXVoa3vBxvWRne0jJj3rGtogK83u5vMpux5mRjz8vHlh+c8vKw5edhSU3tc7j4Gxrw7NuHZ+8+PMX78O7dZ6zv24e/tpYUoOgw6zQcFR2NOSYGU2xscIrBlpKMslrxt7QQaGrGW1VFoKkZf3Mzuq3tCJTCMHbdWsxxcUfs+B0kjIXoL78P2uqgtQ5aa7tPbfX7b2utN655Hg5l6tE6dELCyB4tyC7LHS3HHmEbmvcSjJ8VFrJgwYJ+FU0HAuDzDXhLTGtNoKkpGELleCvK8QWXfXW1KKsVk92OstlRdjvKbsPUdbnna3Y7mM1otwftbifQ7g7O29HtbgJuYx56rb2dgNuYJ1VXs/MXt+OvqzPOQvRktWJJSsKSnIw5JRn7uHFYUpIxRUfjq63DV1WFr6qKtvUbaKqu3j88AZPTiTUtFUtqGqaYGLxVlXjLyvBX13TfUSksaWlYs7KImjqV+CVLsGZnYc3MxBQXj7d4H+7du/Hs3oNn925aPv4Y7e485W+KjQ0Gcz62/DzseXmYk1PwlpXh2bfXCNziYjz79hFo7P67tWRkYBsxgrhTF2IdMYJddfVMmDSpe+curYMtUDpbmXTdrlEmkxGyMbGYYmIwxcZg7gjemBiUuX+XALTHY7Sim5rwNzfjb2oi0GUeaGkN1Z0xGcuqS+u962tdtyu73NokRP/4vV0663Tt1OPufmrW105m2Ub4ZEfn9c/QvHNZe1rRbW3o9lYCbW3o9na0pxVToAmTVWOy6P3zzBa8pzE6CaKTIWm0MY9KCN7naA/ez2jvvO8xOA8ETPhbvPhb3fhdbvyuNgIeH5a0LCyZuVjS0jAnJaEGcDQg7fUarbjqanzV1UR9+CF1e/cSaG01ppbWzuUwk2416gatUTYbJmc85nincZowPi60bHbGY4oPvuaMD74ej7LZ8FVV4y0vCwWt0dorx1dWTqC1tXuBrVasGRlYkpMJuFrwud1ot5uAx4Pushwu7A6oI9jtdmPucKAcdkx2ByrKgT85mbhxYzEnJ2NJTsGSkhxcNiaT09nn1qbW2mhdV1WHQtpXbcy9VVXGKeeKCqwZ6djnz8eamYk1KxtrVpYRuunpKKu19w84fkb3zwsE8JWX4w6Gs2f3bjx79tC6YT1N//lP9/eaTFizs7GNGEH8mWdgGzES28gR2EaMwJqTs1/rfUthIc5+/vF2JCibDUtSEiQlRbooh0zCWESezx083dqIbmkg0FSNbqwl0FxHoKmegKsR3dxIoKXZuLbU2oJuayXQ1k7A7QGfD+33ha7xoJUxD9B9nc7l6ADs8yu0XxHwK3TATMBvCq6D9oH2hytsdHACTApTtANzTCymuDhM8U7M8U7jWlVcLKbYOOOalicW1R5FoKkRX0MDgcYa/A0Nxj/Iwbm/oRHdM3jCMZuNAAie2rSkpnRZ7pxM8fH46+pCIeurqu5crq7GV1ODr7oaf3195y0sQDxQGVxWNhum6GhjiolGRRnL1oSEzu3BSdms+JubjZZJYxP+piZ81dV4vioKtU66fk6vXy85GWtmJvb8fGLmzsWamRUMo0ysmZmYk5P79MeI9vvRwYAOuD1ojxHU2udD2eyYHEbgdgSwshz4n8LdhYXMGKDQUUphSUzEkpgI48YOyDEP+HnBgLVmZ8PJJ3V7LdDWhmfvXny1tdiyjcA/0teaRXgSxmJg+NzgqoKWquAgA40HmBrQbQ24S5to2eemtcJEW62VgM8Iw35RZpTJCiaFMikwmYx/rM0mY9ls7pybzSiTMW/ze4hJScbkiMIcFYXJ4UDZu7SGQnOH8Q+33ZhjsRBoaSHQ7MLvaibQ7DJOh7mMubeqksBXX4W24evR6Ukpo6WYkIA5IQFrahqOMWON9cSE0PaOyRQVha9rqHaZvJWVtG3Zgr+2tk9Bh8WCJcUIb2t2NlHTp/cI8RTWffklJ512GqaoqAO3vvpJ+/1GB51gWAeaGo2Qbm/Hmp6ONTMTS0ZGr9dN+0uZzaioKIiKQvo8984UFYVj/PhIF0MgYSwOJOA3rou6KoNTVY95l+X2ht6PY7Kg7U48bfG0VNpoLdW0FrfjbzMD0djSncTOyTHCJyYWU4wTU5wTFZeAKT4RU1yScR0pKgpTVDSm6ChMUcZ0qH/FFxYWMvkIn17TWqPb240OJu3tod6d/b0eZhs58sCf4/MZ1yVrOoM60NSMOSnJCN9gxyFzQsJBW5WB2lrM8QM/Dq8ymzE7nZidTuhfp2QhhgUJ4yHOVFtL2+ef429qJtBQQ6C2An99NYHGOgKN9fibgx0dWloJtLQTaPPgd/vQ3gAWhx9rtA9LjB9rdJcpwYElLRlTQgakjYdR8yEmzRjpJzYNohLR9ni8NS20bNpB6/rPaFm7Fn9NDeDGmpVF7BmLiTlhDtFz5mBNT490NR0RSqngHxBRR/ZzLBas6WlY09OO6OcIIY4cCeOjxFteTvPKlbi//JLkb30LW17ewB3c74XmcmgsCU7F6PoSqv61ntSPa9jTy9tMloDREckawOwwY3ZYsaXbMcU4UY4ofK0Kb5MHd10LvqLmHu92Y052Yc2IxZrVjiXTizVTY4pupu2z1bR88gm+8nIALKmpxJx4IjFzZhN9wgnYcmTEHiGE6ErC+AjyFBfTvGIFTStW0L7pc2Oj1UrzynfI+fPDRB9//MEPorVxu0xjcbewpbG0c91V0W3wd+2Hsg3pNBWZcUyMJmX2GMzOREyJqZiT0jElZ2JKzkLFphi9fh0JB31eZ8DjwVdZGezt2qXna0UF7t27cX3wYagDkjkhgeg5c4i57lqi58zBlp9/VG6aF0KIY5WE8QBzF+0OBvDbuLcZg9k6Jk4k9aabiFv8NZTJRPF132bf1cvIuue3xC9ZAi3V0LAPGvdBQ7ERtg1dlkOPNwsy243xYJ05MHph57IzB785idI7H6SlaC2pN93ElrFjyF+48LC/l8lmw5abiy03/AW/jntC/U1NWLOzB/T2GyGEGOokjA+T1hr3l1/S/PYKmleswP3llwBETZtG2i23EHf6YmwZaVBXBNWboPZLRl49kpInKim9+Ud4nr2e5HGN3e9XdSQYQ+8lj4ZRC4xlZ64xj8+BmJSwAzb4qqvZ9+1v496xk8zf/IaEC86HwsKjUQ0opTo76AghhOgXCeNDoLXGvX07TcEA9uzeDUoRNWM66d+/iriJyVh1BVS/C68+ArVfdbtp1RKTxogLcyh/z0v1RvAmnkDGDVehkvONwLX3f+g1z5497LvmWny1teT++WFi588fwG8shBDiSJIw7gdvZRVN/3mNhldexfPVV6AU0WNSSDojk7jUKiye5VDzBqwGlNlo2aaMhQnnQOo4Y0oeA7ZoTEDWtwNY//cP1D72GF7fv8l+8EHM9ph+l6tt82aKr/s2ACOfeZqoqVMH9osLIYQ4oiSMDyLQ3k7zu+/S+PJLtHz0CWhNVKqfjIJm4nLascTUGIGbOhtSrwwuj4ekUcawhwegTCbSbr4Ja042Ff/vV+z9xjfIffQRrBkZfS6fa/VqSn7wQyxJSeQ+/lfs+fmH+5WFEEIcZRLGYWitadu4kcYXnqVpxXsE2jxYov0kT2jFOcGOvWAxjF0MmdOMwfoP87mmiRdfjDUzi9If/pA9F19C7l8exTFhwkHf1/DKq5T/4hfYx41lxF/+giU19bDKIYQQIjIkjLvwlpbQ+LdHaFy+Ak+VC2UOEJfTTsKMVKJPXYoafybkFByRh4rHnnIyI59/juJvX8/ey79B9v8+SOy8eWH31VpT+9fHqX7gAaJPPIGcP/0Jc2zsgJdJCCHE0THswzhQX0nz//2ZxuUraNlVDyii0zwkn5lD3NnnY552rvHA86PAMW4cef94geLrv0Pxd75Lxh13kHjJxd320X4/lb+9h/q//534pUvJ+u1vZGB3IYQ4xg35MNZa46+p6XwYd1mZMVhFWRne3TvwFJei/QprbICUU0fivPBibCd93XgmbARY09MZ+be/Ufqjm6n45S/xFu8j9eabUSYTAbebsltvo/mtt0hatoy0W34s9/MKIcQQMCTC2N/cjHXHThrqG/CWleItC44QVVqGt7wc7fF0298UG4s1LQmrby/RU+KI+58biD7jGyjr4GhhmmNjyH34YSruvpvax5/AU1JKxs9/RunNP6J13TrSfvITkr+5LNLFFEIIMUCGRBi3ff45SQ8+SHlw3ZyagjUrC/vECcQuWmQ8lLvjwdxZWZi1Cx5fBNoK1y6H+MyIlj8cZbGQ8ctfYssdQdV99+F69100kHXffTjPPivSxRNCCDGAhkQYR02ZQv0Pf0DBkiVYMjMx2e297+xpgacuMZ65+823BmUQd1BKkfytb2LNzqbmz38m/bZbiZk7N9LFEkIIMcCGRBib4+PxjB9/8CchBfzw8rVQsRkuewEyj43BMeKXnE78ktMjXQwhhBBHyJAI4z5beQfseAPOuBfGSrgJIYQYHPrUFVcptUQptUMptUspdVuY151Kqf8opTYppbYqpQZf76L1T8JHD8Hs62DOtyNdGiGEECLkoGGslDIDDwNnABOBy5RSE3vs9j1gm9Z6GrAAuF8pNTi6JgPsehfe+DGMWQyn/zbSpRFCCCG66UvLeDawS2tdpLX2AC8A5/bYRwNxyniCfCxQB/gGtKSHqnIb/PNqSJsAFz0J5uF1Zl4IIcTgp7TWB95BqYuAJVrra4LrVwBztNbf77JPHPAaMB6IAy7RWr8R5ljXAdcBpKenz3zhhRcG6nvgcrmI7TEkpNXTwMwNt6C0l0+Pvw+3Y/iN3RyuXoTUS2+kXsKTeglP6iW8A9XLwoULN2itC3pu70szcf+n2Bst4a5OBzYCpwKjgZVKqf9qrZu6vUnrx4DHAAoKCvSCBQv68PF9U1hYSLfjedvg6bMg4IJlyzkxa8aAfdaxZL96EYDUS2+kXsKTeglP6iW8Q6mXvpymLgFyu6znAGU99lkG/EsbdgG7MVrJkREIwCvfhtINcMFfYZgGsRBCiGNDX8J4HTBGKZUf7JR1KcYp6a72AYsAlFLpwDigaCAL2i/v3QXb/g2L74IJMlqVEEKIwe2gp6m11j6l1PeBtwEz8KTWeqtS6vrg648CdwFPK6U2Y5zWvlVrXXMEy927z/4Oax6AmVfDid8/6O5CCCFEpPWpa7HWejmwvMe2R7sslwGLB7Zoh2D3avjPD2DUQjjz96DCXe4WQgghBpch8/y96JYS+Mc3IPk4uPgZMFsjXSQhhBCiT4ZGGLfUMmXzXWC2wf+8GLFnEQshhBCHYmiMgFG1DYuvBS5/BRJHRro0QgghRL8MjZZx/il8fMJfIXdWpEsihBBC9NvQCGPAb4mKdBGEEEKIQzJkwlgIIYQ4VkkYCyGEEBEmYSyEEEJEmISxEEIIEWESxkIIIUSESRgLIYQQESZhLIQQQkSYhLEQQggRYRLGQgghRIRJGAshhBARJmEshBBCRJiEsRBCCBFhEsZCCCFEhEkYCyGEEBEmYSyEEEJEmISxEEIIEWESxkIIIUSEDYkw3lbWxJ83tlPe2BbpogghhBD9NiTCOKA1ayv8rN1dF+miCCGEEP02JMJ4QmY8URb4RMJYCCHEMWhIhLHZpBiTYGadhLEQQohj0JAIY4CxSSa+rHJR63JHuihCCCFEvwyZMB6XaAZg3Z76CJdECCGE6J8hE8b5ThN2i4l1e+RUtRBCiGPLkAlji0kxY0SC9KgWQghxzBkyYQwwOz+ZrWWNNLd7I10UIYQQos+GVhjnJRHQ8Om+hkgXRQghhOizIRXGx49MwGJSrN1dG+miCCGEEH02pMI42mZhcrZTrhsLIYQ4pgypMAaYnZ/EpuJG2r3+SBdFCCGE6JOhF8Z5SXj8ATYVN0S6KEIIIUSfDLkwLshLBJBT1UIIIY4ZQy6ME6JtjM+IY60M/iGEEOIYMeTCGIzrxhv21uPzByJdFCGEEOKghmQYz8pLotXjZ2tZU6SLIoQQQhzUkAzj2flJADJOtRBCiGPCkAzj9HgHecnRfCKduIQQQhwDhmQYg3Gqev2eOgIBHemiCCGEEAc0ZMN4dn4S9a1edlW7Il0UIYQQ4oCGbBjPyU8GkFPVQgghBr0+hbFSaolSaodSapdS6rZe9lmglNqolNqqlFo1sMXsv9ykKNLj7ayTMBZCCDHIWQ62g1LKDDwMfA0oAdYppV7TWm/rsk8C8GdgidZ6n1Iq7QiVt8+UUszOT2bt7jq01iilIl0kIYQQIqy+tIxnA7u01kVaaw/wAnBuj33+B/iX1nofgNa6amCLeWhm5ydR0dROcV1bpIsihBBC9KovYZwNFHdZLwlu62oskKiUKlRKbVBKXTlQBTwcs/OM+41laEwhhBCD2UFPUwPhzu/2vF/IAswEFgFRwEdKqY+11ju7HUip64DrANLT0yksLOx3gXvjcrn2O15Aa2Ks8O8Pt5LSvGvAPutYEq5ehNRLb6RewpN6CU/qJbxDqZe+hHEJkNtlPQcoC7NPjda6BWhRSq0GpgHdwlhr/RjwGEBBQYFesGBBvwp7IIWFhYQ73on71rOrqjnsa8NBb/Uy3Em9hCf1Ep7US3hSL+EdSr305TT1OmCMUipfKWUDLgVe67HPv4FTlFIWpVQ0MAfY3q+SHCFz8pPYU9tKVVN7pIsihBBChHXQMNZa+4DvA29jBOyLWuutSqnrlVLXB/fZDrwFfA6sBR7XWm85csXuu45xquW6sRBCiMGqL6ep0VovB5b32PZoj/X7gPsGrmgDY1JWPNE2M2t313HW1KxIF0cIIYTYz5AdgauDxWxi5shE1srgH0IIIQapIR/GYNzitKOymYZWT6SLIoQQQuxnWITxrPwktIb1e+ojXRQhhBBiP8MijKfnJmAzm1gnnbiEEEIMQsMijB1WM9NynfIEJyGEEIPSsAhjgFl5SWwpbaTV44t0UYQQQohuhk0Yz85PwhfQfLavIdJFEUIIIboZNmE8c2QiJoWcqhZCCDHoDJswjnNYmZgVzzoJYyGEEIPMsAljgNl5yXy6rx6PLxDpogghhBAhwyuM8xNx+wJsLm2IdFGEEEKIkGEVxrPygg+N2C2DfwghhBg8hlUYJ8faOS4tlrW7ayNdFCGEECJkWIUxGK3j9Xvq8Qd0pIsihBBCAMMwjOfkJ9Hs9vFFRVOkiyKEEEIAwzCMZ+d3XDeWW5yEEEIMDsMujLMSoshOiJIwFkIIMWgMuzAG41T1uj11aC3XjYUQQkTesAzj2flJ1Lg8FNW0RLooQgghxNAI43ZfO+tb1tPqbe3T/rPkurEQQohBZEiE8QdlH/BMzTMseHEBt/33Nv5b8l98gd4flTgqJYaUWJuMUy2EEGJQsES6AANhYe5CfpD+A0qdpazYs4I3it4gyZHEkrwlLB21lCkpU1BKhfZXSjErL0me4CSEEGJQGBJhbFImjnMcxzUnXsNPZ/+UNaVreL3odV7a+RLPf/E8I+JGcOaoM1mav5Q8Zx5gXDd+c0sFpQ1tZCdERfYLCCGEGNaGRBh3ZTPbOHXEqZw64lSaPc28s/cd3ih6g79s+guPbnqUycmTWTpqKWOzTgJg3e46smdkR7jUQgghhrMhF8ZdxdniOH/M+Zw/5nwqWyp5a89bvF70Or9b9ztMykTcyOP4186vcc706zCpIXH5XAghxDFo2CRQekw6V026in+e/U9ePfdVvjX5W9iiavms/WGe3PJkpIsnhBBiGBs2YdzV6ITR3Hj8jXxr5F/xNk7jT5/+ifUV6yNdLCGEEMPUsAzjDosmZOCrvBDlT+FHhbdQ2yaPVhRCCHH0DeswHpcRx7PLTsFf/g3q2hv5/js/xh/wR7pY+/EH/Hxa+akM3ymEEEPUsA5jgLnHpfDyNRfhaLyQLXXrue3dByNdpP08vvlxrnrrKl768qVIF0UIIcQRMOzDGGBsehyvL7uZGO9s3ix9lrve/XekixRS6irlr5v/ikLx0GcP0eKV8bSFEGKokTAOSo+P4vXLHiRKZfDCnnv4+WsfEghE/rTw79Yat2E9uOBB6trreGLzE5EukhBCiAEmYdxFSkw8fz/rIawWD/8q+R3f+ft62jyRu4a8umQ17xe/z7enfptFIxexdNRSntn6DGWusoiVSQghxMCTMO5hXPJY7jzpdiwxRRRW/53L/voxNS73US+H2+/mnrX3kBefx5UTrwTgBzN+gFKKP3z6h6NeHiGEEEeOhHEY5x13HueOPhd7yvvsaFzP+X/+gF1VrqNahqe2PEVxczE/m/MzrGYrAJmxmVw58UqW717O59WfH9XyCCGEOHIkjHvx8xN+zuiE0STmvUSrr44LH/mQT4qOzn3Ipa5SHt/8OKfnnc6JWSd2e+1bU75FsiOZ+9bdJ7c6CSHEECFh3IsoSxT3z78fn3YzZsq/SY41c8UTa/n3xtIj/tkdnbZ+XPDj/V6LscZww4wb2Fi9kZV7Vx7xsgghhDjyJIwPYFTCKG4/4Xa21m1kycmbOH5kAj94YSN/evfLI9Yq7ei0df2068mIyQi7z3nHnceYxDE8sOEBPH7PESmHEEKIo0fC+CDOHn02F465kL998RTXnu7m/BnZ3L9yJz956XNa3L4B/ayOTlv5znyumHBFr/uZTWZ+XPBjSl2lPL/9+QEtgxBCiKNPwrgPbpt9G+MSx/HLj37BT5amc+OiMfxzQwnz7n2fx/9bRLt3YG5/Ctdpqzdzs+ZySvYp/OXzv1DXXjcgny+EECIyJIz7wGFx8Pv5v8fr93LL6lu4YVE+r3x3LhOz4rn7je3Mu/d9nv1oD27foYdySXNJqNPWCZkn9Ok9Pyr4EW2+Nh7Z+Mghf64QQojIkzDuozxnHv9v7v9jU/Um/vjpH5kxIpG/fWsOL1x3AiOTo7nj31s59fer+Me6fXj9gX4f/9519/baaas3oxNGc9HYi/jnzn9S1FDU788UQggxOEgY98OS/CVcMu4Snt76NIXFhQCcMCqZF799Is9+czYpsTZufXkzX3tgFa9+Voq/j8NpdnTa+s607/Taaas3353+XaPn94b7+/lthBBCDBYSxv10y6xbmJA0gZ+v+TkflX0EgFKKeWNTefV7J/H4lQVE2Sz88B8bWfK/q1m+ufyAY1y7/W5++8lvyXfm840J3+h3eZIcSVw79VpWl6wOlUcIIcSxRcK4n+xmO/cvuJ9ERyLXrbyOW1ffSk1bDWCE8mkT03njhpN5+H+OJ6A1333uU8760xre3V4Z9naop7Y8RYmrpE+dtnpz+YTLyY7N5vfrfz8on8cshBDiwPoUxkqpJUqpHUqpXUqp2w6w3yyllF8pddHAFXHwyY3L5eVzXub6adezcu9Kznn1HP65858EtHGt2GRSLJ2ayYqb5vPAxdNo8fj41jPrOf/PH7J6Z3UolDs6bS3JW9LnTlvh2M12fjjzh+ys38m/vxo8j38UQgjRNwcNY6WUGXgYOAOYCFymlJrYy36/A94e6EIORnazne9N/x4vnfMS45PG86uPfsVVb17FzvqdoX3MJsUFx+fwzs3zueeCKVQ1tXPlk2v52oOreWLNbn798T2YlIkfFfzosMtz+sjTmZY6jT999id55rEQQhxj+tIyng3s0loXaa09wAvAuWH2uwF4GagawPINeqOco3hi8RP8+uRfs6dpD5f85xIe2PAArd7W0D5Ws4lLZ4/g/VsWcO9FU4m1W/hN4b9YU7aKbM6luNp22CN6KaW4ZdYt1LTV8OSWJw/3awkhhDiK+hLG2UBxl/WS4LYQpVQ2cD7w6MAV7dihlOKc0efwn/P+w9mjz+apLU9xwWsXsLpkdbf97BYzFxfk8o/rC8gfu4I4Uza7dk7n649+xOIHV/Pkmt00tB768JbTUqdxRv4ZPLP1GSpaKg73awkhhDhK1MFaZEqprwOna62vCa5fAczWWt/QZZ9/AvdrrT9WSj0NvK61finMsa4DrgNIT0+f+cILLwzYF3G5XMTGxg7Y8Q7HrvZd/KPuH1R4K5gePZ2LEi/CaXGGXn+z4U2WNy7n+2nfJ886lk8qfBQW+yhqDGA1wawMCwtyLYxJMKGU6tdn1/nquKv0LmbEzODKlCsHVb0MJlIv4Um9hCf1Ep7US3gHqpeFCxdu0FoX9NzelzA+EbhTa316cP2nAFrr33bZZzfQkRopQCtwndb61d6OW1BQoNevX3/Az+6PwsJCFixYMGDHO1xev5entj7FY58/hsVk4YYZN3DpuEspbynnvH+fx8Lchdw3/75u79la1sj/rd3Hq5+V4XL7GJMWy2WzR3Dh8Tk4o/ve0/p/N/wvT2x5gheWvkD1lupBVS+DxWD7vQwWUi/hSb2EJ/US3oHqRSkVNoz7cpp6HTBGKZWvlLIBlwKvdd1Ba52vtc7TWucBLwHfPVAQDwdWs5Xrpl7HK+e8wrTUadyz9h4uX345d3x4R68jbU3KcnL3eVP45GeL+N2FU4i2mfnV69uY/Zt3uOkfG3lnW2WfxsG+Zso1JDmSuHfdvfLMYyGEOAZYDraD1tqnlPo+Ri9pM/Ck1nqrUur64OvD8jpxX+XG5/LoaY/y5u43uXfdvdS21/KjmT8iPSa91/fE2C1cMmsEl8wawZZSo7X82sYyXvmslCirmVPGpLB4Uganjk8jKca23/tjbbF8b/r3uOvju5iROoOFLDySX1EIIcRhOmgYA2itlwPLe2wLG8Ja66sPv1hDi1KKM0edyck5J/Nh2YecNuK0Pr93craTX58/hV+ePYmPi2pZua2SldsqWbGtEpOCgrwkFk9MZ/HEDEYkR4fed8GYC/i/L/6PV+tfZeSXI0mJSglNiY5ELKY+/acXQghxFMi/yEdRvC2eJXlLDum9NouJeWNTmTc2lV+dO4nNpY1GKG+t5O43tnP3G9sZlx7H4knpfG1iOlOyndw2+za+s/I73PHhHd2OpVAkOhK7BXTPKTUqley4bKymQxsVTAghRN9JGB+DlFJMzUlgak4CP1o8jn21razYVsGKbZU8/P4u/vTeLjKdDk6bkM4Vjrs557TJuPz11LTWUNNWQ017cN5WQ21bLbsbd1PTVoM34O32ORaThbz4PEYnjGZ0wmiOSziO0c7R5MbnSkgLIcQAkjAeAkYkR3PNKaO45pRR1LV4eO+LKlZsreCfG4pp92oe2bSV6bkJnDA6lxNHTefc0Qk4rOZux9Ba0+RpCoV0RUsFRY1FfNXwFVtrtrJizwo0RmewjpA+LuE4RiWMMkI6YTS5cRLSQghxKCSMh5ikGBsXzczhopk5tHv9/OXV92mJyeajr2p56L0v+eO7X2K3mDh+RCInjk7mxNHJTMtJwGYx4bQ7cdqdjE4Yvd9xW72t7G7aTVFDEbsadvFVw1dsqdnC23ve7hbSo52jWTRiEWfkn0GeM+8of3shhDg2SRgPYQ6rmWmpFhYsmABAY5uXtbvr+Liolo++quXBd3bywEqIspopyEvkhFFGOE/JdmI1d7/rLdoazaTkSUxKntRte0dIf9XwFV81fMXn1Z/zyKZH+POmPzMxeSJn5p/JkrwlB+w9LoQQw52E8TDijLLytYlGBy+AhlYPHxd1hvN9b+8AIMZmZlZ+ErPykpiTn8SUHCd2iznsMcOFdGVLJW/veZvlu5fz+/W/5/7191OQUcAZ+WeweORinHZn2GMJIcRwJWE8jCVE21gyOYMlkzMAqHG5+aSojo+Kavi4qI7CHUY42y0mpucmMDsY0MePTCTW3vtPJz0mnSsnXcmVk65kT+Me3tzzJsuLlvOrj37Fbz75DSdnncwZ+WewIHcB0dboXo8jhBDDhYSxCEmJtbN0aiZLp2YCUOtys25PPev21LFuTx1/LvwKf2AXZpNiUlY8s/KSQgEdbvARgDxnHt+Z9h2un3o92+u28+buN1m+ezmFJYVEWaJYmLuQM/PPZG7WXKxm6fwlhBieJIxFr5Jj7d1azi63j0/3GuG8dncdf/t4L0+s2Q3AmLTY4KntRCZkxpOfEtPt1LZSionJE5mYPJGbZt7EhsoNLN+9nJV7V7J893LibHFMSZnCxOSJodPeGTEZ/X5QhhBCHIskjEWfxdotoYFHANw+P5tLGlkbDOf/bCzj+U/2AWA2KfJTYhibHsvY9LjQlJccjcVsYlbGLGZlzOJns3/Gh2Uf8n7x+2yt3crTW57Gp30AJDmSmJA8IRTOE5Mnkh6dLgEthBhyJIzFIbNbzBTkJVGQl8R3F4A/oNlV5WJHZTM7K5rZWdnMtrIm3txSQcfzKmxmE6NSYxibHse4jDjGpMUyLqOAO06Yh8mkaPe1s7N+J9tqt7G1divbarfxRNkT+LXxgIxkRzKTUiaFWtDHJRyHRuPxe3D73aHJ4/fQ7msPLfd8bV/9PiiGmekzibPFRa4ShRACCWMxgMwmxbgMI2SZ1rm9zePnq2oXOyub2VHZzJeVLjbsree1TWWhfaKsZsZmxDExM44JmfFMyFzM0pkXEuew0uZrY0fdjm4BvaZ0DQEdOKRyWpSFgA7w9ntvY1ImJiZNZHbmbGZnzGZG2oxjtlOZ1pp9zftYW7GWPY17mJY6jROyTiDeFh/pogkhDkLCWBxxUTYzk7OdTM7ufkuTy+3jy0qjBb2jwsX2cqMV/X9ri0P75CZFMTEzPhjQp3L9xPPISYwyArp+B0UNRVhMFuxme2iymW04LA5sZlu37R2vWUwWVr6/koQJCaytWMva8rU8u+1ZntzyJBaThSkpU5iVMYs5GXOYljYNu9l+2HWgtR7w0+taa0pcJayrWMfairWsq1hHVWsVYPzB8ey2ZzErM1NTp3JS1kmclH0SE5MnYlJ9eXKqEOJokjAWERNrtzBjRCIzRiSGtmmtqWhqZ3t5E9vLjdPc28ubWLGtMnSqO85uYXyoBT2LvPRYjkuLwxnV997YVmUNXbf+3vTv0eptZWPVRiOcK9by+ObHeezzx7CZbExPm26Ec+YcJidPxu130+Bu6DY1uhuN5fYuy8Ht9e563H43mTGZ5MblkhuXy4i4EeTGG/OcuByiLFF9Kne5qzxUxnUV6yhvKQeM6+uzMmYxO2M2szJmkROXw+bqzawpXcOHZR/y0MaHeGjjQyTaEzkx60ROyj6JuVlzSYlK6ft/sAHWMQSr3HcuhISxGGSUUmQ6o8h0RnHq+M5Ru1o9PnZUNLO9vDkY1E3869NSXO69oX3S4+2MSYtjTHosY9LiGBucO6MPHtLR1mjmZs9lbvZcAJo9zXxa+Wko+P688c88vPHhgx4n3hZPgj2BBHsCqdGpjEkcg9PuxGF2UNZSRnFTMSv3rqTB3dDtfWnRaYyIG8GI+BHdAjvOFsdnVZ+xrmId6yrWUeIqASDBnkBBegFXT7qa2RmzGZ0wer+W9/Hpx3N8+vHcePyN1LbV8lH5R3xY+iEflH3A8t3GE1EnJE1gbtZcTso+ielp0w/6/Q5Xu6+dT8o/YVXJKlaVrKKqtYqsmCxmps+kIKOAmekzGRE3QjrpiWFHwlgcE6Jt+7eiAwFNaUMbOyub+bLKxZeVLr6sauaFtcW0ef2h/VLj7KFg7ghql0cf8PPibHHMz53P/Nz5ADS0N7C+cj1f1H1BrDUWp91phK4jIRS+8bZ4zKbwI5X11OhupKS5hH3N+9jXtI99zfsobi5mVfEqattrw5anIL2AyydczqyMWYxJHNOv083JUcmcNeoszhp1FgEd4Iu6L/iw7EPWlK7hma3P8MSWJ4ixxpBvyWfHph1MSJ7AxOSJA9JyrmipYHXJalaXrOaT8k9o97cTbYnmpOyTmJA0ge112/mg7AP+U/QfAFKjUo1wTjfCOdwfGkIMNRLG4phlMilyk6LJTYpm0YTOVnRHSO+qcnUJ6mZeXF9Mq6czpH/+0QryUmLIT4425ikxjEyOIT85Zr/WdIIjgdNGnsZpI08bkLJ3PJRjUsqk/V5r8bZQ3FzMvqZ9NLgbmJwymXGJ4/oc9AdjUqbQPd/XTLkGl8fFJxWf8EHpBxQWFfLQxodC+6ZGpTIheQITkiaEbjM72O1lAR1ga81WVpWsYnXJarbXbQcgOzabC8deyLyceRSkF2Azdw4Uo7Vmd+Nu1leuZ33lejZUbOCtPW8BkGhP5Pj040MBPTZx7IDVhRCDhYSxGHK6hvTC8Wmh7YGApqyxjS+rXLz14SbMCRnsrW1h3Z56/r2pLHRNGiAx2hoMaiOg81KiyU+JIS8lhnjHkR0pLMYaw/ik8YxPGn9EP6dDrC2WRSMWsWjEIua551Ewt4Av6r5ge912ttduZ3vd9m691xPtid0CemLSRJKikvi47ONQANe212JSJqanTuemmTcxP2c+o5yjeg1xpRSjEkYxKmEUF4+7ONQ5bX3FejZUbmBD5Qbe3fcuAHHWOCanTCY1OhWn3UmiPbHbGYoEewKJjkScducx9UhPX8DH59Wfs6pkFXsa93BKzil8beTX5Jr6MCFhLIYNk0mRkxhNTmI0qtzKggVTQq+1e/3sq2tld00Le2tb2F3Typ6aFj4qquVfn5V2O05anJ3j0mI7p1RjnhpnHxKnU2NtsRRkFFCQURDa1uZrY2f9zlA4b6/dzjPbnsEX8HV7b5w1jpOyT2J+7nxOzjqZBEfCIZVBKRW6dn7+mPMB43R3RzBvq93G3qa9NLgbaPW19v5drLGdIe1IIMmRRE5sDjlxOaHjJzmSIvbfrdHdyIdlH7KqZBVrStfQ6G7EoiwkRyXzXvF7/OaT3zAvZx5LRy1lXs68AenZD8aZiO112yksLqSwuJA9TXs4MfNEFuctZn7OfGJtsQPyOaLvJIyFwHjcZMcoYT21eTqDendNC7uqXOyqdgU7kHWGUZzD0i2cO6acxGjMpmM7pKMsUUxLnca01M4byD1+D7sadrG9djuVrZXMypjF9LTpR6w1mhGTwdJRS1k6amm37W6/m4b27r3bG9obqHfXh3qzN7Q3UN9ez5f1X/Kf1v+EnsENEG2JDgVzblxut6DOiMnAYhq4fyY7Tsd3dGDbWLURv/aTaE9kfs585ufM58SsE4m1xrKtdhuvF73OW3ve4t197xJrjeW0kaexdNRSZqXP6veperffzdrytUYAlxRS1VqFQjE9bTpn5p/Jf0v+y3vF72E1WTkp6yQjmHPny33qR4mEsRAHEWUzdw5m0oXWmsomtxHOVc3sqnaxq8rF+zuq+eeGktB+douJ/JSYYKs8ipzEKLIToshOjCInMZrEaOsx2aK2mW2ha8+RZDfbSY9J7/Mzs91+N6WuUkqaSyhuLg5NXzV+xaqSVXgD3tC+FmUhKzaLaG80b/33LRLtiSQ6glOPZafdGbZTncfvYX3lelaXrGZV8apQj/hxieP45uRvMj93PpOTJ+8XrpNSJjEpZRI/KvgRayvW8kbRG6zcu5JXd71KWlQaS/KXsHTUUiYkTej191PbVmt8bskqPiz7kDZfG1GWKE7KOokFuQs4JecUkhxJgHGtf1P1JlbsWcHKvSspLCnEYrKEWswLcxcOm1PmvoCPclc5xa5i5mbNPSqfKWEsxCFSSpHhdJDhdHDymO69jhtaPcGQNqaimhaK61r5uKi2W2sajNHHssOEdHZCFLmJUaTE2jEd4y3rwcRutjPKOYpRzlH7veYP+KlqreoW0sXNxewo38HGqo00uBto8baEPa5JmXDanN0C2qd9rC1fS6uvFbvZzgmZJ7Bs8jLm5cwjIyajT+W1mCzMzZrL3Ky53O67ncKSQt4oeoPnv3ieZ7c9S74zn6X5Szlz1JnkxOZQ1FjE+8Xvs6p4FZuqN6HRpEenc87oc1iQu4BZGbPCnu42KRMz0mYwI20Gt8y6hc01m1m5ZyUr967k9g9ux6IszMmcEwrmREdimNIeO3wBH2WuMvY172Nv016Km4tD89Lm0tAY+WsuXXNU/ghRWh/4Fo8jpaCgQK9fv37AjldYWMiCBQsG7HhDhdRLeJGqF601jW1eSurbKG1oo7S+LbjcSmmDsdzQ6u32HpvFRE6XkM5NiurWyk6NHbhr1fJ7Ca9rvXScFq9311PfHpzCLDe4G/AFfMzOmM383PnMypjV58Fd+qKhvYEVe1fwRtEbfFr1KQApUSnUtNUAMDF5IgtyFrAgdwHjk8Yf8m9Ea83W2q2s2LuCFXtWUOoqxazMxuAy7TksmrmIzJhMMmMyj9pQsv6AH5/24QsYkzfg7Tbvud3ldYXuUOi4nbDMVRYKXDAuV4yMH0luXG5oPiJ+BFNTpvb78a4H+v9IKbVBa13Qc7u0jIU4ipRSJETbSIi27Tc8aIcWt69LULdSEgzskvpWVpRVUNvi6ba/3WIKBnN0aN41sJNjbMfkafDBqr+nxY+UBEcCF4+7mIvHXUyZq4zlu5ezo24HszJm9avlfTBKKSanTGZyymRuOv4mttdtZ+XelazYs4KPmz/mpXdeCu0bb4snKzaLjJiMUEBnxmSSGWvMU6JS9juV3+Zro669jrq2OmPeXkdte21oub69PvR6o6cRb8B7yOPSx1hjGBE3ggnJEzg973RGxI8IDbaT7EiO6P8nEsZCDDIxdkuvncmgM6w7grq4rjOwPy9poL5HyzraZu4M6R5hnZsYTXyURcL6GJcVm8U1U6454p/T9bnkN864kVfffZW8qXmUu8opbzGmipYKSl2lbKjYQLO3udv7LSYL6dHpJNgTaHA3UNdeR5uvLexnRVmiSHIkkexIJiM6g4nJE3HanFhMFqwmK1azFYuyhNYtpv2XO9ajLFER7zl/MBLGQhxjDhbWze3ebq3p4rrgvL6NdbvraO5xzTrObiEnyWhF0+LmC/UVaXF20uIcpMXbSYuz44w6NjuZiSNHKUWiJTF0nTmcZk8zFS0VRlB3CexGdyN5zjySHEmhwO1YTopKItGeeMw+Pe1QSRgLMcTEOaxMyLQyITP8LSmNrV6K61v3C+q9tS3srfGxcu8X+73HZjEFA7p7SKfFO0iLs5Me7yDT6ZDQFt3E2eKIs8UxJnFMpIsy6EkYCzHMOKOtOKP3f6QlGB1PCk48maqmdqqa3cbUsRyc76p28eFXNTS1+/Z7f5TVTKbTQWaCg0xnFFlOB5kJUWQ4HWQ5o8hMcBzxEcyEOBZJGAshuom1W4hNjWVU6oFHYWr3+qludlPZ1E5lk5vyxjbKG9spb2yjrKGdNV/WUNXcTqDHDRuxdguZwVvCspxRpDsdZMQ7yHAaLeyMeAdJ0ulMDDMSxkKIQ+KwmkNjgPfG6w9Q1eymvKGNssZ2KoJB3RHcX1Q0U+Ny0/MOS5vFRHq8nYx4RyigM5zB5WB4p8XbsVvkgRFiaJAwFkIcMVazyRjIJKH3+2u9/gDVzW7KG9upbGqnomMeXN5S2sg72ytp9+5/O0tSjC0Y1vZQWHeEd0dwH6sjnInhRcJYCBFRVrOJrIQosg4Q2Fprmtp8RkA3tVPZ2L7f8ubSRmpcnv3e27WV3dHhLC0uOI+3kxpcl9AWkSRhLIQY9JRSwY5n1v3GCO/K4wtQ7XJ3tq57tLK3lTVR2NROS5fnWnewmhWpsXZSg4Gd2qX3eGWVD+e+elJi7STH2oi2yT+dYmDJL0oIMWTYLAc/LQ7GwCnVHb3Fm9upanJT7XJT1WSsF9e1smFvPXVdRjv7w6cfhpYdVhPJMXZSYm0kx9pJjjHmKbE2kmI6t6XE2kmKsWGz7P8ACSG6GlRh7PV6KSkpob29vd/vdTqdbN++/QiU6th2OPXicDjIycnBapVbUcTQEmO3EGO3kJcSc8D9vP4ANS43bxZ+SP64KdS43NS2eKhr8RjLLg9Vze1sL2+i1uXB4w8/TKMzykpyrBHOqcHWdUqXeUpo3U6MzSyny4ehQRXGJSUlxMXFkZeX1+8fY3NzM3FxvZ++Gq4OtV601tTW1lJSUkJ+fv4RKJkQg5/VbCLTGcUop5kF49MOuK/Wmma3j1qXh7oWNzWuzsCudXWuf1HRRG2LZ78HgnToaHUnx9pIjLaRHGO0thNjjOWOeVJwindY5aleQ8CgCuP29vZDCmIx8JRSJCcnU11dHemiCHFMUEoR77AS77CSf5AWNxjXt+tbPVQ3G63tmmY3tV1CvC7YAv+q2kVdi4fWMNe5AcwmRWK0jaQYK8kxdtLjjfu10+IdoeX04KhpDqvcCjZYDaowBiSIBxH5byHEkWP08jZuweqLdq+f2hYP9S2e4Klyo9Vd32qEdq3L2L5hXz2VTW48vv1Pmcc7LKHPTAsFtZ3UOAdxDktwshIfnDusJvl34CgZdGEcabGxsbhcrkgXQwghunFYzX3qnAadz82ubOoYIc0YyrRjubLJze6iFiqb2vH1HCKtC4tJhQI61t4zrC3UVXkosuwmObbztHlyjHRaOxQSxkIIMcR0fW72gW4FCwS0carc5aa53Udzu5fmdh9N7T5cXdY75z5K6ltxuY3lpjYv//lqW9hjx9ktJHX0Lu9x3bvjmnhHJ7akGNuwH01NwrgXWmt+8pOf8Oabb6KU4he/+AWXXHIJ5eXlXHLJJTQ1NeHz+XjkkUeYO3cu3/rWt1i/fj1KKb75zW9y0003RforCCHEAZlMyrgNK9Z+SO9/7/33mT77pND17bqWYG9zlyfU67yuxUNpgzEoS12LB68/fEs8zmEJ9SzvCOvknusxxh8YzijrkGt5D9ow/n//2cq2sqY+7+/3+zGbD/yX1cSseH559qQ+He9f//oXGzduZNOmTdTU1DBr1izmzZvH888/z+mnn87Pf/5z/H4/ra2tbNy4kdLSUrZs2QJAQ0NDn8sthBDHKpNSodPTfRGux3lHb/PaLreLFdW4WLfHQ12rZ79xyzvE2i04o6wkRHdMNhKC64nBwDbODlhJ7PK6xTw4Q3zQhnGkrVmzhssuuwyz2Ux6ejrz589n3bp1zJo1i29+85t4vV7OO+88pk+fzqhRoygqKuKGG25g6dKlLF68ONLFF0KIQae/Pc59/gD1rV5qg53Valxumtq81Ld6aWj10tDmobHVS32rh/LGJhpbvTS0efEf4Dp4nMNCUrCFnRgM7sTgckKMjaSO5WgbiTFW0uMcR+XWsUEbxn1twXYY6PuMdS9/js2bN4/Vq1fzxhtvcMUVV3DLLbdw5ZVXsmnTJt5++20efvhhXnzxRZ588skBK4sQQgxHFrOJ1ODQpH3V0fpuDAZ2favR47xjuXObl1qXh11VLhpavbjc+z+fG2DjHV8jIbpvLf/DMWjDONLmzZvHX/7yF6666irq6upYvXo19913H3v37iU7O5trr72WlpYWPv30U84880xsNhsXXngho0eP5uqrr4508YUQYljq2vrOTer7+zy+AA3BkDZC21iOdxydEQgljHtx/vnn89FHHzFt2jSUUtx7771kZGTwzDPPcN9992G1WomNjeXZZ5+ltLSUZcuWEQgY9/X99re/jXDphRBC9IfNYjKe6tXH+74HWp/CWCm1BPgDYAYe11rf0+P1y4Fbg6su4Dta600DWdCjpeMeY6UU9913H/fdd1+316+66iquuuqq/d736aefHpXyCSGEGHoO2q1MKWUGHgbOACYClymlJvbYbTcwX2s9FbgLeGygCyqEEEIMVX3p4z0b2KW1LtJae4AXgHO77qC1/lBrXR9c/RjIGdhiCiGEEENXX05TZwPFXdZLgDkH2P9bwJvhXlBKXQdcB5Cenk5hYWG3151OJ83NzX0o0v78fv8hv3coO9x6aW9v3++/01DgcrmG5Pc6XFIv4Um9hCf1Et6h1EtfwjjcDVZh7/tRSi3ECOOTw72utX6M4CnsgoICvWDBgm6vb9++/ZBvT5JHKIZ3uPXicDiYMWPGAJZocCgsLKTn709IvfRG6iU8qZfwDqVe+hLGJUBul/UcoKznTkqpqcDjwBla69p+lUIIIYQYxvpyzXgdMEYpla+UsgGXAq913UEpNQL4F3CF1nrnwBdTCCGEGLoO2jLWWvuUUt8H3sa4telJrfVWpdT1wdcfBe4AkoE/B5996dNaFxy5YgshhBBDR5/uM9ZaLweW99j2aJfla4BrBrZoQ5vP58NikTFXhBBC9O009bBz3nnnMXPmTCZNmsRjjxm3TL/11lscf/zxTJs2jUWLFgFGj7lly5YxZcoUpk6dyssvvwxAbGxs6FgvvfRSaHjMq6++mptvvpmFCxdy6623snbtWubOncuMGTOYO3cuO3bsAIwe0D/+8Y9Dx/3Tn/7Eu+++y/nnnx867sqVK7nggguORnUIIYQ4wgZv0+zN26Bic593j/L7wHyQr5MxBc6458D7AE8++SRJSUm0tbUxa9Yszj33XK699lpWr15Nfn4+dXV1ANx11104nU42bzbKWV9ff6DDArBz507eeecdzGYzTU1NrF69GovFwjvvvMPPfvYzXn75ZR577DF2797NZ599hsVioa6ujsTERL73ve9RXV1NamoqTz31FMuWLTt4xQghhBj0Bm8YR9Af//hHXnnlFQCKi4t57LHHmDdvHvn5+QAkJRmjj7/zzju88MILofclJiYe9Nhf//rXQ89dbmxs5KqrruLLL79EKYXX6w0d9/rrrw+dxu74vCuuuIK///3vLFu2jI8++ohnn312gL6xEEKISBq8YdyHFmxXbQN0n3FhYSHvvPMOH330EdHR0SxYsIBp06aFTiF3pbUm2GGtm67b2tvbu70WE9P5DM/bb7+dhQsX8sorr7Bnz57QfWm9HXfZsmWcffbZOBwOvv71r8s1ZyGEGCLkmnEPjY2NJCYmEh0dzRdffMHHH3+M2+1m1apV7N69GyB0mnrx4sU89NBDofd2nKZOT09n+/btBAKBUAu7t8/Kzs4G4Omnnw5tX7x4MY8++ig+n6/b52VlZZGVlcXdd98tj2kUQoghRMK4hyVLluDz+Zg6dSq33347J5xwAqmpqTz22GNccMEFTJs2jUsuuQSAX/ziF9TX1zN58mSmTZvG+++/D8A999zDWWedxamnnkpmZmavn/WTn/yEn/70p5x00kn4/f7Q9muuuYYRI0YwdepUpk2bxvPPPx967fLLLyc3N5eJE3s+q0MIIcSxSs5z9mC323nzzbBDa3PGGWd0W4+NjeWZZ57Zb7+LLrqIiy66aL/tXVu/ACeeeCI7d3aOkXLXXXcBYLFYeOCBB3jggQf2O8aaNWu49tprD/o9hBBCHDskjI8hM2fOJCYmhvvvvz/SRRFCCDGAJIyPIRs2bIh0EYQQQhwBcs1YCCGEiDAJYyGEECLCJIyFEEKICJMwFkIIISJMwlgIIYSIMAnjw9D16Uw97dmzh8mTJx/F0gghhDhWSRgLIYQQETZo7zP+3drf8UXdF33e3+/3h56G1JvxSeO5dfatvb5+6623MnLkSL773e8CcOedd6KUYvXq1dTX1+P1ern77rs599xz+1wuMB4W8Z3vfIf169eHRtdauHAhW7duZdmyZXg8HgKBAC+//DJZWVlcfPHFlJSU4Pf7uf3220PDbwohhBiaBm0YR8Kll17KD3/4w1AYv/jii7z11lvcdNNNxMfHU1NTwwknnMA555wT9qlKvXn44YcB2Lx5M1988QWLFy9m586dPProo/zgBz/g8ssvx+Px4Pf7Wb58OVlZWbzxxhuA8TAJIYQQQ9ugDeMDtWDDaR6ARyjOmDGDqqoqysrKqK6uJjExkczMTG666SZWr16NyWSitLSUyspKMjIy+nzcNWvWcMMNNwAwfvx4Ro4cyc6dOznxxBP59a9/TUlJCRdccAFjxoxhypQp/PjHP+bWW2/lrLPO4pRTTjms7ySEEGLwk2vGPVx00UW89NJL/OMf/+DSSy/lueeeo7q6mg0bNrBx40bS09P3e0bxwWitw27/n//5H1577TWioqI4/fTTee+99xg7diwbNmxgypQp/PSnP+VXv/rVQHwtIYQQg9igbRlHyqWXXsq1115LTU0Nq1at4sUXXyQtLQ2r1cr777/P3r17+33MefPm8dxzz3Hqqaeyc+dO9u3bx7hx4ygqKmLUqFHceOONFBUV8fnnnzN+/HiSkpL4xje+QWxs7H5PehJCCDH0SBj3MGnSJJqbm8nOziYzM5PLL7+cs88+m4KCAqZPn8748eP7fczvfve7XH/99UyZMgWLxcLTTz+N3W7nH//4B3//+9+xWq1kZGRwxx13sG7dOm655RZMJhNWq5VHHnnkCHxLIYQQg4mEcRibN28OLaekpPDRRx+F3c/lcvV6jLy8PLZs2QKAw+EI28L96U9/yk9/+tNu204//XROP/30Qyi1EEKIY5VcMxZCCCEiTFrGh2nz5s1cccUV3bbZ7XY++eSTCJVICCHEsUbC+DBNmTKFjRs3RroYQgghjmFymloIIYSIMAljIYQQIsIkjIUQQogIkzAWQgghIkzC+DAc6HnGQgghRF9JGA8BPp8v0kUQQghxGAbtrU0Vv/kN7u19f56xz++n7iDPM7ZPGE/Gz37W6+sD+Txjl8vFueeeG/Z9zz77LL///e9RSjF16lT+9re/UVlZyfXXX09RUREAjzzyCFlZWZx11lmhkbx+//vf43K5uPPOO1mwYAFz587lgw8+4JxzzmHs2LHcfffdeDwekpOTee6550hPT8flcnHjjTeyfv16lFL88pe/pKGhgS1btvDggw8C8Ne//pXt27fzwAMPHLyihRBCDLhBG8aRMJDPM3Y4HLzyyiv7vW/btm38+te/5oMPPiAlJYW6ujoAbrzxRubPn88rr7yC3+/H5XJRX19/wM9oaGhg1apVANTX1/Pxxx+jlOLxxx/n3nvv5f777+fee+/F6XSGhvisr6/HZrMxdepU7r33XqxWK0899RR/+ctfDrf6hBBCHKJBG8YHasGGM9ieZ6y15mc/+9l+73vvvfe46KKLSElJASApKQmA9957j2effRYAs9mM0+k8aBhfcskloeWSkhIuueQSysvL8Xg85OfnA1BYWMiLL74Y2i8xMRGAU089lddff50JEybg9XqZMmVKP2tLCCHEQBm0YRwpHc8zrqio2O95xlarlby8vD49z7i392mtD9qq7mCxWAgEAqH1np8bExMTWr7hhhu4+eabOeeccygsLOTOO+8E6PXzrrnmGn7zm98wfvx4li1b1qfyCCGEODKkA1cPl156KS+88AIvvfQSF110EY2NjYf0POPe3rdo0SJefPFFamtrAUKnqRctWhR6XKLf76epqYn09HSqqqqora3F7Xbz+uuvH/DzsrOzAXjmmWdC20899VQeeuih0HpHa3vOnDkUFxfz/PPPc9lll/W1eoQQQhwBEsY9hHue8fr16ykoKOC5557r8/OMe3vfpEmT+PnPf878+fOZNm0aN998MwB/+MMfeP/995kyZQozZ85k69atWK1W7rjjDubMmcNZZ511wM++8847+frXv84pp5wSOgUOcMstt1BfX8/kyZOZNm0a77//fui1iy++mJNOOil06loIIURkyGnqMAbiecYHet9VV13FVVdd1W1beno6//73v/fb98Ybb+TGG2/cb3thYWG39XPPPTdsL+/Y2NhuLeWu1qxZw0033dTbVxBCCHGUSMt4GGpoaGDs2LFERUWxaNGiSBdHCCGGPWkZH6Zj8XnGCQkJ7Ny5M9LFEEIIESRhfJjkecZCCCEO16A7Ta21jnQRRJD8txBCiKNjUIWxw+GgtrZWQmAQ0FpTW1uLw+GIdFGEEGLIG1SnqXNycigpKaG6urrf721vb5fgCONw6sXhcJCTkzPAJRJCCNFTn8JYKbUE+ANgBh7XWt/T43UVfP1MoBW4Wmv9aX8LY7VaQ8M49ldhYSEzZsw4pPcOZVIvQggx+B30NLVSygw8DJwBTAQuU0pN7LHbGcCY4HQd8MgAl1MIIYQYsvpyzXg2sEtrXaS19gAvAD1HlzgXeFYbPgYSlFKZA1xWIYQQYkjqSxhnA8Vd1kuC2/q7jxBCCCHC6Ms143CPGOrZ3bkv+6CUug7jNDaASym1ow+f31cpQM0AHm+okHoJT+olPKmX8KRewpN6Ce9A9TIy3Ma+hHEJkNtlPQcoO4R90Fo/BjzWh8/sN6XUeq11wZE49rFM6iU8qZfwpF7Ck3oJT+olvEOpl76cpl4HjFFK5SulbMClwGs99nkNuFIZTgAatdbl/SmIEEIIMVwdtGWstfYppb4PvI1xa9OTWuutSqnrg68/CizHuK1pF8atTfK0eiGEEKKP+nSfsdZ6OUbgdt32aJdlDXxvYIvWb0fk9PcQIPUSntRLeFIv4Um9hCf1El6/60XJ0JNCCCFEZA2qsamFEEKI4WhIhLFSaolSaodSapdS6rZIl2ewUErtUUptVkptVEqtj3R5IkUp9aRSqkoptaXLtiSl1Eql1JfBeWIkyxgJvdTLnUqp0uBvZqNS6sxIljESlFK5Sqn3lVLblVJblVI/CG4f1r+ZA9TLsP7NKKUcSqm1SqlNwXr5f8Ht/fq9HPOnqYPDde4EvoZxi9U64DKt9baIFmwQUErtAQq01sP6PkCl1DzAhTFK3OTgtnuBOq31PcE/4BK11rdGspxHWy/1cifg0lr/PpJli6Tg6IGZWutPlVJxwAbgPOBqhvFv5gD1cjHD+DcTfDZDjNbapZSyAmuAHwAX0I/fy1BoGfdluE4xjGmtVwN1PTafCzwTXH4G4x+VYaWXehn2tNblHQ+60Vo3A9sxRhQc1r+ZA9TLsBYcBtoVXLUGJ00/fy9DIYxlKM7eaWCFUmpDcPQz0Sm941744DwtwuUZTL6vlPo8eBp7WJ2K7UkplQfMAD5BfjMhPeoFhvlvRillVkptBKqAlVrrfv9ehkIY92kozmHqJK318RhP1fpe8LSkEAfyCDAamA6UA/dHtDQRpJSKBV4Gfqi1bop0eQaLMPUy7H8zWmu/1no6xuiTs5VSk/t7jKEQxn0ainM40lqXBedVwCsYp/SFobLjyWLBeVWEyzMoaK0rg/+wBIC/Mkx/M8Frfy8Dz2mt/xXcPOx/M+HqRX4znbTWDUAhsIR+/l6GQhj3ZbjOYUcpFRPsZIFSKgZYDGw58LuGldeAq4LLVwH/jmBZBo0ejz49n2H4mwl2yHkC2K61fqDLS8P6N9NbvQz334xSKlUplRBcjgJOA76gn7+XY743NUCwK/3/0jlc568jW6LIU0qNwmgNgzHS2vPDtV6UUv8HLMB4kkol8EvgVeBFYASwD/i61npYdWbqpV4WYJxu1MAe4NvDbZx5pdTJwH+BzUAguPlnGNdHh+1v5gD1chnD+DejlJqK0UHLjNHAfVFr/SulVDL9+L0MiTAWQgghjmVD4TS1EEIIcUyTMBZCCCEiTMJYCCGEiDAJYyGEECLCJIyFEEKICJMwFkIIISJMwlgIIYSIMAljIYQQIsL+PwPC2pXHBZvbAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))  # historyはエポック毎のloss, accuracy, val_loss, val_accuracyを保持する\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # 縦の範囲を 0 から 1 までに\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この例では、訓練の開始時には検証セットでの成績の方が訓練セットでの成績よりも高いように見えるが、実際にはそうではない。検証誤差は各エポックの最後に計算されるのに対し、訓練誤差は各エポックの途中で移動平均を使って計算されている。そのため、訓練セットの曲線は、半エポック分左にずらすべきところなのである。\n",
    "\n",
    "実際にそうすると、訓練セットと検証セットの曲線は、訓練開始時にはほぼ完全に重なり合うこと\n",
    "がわかる~~らしいがやり方は分からない~~。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 62.1298 - accuracy: 0.8426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[62.12981414794922, 0.8425999879837036]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コールバック関数で保存した最高性能のモデルにロールバック\n",
    "model = keras.models.load_model('my_keras_sequential_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 51.7288 - accuracy: 0.8553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[51.72883605957031, 0.8553000092506409]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ロールバック後のモデルで再評価\n",
    "mse_test = model.evaluate(x_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルを使った予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== predict : probability ==========\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "========== predict : class ==========\n",
      "[9 2 1]\n",
      "['Ankle boot' 'Pullover' 'Trouser']\n"
     ]
    }
   ],
   "source": [
    "# サンプル用にデータサイズを限定\n",
    "x_new = x_test[:3]\n",
    "\n",
    "# 各クラスに分類される確率を出力する\n",
    "print('========== predict : probability ==========')\n",
    "y_proba = model.predict(x_new)\n",
    "print(y_proba.round(2))\n",
    "\n",
    "print('========== predict : class ==========')\n",
    "# y_pred = model.predict_classes(x_new)  # 廃止メソッドのよう\n",
    "y_pred = np.argmax(model.predict(x_new), axis=1)  # 確率最大のクラスを出力する\n",
    "print(y_pred)\n",
    "print(np.array(class_names)[y_pred])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像を表示して確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure fashion_mnist_images_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 518.4x172.8 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \"..\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "plt.figure(figsize=(7.2, 2.4))\n",
    "for index, image in enumerate(x_new):\n",
    "    plt.subplot(1, 3, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
    "    plt.axis('off')\n",
    "    plt.title(class_names[y_test[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "save_fig('fashion_mnist_images_plot', tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの保存と復元"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras は HDF5 形式を使ってモデルのアーキテクチャ（すべてのハイパーパラメータを含む）とすべての層のモデルパラメータの値（たとえば接続重みやバイアス）を保存する。\n",
    "さらに、オプティマイザ（ハイパーパラメータやその他の状態情報を含む）も保存する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_keras_sequential_classification_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 復元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('my_keras_sequential_classification_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回帰問題：sklearn.datasets.fetch_california_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パッケージインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow ver.2.8.0\n",
      "keras ver.2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense  # layerクラスを直接インポートして使用出来る\n",
    "\n",
    "##### これうまくいくはずなんだけど学習できてない #####\n",
    "from tensorflow.keras.losses import MeanSquaredError  # 損失関数クラスを直接インポートして使用出来る\n",
    "from tensorflow.keras.optimizers import SGD  # オプティマイザクラスを直接インポートして使用出来る\n",
    "##################################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(f'tensorflow ver.{tf.__version__}')\n",
    "print(f'keras ver.{keras.__version__}')\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  データロードと前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape : (11610, 8)\n",
      "y_train.shape : (11610,)\n",
      "x_valid.shape : (3870, 8)\n",
      "y_valid.shape : (3870,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_full, y_train_full)\n",
    "\n",
    "# データサイズを確認\n",
    "print(f'x_train.shape : {x_train.shape}')\n",
    "print(f'y_train.shape : {y_train.shape}')\n",
    "print(f'x_valid.shape : {x_valid.shape}')\n",
    "print(f'y_valid.shape : {y_valid.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainデータを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.7237</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.837607</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>323.0</td>\n",
       "      <td>2.760684</td>\n",
       "      <td>37.41</td>\n",
       "      <td>-122.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.6535</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.167647</td>\n",
       "      <td>1.067647</td>\n",
       "      <td>3193.0</td>\n",
       "      <td>3.130392</td>\n",
       "      <td>33.95</td>\n",
       "      <td>-118.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.9479</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.564151</td>\n",
       "      <td>1.266038</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>3.056604</td>\n",
       "      <td>34.55</td>\n",
       "      <td>-117.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.8295</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.938998</td>\n",
       "      <td>1.013072</td>\n",
       "      <td>1773.0</td>\n",
       "      <td>3.862745</td>\n",
       "      <td>34.44</td>\n",
       "      <td>-118.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.3893</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>316.0</td>\n",
       "      <td>2.925926</td>\n",
       "      <td>33.62</td>\n",
       "      <td>-117.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11605</th>\n",
       "      <td>3.5403</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.226244</td>\n",
       "      <td>1.162896</td>\n",
       "      <td>687.0</td>\n",
       "      <td>3.108597</td>\n",
       "      <td>33.91</td>\n",
       "      <td>-117.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11606</th>\n",
       "      <td>5.0524</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.187870</td>\n",
       "      <td>1.051775</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>1.810651</td>\n",
       "      <td>37.91</td>\n",
       "      <td>-122.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11607</th>\n",
       "      <td>3.7083</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.703604</td>\n",
       "      <td>1.063964</td>\n",
       "      <td>3419.0</td>\n",
       "      <td>3.080180</td>\n",
       "      <td>38.46</td>\n",
       "      <td>-121.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11608</th>\n",
       "      <td>3.5481</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.547511</td>\n",
       "      <td>1.013575</td>\n",
       "      <td>742.0</td>\n",
       "      <td>3.357466</td>\n",
       "      <td>34.13</td>\n",
       "      <td>-118.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11609</th>\n",
       "      <td>2.7583</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.080537</td>\n",
       "      <td>1.024609</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>2.514541</td>\n",
       "      <td>35.42</td>\n",
       "      <td>-119.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11610 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      10.7237      21.0  8.837607   1.000000       323.0  2.760684     37.41   \n",
       "1       2.6535      26.0  3.167647   1.067647      3193.0  3.130392     33.95   \n",
       "2       2.9479       5.0  5.564151   1.266038      1620.0  3.056604     34.55   \n",
       "3       4.8295      10.0  5.938998   1.013072      1773.0  3.862745     34.44   \n",
       "4      10.3893      18.0  6.750000   0.972222       316.0  2.925926     33.62   \n",
       "...        ...       ...       ...        ...         ...       ...       ...   \n",
       "11605   3.5403      36.0  6.226244   1.162896       687.0  3.108597     33.91   \n",
       "11606   5.0524      18.0  5.187870   1.051775      1224.0  1.810651     37.91   \n",
       "11607   3.7083      10.0  5.703604   1.063964      3419.0  3.080180     38.46   \n",
       "11608   3.5481      35.0  4.547511   1.013575       742.0  3.357466     34.13   \n",
       "11609   2.7583      42.0  5.080537   1.024609      1124.0  2.514541     35.42   \n",
       "\n",
       "       Longitude  \n",
       "0        -122.18  \n",
       "1        -118.36  \n",
       "2        -117.54  \n",
       "3        -118.13  \n",
       "4        -117.85  \n",
       "...          ...  \n",
       "11605    -117.90  \n",
       "11606    -122.38  \n",
       "11607    -121.82  \n",
       "11608    -118.00  \n",
       "11609    -119.02  \n",
       "\n",
       "[11610 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11610 entries, 0 to 11609\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   MedInc      11610 non-null  float64\n",
      " 1   HouseAge    11610 non-null  float64\n",
      " 2   AveRooms    11610 non-null  float64\n",
      " 3   AveBedrms   11610 non-null  float64\n",
      " 4   Population  11610 non-null  float64\n",
      " 5   AveOccup    11610 non-null  float64\n",
      " 6   Latitude    11610 non-null  float64\n",
      " 7   Longitude   11610 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 725.8 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.894098</td>\n",
       "      <td>28.682515</td>\n",
       "      <td>5.445182</td>\n",
       "      <td>1.097018</td>\n",
       "      <td>1423.704393</td>\n",
       "      <td>3.086505</td>\n",
       "      <td>35.619636</td>\n",
       "      <td>-119.563125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.926992</td>\n",
       "      <td>12.629721</td>\n",
       "      <td>2.675345</td>\n",
       "      <td>0.522784</td>\n",
       "      <td>1169.391033</td>\n",
       "      <td>12.452525</td>\n",
       "      <td>2.127324</td>\n",
       "      <td>2.007963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>32.560000</td>\n",
       "      <td>-124.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.565050</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.462816</td>\n",
       "      <td>1.006332</td>\n",
       "      <td>785.000000</td>\n",
       "      <td>2.435381</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>-121.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.551400</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.239784</td>\n",
       "      <td>1.048485</td>\n",
       "      <td>1163.000000</td>\n",
       "      <td>2.822018</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>-118.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.781300</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.058570</td>\n",
       "      <td>1.098736</td>\n",
       "      <td>1712.000000</td>\n",
       "      <td>3.274970</td>\n",
       "      <td>37.700000</td>\n",
       "      <td>-118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>34.066667</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>1243.333333</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.310000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
       "count  11610.000000  11610.000000  11610.000000  11610.000000  11610.000000   \n",
       "mean       3.894098     28.682515      5.445182      1.097018   1423.704393   \n",
       "std        1.926992     12.629721      2.675345      0.522784   1169.391033   \n",
       "min        0.499900      1.000000      0.888889      0.375000      3.000000   \n",
       "25%        2.565050     18.000000      4.462816      1.006332    785.000000   \n",
       "50%        3.551400     29.000000      5.239784      1.048485   1163.000000   \n",
       "75%        4.781300     37.000000      6.058570      1.098736   1712.000000   \n",
       "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
       "\n",
       "           AveOccup      Latitude     Longitude  \n",
       "count  11610.000000  11610.000000  11610.000000  \n",
       "mean       3.086505     35.619636   -119.563125  \n",
       "std       12.452525      2.127324      2.007963  \n",
       "min        0.692308     32.560000   -124.350000  \n",
       "25%        2.435381     33.930000   -121.810000  \n",
       "50%        2.822018     34.250000   -118.490000  \n",
       "75%        3.274970     37.700000   -118.000000  \n",
       "max     1243.333333     41.950000   -114.310000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_x_train = pd.DataFrame(x_train, columns=housing.feature_names)\n",
    "display(pd_x_train)\n",
    "pd_x_train.info()\n",
    "pd_x_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### スケーリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "データの標準化を行う。\n",
    "\n",
    "代表的なメソッドは以下：\n",
    "\n",
    "|メソッド|説明|\n",
    "|---|---|\n",
    "|fit()|標準化するための平均と分散を計算する。|\n",
    "|trasform()|（事前に計算した平均と分散を使用して）標準化を行う。|\n",
    "|fit_transform()|平均と分散を計算し、標準化を行う。|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_valid = scaler.transform(x_valid)  # x_trainの平均・分散を使用する（のはなぜ？）\n",
    "x_test = scaler.transform(x_test)  # x_trainの平均・分散を使用する（のはなぜ？）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### レイヤ構成を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期化時にレイヤのリストを渡すことでレイヤ定義も同時に行う\n",
    "model = keras.models.Sequential([\n",
    "    Dense(30, activation='relu', input_shape=x_train.shape[1:])\n",
    "    , Dense(1)  # 予測値を出力するため出力層のノード数は1\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルのコンパイル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 30)                270       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model.compile(loss=MeanSquaredError(), optimizer=SGD())  # なぜかこっちは学習結果がNaNになる\n",
    "# model.compile(loss=\"mean_squared_error\", optimizer=SGD())  # なぜか全然学習が進まない\n",
    "# model.compile(loss=MeanSquaredError(), optimizer='sgd')  # なぜか全然学習が進まない\n",
    "model.compile(loss=\"mean_squared_error\", optimizer='sgd')\n",
    "\n",
    "# モデルのレイヤ構成を表示\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習と評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コールバックによる学習中のチェックポイント保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回早期打ち切り設定を入れるためにEarlyStopping関数を使用する。<br>\n",
    "このコールバック関数は学習打ち切り時に性能が最高だった時の重みを自動で復元するかを選べる。これを使うと最良モデルの保存と復元は不要になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 早期打ち切りのコールバック関数\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)  # patienceで指定したエポック数学習が進まなかったときに学習を打ち切る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、コールバック関数は自作したものを使うことが出来る。<br>\n",
    "\n",
    "\n",
    "自作コールバックの作り方については以下を参照：<br>\n",
    "[TensorFlow.Kerasガイド_コールバックを書く](https://www.tensorflow.org/guide/keras/custom_callback?hl=ja)<br>\n",
    "以下のようなことが記載されている。\n",
    "* メソッド名と呼び出しタイミング\n",
    "\n",
    "|メソッドの種類|メソッド名|呼び出しタイミング|\n",
    "|-|-|-|\n",
    "|グローバルメソッド|on_(train/test/predict)_begin(self, logs=None)|fit/evalute/predictメソッドの先頭|\n",
    "||on_(train/test/predict)_end(self, logs=None)|fit/evaluate/predictメソッドの最後|\n",
    "|バッチレベルメソッド|on_(train/test/predict)_batch_begin(self, batch, logs=None)|トレーニング/テスト/予測の各バッチの直前|\n",
    "||on_(train/test/predict)_batch_end(self, batch, logs=None)|トレーニング/テスト/予測の各バッチの終了時|\n",
    "|エポックレベルメソッド|on_epoch_begin(self, epoch, logs=None)|トレーニングの各エポックの先頭|\n",
    "||on_epoch_end(self, epoch, logs=None)|トレーニングの各エポックの最後|\n",
    "\n",
    "* logs ディクショナリ<br>\n",
    "    →バッチまたはエポックの最後の損失値と全てのメトリクスを含む。これを利用して学習過程を出力したり早期打ち切りを実装したりできる。\n",
    "\n",
    "例として学習中の訓練データのlossとvalidationデータのlossの比率を表示する関数を作成する。（過学習を検知すること想定）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):  # トレーニングの各エポックの最後\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))  # logsディレクトリからval_lossとlossを取得\n",
    "\n",
    "print_valid_train_ration_cb = PrintValTrainRatioCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoardを使った可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoardを使って訓練中の学習曲線を表示したり、複数の実行の学習曲線を比較したり、計算グラフを表示したり、訓練の統計情報を解析したりすることが出来る。\n",
    "\n",
    "TensorBoardはコールバック関数として準備されている。<br>\n",
    "利用するにはイベントファイルと呼ばれるバイナリファイルを出力させる必要がある。\n",
    "\n",
    "また、TensorBoardサーバを立てる必要がある。<br>\n",
    "TensorBoardサーバはロートログディレクトリを参照し、プログラムには実行ごとに別のサブディレクトリをに出力するように設定する。こうすることで複数の実行から得た情報が混ざることなく使用することが出来る。\n",
    "\n",
    "ここでは実行ごとのログディレクトリ名を生成する関数を定義し、その関数を使って生成したログディレクトリ名をTensorBoardのコールバックに渡す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ログ出力のルートディレクトリ\n",
    "root_dir = os.path.join(os.curdir, 'my_logs')\n",
    "\n",
    "# ログディレクトリ名を生成する関数\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_dir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/363 [..............................] - ETA: 1:19 - loss: 8.1022WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0013s). Check your callbacks.\n",
      "349/363 [===========================>..] - ETA: 0s - loss: 0.9747\n",
      "val/train: 0.58\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9597 - val_loss: 0.5542\n",
      "Epoch 2/100\n",
      "356/363 [============================>.] - ETA: 0s - loss: 0.6194\n",
      "val/train: 0.78\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6185 - val_loss: 0.4850\n",
      "Epoch 3/100\n",
      "361/363 [============================>.] - ETA: 0s - loss: 0.4912\n",
      "val/train: 0.99\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4931 - val_loss: 0.4873\n",
      "Epoch 4/100\n",
      "357/363 [============================>.] - ETA: 0s - loss: 0.4948\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4937 - val_loss: 0.4573\n",
      "Epoch 5/100\n",
      "321/363 [=========================>....] - ETA: 0s - loss: 0.4873\n",
      "val/train: 0.90\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4794 - val_loss: 0.4329\n",
      "Epoch 6/100\n",
      "315/363 [=========================>....] - ETA: 0s - loss: 0.4509\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4513 - val_loss: 0.4177\n",
      "Epoch 7/100\n",
      "332/363 [==========================>...] - ETA: 0s - loss: 0.4564\n",
      "val/train: 0.94\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.4487 - val_loss: 0.4219\n",
      "Epoch 8/100\n",
      "308/363 [========================>.....] - ETA: 0s - loss: 0.4325\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4358 - val_loss: 0.4057\n",
      "Epoch 9/100\n",
      "326/363 [=========================>....] - ETA: 0s - loss: 0.4331\n",
      "val/train: 0.94\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4284 - val_loss: 0.4011\n",
      "Epoch 10/100\n",
      "316/363 [=========================>....] - ETA: 0s - loss: 0.4244\n",
      "val/train: 0.98\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4279 - val_loss: 0.4175\n",
      "Epoch 11/100\n",
      "332/363 [==========================>...] - ETA: 0s - loss: 0.4292\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.4280 - val_loss: 0.3956\n",
      "Epoch 12/100\n",
      "337/363 [==========================>...] - ETA: 0s - loss: 0.4211\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.4156 - val_loss: 0.3813\n",
      "Epoch 13/100\n",
      "361/363 [============================>.] - ETA: 0s - loss: 0.4163\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4161 - val_loss: 0.3827\n",
      "Epoch 14/100\n",
      "348/363 [===========================>..] - ETA: 0s - loss: 0.4072\n",
      "val/train: 0.94\n",
      "363/363 [==============================] - 0s 955us/step - loss: 0.4071 - val_loss: 0.3817\n",
      "Epoch 15/100\n",
      "348/363 [===========================>..] - ETA: 0s - loss: 0.4052\n",
      "val/train: 0.96\n",
      "363/363 [==============================] - 0s 957us/step - loss: 0.4048 - val_loss: 0.3886\n",
      "Epoch 16/100\n",
      "343/363 [===========================>..] - ETA: 0s - loss: 0.4042\n",
      "val/train: 0.94\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.4027 - val_loss: 0.3767\n",
      "Epoch 17/100\n",
      "352/363 [============================>.] - ETA: 0s - loss: 0.3948\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 947us/step - loss: 0.3954 - val_loss: 0.3663\n",
      "Epoch 18/100\n",
      "289/363 [======================>.......] - ETA: 0s - loss: 0.4003\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.3950 - val_loss: 0.3647\n",
      "Epoch 19/100\n",
      "297/363 [=======================>......] - ETA: 0s - loss: 0.4103\n",
      "val/train: 0.90\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.4080 - val_loss: 0.3672\n",
      "Epoch 20/100\n",
      "292/363 [=======================>......] - ETA: 0s - loss: 0.3964\n",
      "val/train: 1.06\n",
      "363/363 [==============================] - 0s 892us/step - loss: 0.4051 - val_loss: 0.4313\n",
      "Epoch 21/100\n",
      "348/363 [===========================>..] - ETA: 0s - loss: 0.4245\n",
      "val/train: 0.86\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.4218 - val_loss: 0.3644\n",
      "Epoch 22/100\n",
      "332/363 [==========================>...] - ETA: 0s - loss: 0.3930\n",
      "val/train: 0.91\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.3567\n",
      "Epoch 23/100\n",
      "346/363 [===========================>..] - ETA: 0s - loss: 0.3964\n",
      "val/train: 0.95\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3955 - val_loss: 0.3745\n",
      "Epoch 24/100\n",
      "334/363 [==========================>...] - ETA: 0s - loss: 0.4003\n",
      "val/train: 0.90\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4006 - val_loss: 0.3617\n",
      "Epoch 25/100\n",
      "321/363 [=========================>....] - ETA: 0s - loss: 0.3847\n",
      "val/train: 0.94\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3830 - val_loss: 0.3607\n",
      "Epoch 26/100\n",
      "300/363 [=======================>......] - ETA: 0s - loss: 0.3866\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.3549\n",
      "Epoch 27/100\n",
      "326/363 [=========================>....] - ETA: 0s - loss: 0.3859\n",
      "val/train: 0.91\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3838 - val_loss: 0.3496\n",
      "Epoch 28/100\n",
      "346/363 [===========================>..] - ETA: 0s - loss: 0.3803\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.3463\n",
      "Epoch 29/100\n",
      "338/363 [==========================>...] - ETA: 0s - loss: 0.3791\n",
      "val/train: 0.94\n",
      "363/363 [==============================] - 0s 962us/step - loss: 0.3746 - val_loss: 0.3503\n",
      "Epoch 30/100\n",
      "333/363 [==========================>...] - ETA: 0s - loss: 0.3757\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3731 - val_loss: 0.3449\n",
      "Epoch 31/100\n",
      "331/363 [==========================>...] - ETA: 0s - loss: 0.3701\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.3711 - val_loss: 0.3402\n",
      "Epoch 32/100\n",
      "335/363 [==========================>...] - ETA: 0s - loss: 0.3788\n",
      "val/train: 0.91\n",
      "363/363 [==============================] - 0s 961us/step - loss: 0.3799 - val_loss: 0.3456\n",
      "Epoch 33/100\n",
      "320/363 [=========================>....] - ETA: 0s - loss: 0.3701\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.3390\n",
      "Epoch 34/100\n",
      "324/363 [=========================>....] - ETA: 0s - loss: 0.3758\n",
      "val/train: 0.90\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3722 - val_loss: 0.3367\n",
      "Epoch 35/100\n",
      "319/363 [=========================>....] - ETA: 0s - loss: 0.3650\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.3378\n",
      "Epoch 36/100\n",
      "324/363 [=========================>....] - ETA: 0s - loss: 0.3681\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.3704 - val_loss: 0.3414\n",
      "Epoch 37/100\n",
      "314/363 [========================>.....] - ETA: 0s - loss: 0.3678\n",
      "val/train: 0.90\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.3336\n",
      "Epoch 38/100\n",
      "344/363 [===========================>..] - ETA: 0s - loss: 0.3625\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 941us/step - loss: 0.3616 - val_loss: 0.3364\n",
      "Epoch 39/100\n",
      "328/363 [==========================>...] - ETA: 0s - loss: 0.3581\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 975us/step - loss: 0.3647 - val_loss: 0.3365\n",
      "Epoch 40/100\n",
      "323/363 [=========================>....] - ETA: 0s - loss: 0.3640\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3609 - val_loss: 0.3332\n",
      "Epoch 41/100\n",
      "332/363 [==========================>...] - ETA: 0s - loss: 0.3595\n",
      "val/train: 0.98\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.3632 - val_loss: 0.3575\n",
      "Epoch 42/100\n",
      "330/363 [==========================>...] - ETA: 0s - loss: 0.3720\n",
      "val/train: 0.90\n",
      "363/363 [==============================] - 0s 969us/step - loss: 0.3733 - val_loss: 0.3351\n",
      "Epoch 43/100\n",
      "335/363 [==========================>...] - ETA: 0s - loss: 0.3637\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.3632 - val_loss: 0.3363\n",
      "Epoch 44/100\n",
      "336/363 [==========================>...] - ETA: 0s - loss: 0.3548\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3557 - val_loss: 0.3263\n",
      "Epoch 45/100\n",
      "313/363 [========================>.....] - ETA: 0s - loss: 0.3535\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.3257\n",
      "Epoch 46/100\n",
      "341/363 [===========================>..] - ETA: 0s - loss: 0.3514\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 953us/step - loss: 0.3544 - val_loss: 0.3263\n",
      "Epoch 47/100\n",
      "331/363 [==========================>...] - ETA: 0s - loss: 0.3480\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.3228\n",
      "Epoch 48/100\n",
      "306/363 [========================>.....] - ETA: 0s - loss: 0.3474\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3486 - val_loss: 0.3236\n",
      "Epoch 49/100\n",
      "333/363 [==========================>...] - ETA: 0s - loss: 0.3496\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 973us/step - loss: 0.3480 - val_loss: 0.3236\n",
      "Epoch 50/100\n",
      "345/363 [===========================>..] - ETA: 0s - loss: 0.3501\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 938us/step - loss: 0.3502 - val_loss: 0.3216\n",
      "Epoch 51/100\n",
      "344/363 [===========================>..] - ETA: 0s - loss: 0.3422\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 962us/step - loss: 0.3460 - val_loss: 0.3190\n",
      "Epoch 52/100\n",
      "326/363 [=========================>....] - ETA: 0s - loss: 0.3437\n",
      "val/train: 0.94\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3446 - val_loss: 0.3227\n",
      "Epoch 53/100\n",
      "330/363 [==========================>...] - ETA: 0s - loss: 0.3435\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 975us/step - loss: 0.3432 - val_loss: 0.3147\n",
      "Epoch 54/100\n",
      "328/363 [==========================>...] - ETA: 0s - loss: 0.3439\n",
      "val/train: 0.94\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.3426 - val_loss: 0.3209\n",
      "Epoch 55/100\n",
      "342/363 [===========================>..] - ETA: 0s - loss: 0.3403\n",
      "val/train: 0.91\n",
      "363/363 [==============================] - 0s 958us/step - loss: 0.3418 - val_loss: 0.3126\n",
      "Epoch 56/100\n",
      "297/363 [=======================>......] - ETA: 0s - loss: 0.3379\n",
      "val/train: 0.94\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3394 - val_loss: 0.3204\n",
      "Epoch 57/100\n",
      "328/363 [==========================>...] - ETA: 0s - loss: 0.3378\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.3389 - val_loss: 0.3138\n",
      "Epoch 58/100\n",
      "335/363 [==========================>...] - ETA: 0s - loss: 0.3426\n",
      "val/train: 0.94\n",
      "363/363 [==============================] - 0s 963us/step - loss: 0.3395 - val_loss: 0.3187\n",
      "Epoch 59/100\n",
      "339/363 [===========================>..] - ETA: 0s - loss: 0.3364\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 951us/step - loss: 0.3383 - val_loss: 0.3113\n",
      "Epoch 60/100\n",
      "354/363 [============================>.] - ETA: 0s - loss: 0.3407\n",
      "val/train: 0.95\n",
      "363/363 [==============================] - 0s 951us/step - loss: 0.3394 - val_loss: 0.3210\n",
      "Epoch 61/100\n",
      "326/363 [=========================>....] - ETA: 0s - loss: 0.3409\n",
      "val/train: 0.91\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3398 - val_loss: 0.3107\n",
      "Epoch 62/100\n",
      "337/363 [==========================>...] - ETA: 0s - loss: 0.3397\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 967us/step - loss: 0.3369 - val_loss: 0.3134\n",
      "Epoch 63/100\n",
      "341/363 [===========================>..] - ETA: 0s - loss: 0.3352\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 944us/step - loss: 0.3339 - val_loss: 0.3090\n",
      "Epoch 64/100\n",
      "348/363 [===========================>..] - ETA: 0s - loss: 0.3326\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 940us/step - loss: 0.3328 - val_loss: 0.3082\n",
      "Epoch 65/100\n",
      "336/363 [==========================>...] - ETA: 0s - loss: 0.3313\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.3317 - val_loss: 0.3094\n",
      "Epoch 66/100\n",
      "361/363 [============================>.] - ETA: 0s - loss: 0.3497\n",
      "val/train: 0.90\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.3497 - val_loss: 0.3141\n",
      "Epoch 67/100\n",
      "354/363 [============================>.] - ETA: 0s - loss: 0.3361\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 922us/step - loss: 0.3364 - val_loss: 0.3112\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.3322\n",
      "val/train: 0.94\n",
      "363/363 [==============================] - 0s 912us/step - loss: 0.3322 - val_loss: 0.3114\n",
      "Epoch 69/100\n",
      "360/363 [============================>.] - ETA: 0s - loss: 0.3319\n",
      "val/train: 0.95\n",
      "363/363 [==============================] - 0s 924us/step - loss: 0.3318 - val_loss: 0.3139\n",
      "Epoch 70/100\n",
      "360/363 [============================>.] - ETA: 0s - loss: 0.3306\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.3300 - val_loss: 0.3059\n",
      "Epoch 71/100\n",
      "334/363 [==========================>...] - ETA: 0s - loss: 0.3296\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 957us/step - loss: 0.3350 - val_loss: 0.3102\n",
      "Epoch 72/100\n",
      "351/363 [============================>.] - ETA: 0s - loss: 0.3355\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 930us/step - loss: 0.3320 - val_loss: 0.3080\n",
      "Epoch 73/100\n",
      "356/363 [============================>.] - ETA: 0s - loss: 0.3286\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 924us/step - loss: 0.3294 - val_loss: 0.3042\n",
      "Epoch 74/100\n",
      "321/363 [=========================>....] - ETA: 0s - loss: 0.3307\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.3287 - val_loss: 0.3069\n",
      "Epoch 75/100\n",
      "357/363 [============================>.] - ETA: 0s - loss: 0.3262\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3267 - val_loss: 0.3042\n",
      "Epoch 76/100\n",
      "353/363 [============================>.] - ETA: 0s - loss: 0.3267\n",
      "val/train: 0.94\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.3256 - val_loss: 0.3063\n",
      "Epoch 77/100\n",
      "325/363 [=========================>....] - ETA: 0s - loss: 0.3315\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.3258 - val_loss: 0.3040\n",
      "Epoch 78/100\n",
      "361/363 [============================>.] - ETA: 0s - loss: 0.3265\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 927us/step - loss: 0.3257 - val_loss: 0.3000\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.3250\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 910us/step - loss: 0.3250 - val_loss: 0.3034\n",
      "Epoch 80/100\n",
      "339/363 [===========================>..] - ETA: 0s - loss: 0.3261\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 948us/step - loss: 0.3253 - val_loss: 0.2991\n",
      "Epoch 81/100\n",
      "361/363 [============================>.] - ETA: 0s - loss: 0.3243\n",
      "val/train: 0.96\n",
      "363/363 [==============================] - 0s 932us/step - loss: 0.3243 - val_loss: 0.3116\n",
      "Epoch 82/100\n",
      "362/363 [============================>.] - ETA: 0s - loss: 0.3255\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.3254 - val_loss: 0.2998\n",
      "Epoch 83/100\n",
      "357/363 [============================>.] - ETA: 0s - loss: 0.3225\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 946us/step - loss: 0.3230 - val_loss: 0.2991\n",
      "Epoch 84/100\n",
      "356/363 [============================>.] - ETA: 0s - loss: 0.3224\n",
      "val/train: 0.93\n",
      "363/363 [==============================] - 0s 928us/step - loss: 0.3226 - val_loss: 0.2992\n",
      "Epoch 85/100\n",
      "356/363 [============================>.] - ETA: 0s - loss: 0.3232\n",
      "val/train: 0.95\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3225 - val_loss: 0.3060\n",
      "Epoch 86/100\n",
      "345/363 [===========================>..] - ETA: 0s - loss: 0.3230\n",
      "val/train: 0.94\n",
      "363/363 [==============================] - 0s 937us/step - loss: 0.3229 - val_loss: 0.3050\n",
      "Epoch 87/100\n",
      "303/363 [========================>.....] - ETA: 0s - loss: 0.3375\n",
      "val/train: 0.90\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3341 - val_loss: 0.3023\n",
      "Epoch 88/100\n",
      "362/363 [============================>.] - ETA: 0s - loss: 0.3318\n",
      "val/train: 0.92\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3319 - val_loss: 0.3047\n",
      "Epoch 89/100\n",
      "330/363 [==========================>...] - ETA: 0s - loss: 0.3193\n",
      "val/train: 0.94\n",
      "363/363 [==============================] - 0s 961us/step - loss: 0.3226 - val_loss: 0.3046\n",
      "Epoch 90/100\n",
      "323/363 [=========================>....] - ETA: 0s - loss: 0.3190\n",
      "val/train: 0.94\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.3217 - val_loss: 0.3011\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_valid), callbacks=[early_stopping_cb, print_valid_train_ration_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 59349), started 0:16:01 ago. (Use '!kill 59349' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-65bcef098b83513c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-65bcef098b83513c\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir ./my_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 713us/step - loss: 0.3482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34820038080215454"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(x_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルを使った予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict : [2.0469236 0.7469141 2.8435235]\n",
      "correct : [2.299 0.867 2.827]\n"
     ]
    }
   ],
   "source": [
    "# サンプル用にデータサイズを限定\n",
    "x_new = x_test[:3]\n",
    "\n",
    "y_pred = model.predict(x_new)\n",
    "print(f'predict : {y_pred.reshape(-1)}')\n",
    "print(f'correct : {y_test[:3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの保存と復元"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras は HDF5 形式を使ってモデルのアーキテクチャ（すべてのハイパーパラメータを含む）とすべての層のモデルパラメータの値（たとえば接続重みやバイアス）を保存する。\n",
    "さらに、オプティマイザ（ハイパーパラメータやその他の状態情報を含む）も保存する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_keras_sequential_regression_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 復元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('my_keras_sequential_regression_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.kaggle_')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2267c7f86544334f90fd828bd0d523f9563b963bbe28c7d2d8efd515b9a10ad6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
