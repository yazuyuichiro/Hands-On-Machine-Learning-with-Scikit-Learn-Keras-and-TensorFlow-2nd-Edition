{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KerasのSequential APIを使ったニューラルネットワークの構築例をまとめる。<br>\n",
    "分類問題と回帰問題の例をそれぞれ1モデル作成する。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類問題：Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fashion MNISTはファッション商品（写真）の画像データセットである。\n",
    "* ラベル「0」： T-shirt/top（Tシャツ／トップス）\n",
    "* ラベル「1」： Trouser（ズボン）\n",
    "* ラベル「2」： Pullover（プルオーバー、頭から被って着る服）\n",
    "* ラベル「3」： Dress（ドレス）\n",
    "* ラベル「4」： Coat（コート）\n",
    "* ラベル「5」： Sandal（サンダル）\n",
    "* ラベル「6」： Shirt（シャツ）\n",
    "* ラベル「7」： Sneaker（スニーカー）\n",
    "* ラベル「8」： Bag（バッグ）\n",
    "* ラベル「9」： Ankle boot（アンクルブーツ、かかとが隠れる丈のブーツ）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パッケージインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow ver.2.5.0\n",
      "keras ver.2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(f'tensorflow ver.{tf.__version__}')\n",
    "print(f'keras ver.{keras.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データロード及び前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_full, y_train_full), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape : (55000, 28, 28)\n",
      "y_train.shape : (55000,)\n",
      "x_valid.shape : (5000, 28, 28)\n",
      "y_valid.shape : (5000,)\n"
     ]
    }
   ],
   "source": [
    "valid_size = 5000\n",
    "x_valid, x_train = x_train_full[:valid_size], x_train_full[valid_size:]\n",
    "y_valid, y_train = y_train_full[:valid_size], y_train_full[valid_size:]\n",
    "\n",
    "print(f'x_train.shape : {x_train.shape}')\n",
    "print(f'y_train.shape : {y_train.shape}')\n",
    "print(f'x_valid.shape : {x_valid.shape}')\n",
    "print(f'y_valid.shape : {y_valid.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スケーリング0~255を0~1に変換する\n",
    "x_valid, x_train = x_valid/225.0, x_train/225.0\n",
    "\n",
    "# クラス名を定義（データ加工ではないが準備作業としてこちらに記載)\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "# サンプルで1枚目のクラウス名を出力\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### レイヤ構成を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequentialモデル生成\n",
    "model = keras.models.Sequential()\n",
    "# 平滑化層\n",
    "model.add(keras.layers.Flatten(input_shape=x_train.shape[1:]))\n",
    "# 全結合層\n",
    "model.add(keras.layers.Dense(units=300, activation='relu'))\n",
    "# 全結合層\n",
    "model.add(keras.layers.Dense(units=100, activation='relu'))\n",
    "# 全結合層（出力層）\n",
    "model.add(keras.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "# レイヤ構成を表示\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ※モデルの直接操作することもできる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レイヤを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x1fb78c00448>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1fb78c07b88>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1fb7f0eaa08>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1fb7f0ea388>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第1中間レイヤのパラメータを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00764104  0.01126886 -0.00599259 ... -0.01770302  0.01980142\n",
      "   0.05940279]\n",
      " [-0.02537611 -0.03946541 -0.00996497 ...  0.06723717 -0.00879716\n",
      "   0.07436714]\n",
      " [ 0.06061147  0.03658877 -0.02140393 ... -0.06959631 -0.02907168\n",
      "   0.04009003]\n",
      " [-0.0009442  -0.07339472  0.03956322 ... -0.05585682  0.06150056\n",
      "   0.01342092]\n",
      " [ 0.01838857 -0.06732468  0.00936014 ...  0.01951755 -0.06311397\n",
      "  -0.00020175]]\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "hidden_1_weights, hidden_1_biases = model.layers[1].get_weights()\n",
    "print(hidden_1_weights[:5])\n",
    "print(hidden_1_biases[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第1中間レイヤのパラメータを設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 重みとバイアスをすべて1に設定\n",
    "model.layers[1].set_weights([np.ones_like(model.layers[1].get_weights()[0]), np.ones_like(model.layers[1].get_weights()[1])])\n",
    "print(model.layers[1].get_weights()[0][:5])\n",
    "print(model.layers[1].get_weights()[1][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00764104  0.01126886 -0.00599259 ... -0.01770302  0.01980142\n",
      "   0.05940279]\n",
      " [-0.02537611 -0.03946541 -0.00996497 ...  0.06723717 -0.00879716\n",
      "   0.07436714]\n",
      " [ 0.06061147  0.03658877 -0.02140393 ... -0.06959631 -0.02907168\n",
      "   0.04009003]\n",
      " [-0.0009442  -0.07339472  0.03956322 ... -0.05585682  0.06150056\n",
      "   0.01342092]\n",
      " [ 0.01838857 -0.06732468  0.00936014 ...  0.01951755 -0.06311397\n",
      "  -0.00020175]]\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 重みとバイアスを元に戻す\n",
    "model.layers[1].set_weights([hidden_1_weights, hidden_1_biases])\n",
    "print(model.layers[1].get_weights()[0][:5])\n",
    "print(model.layers[1].get_weights()[1][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルのコンパイル\n",
    "モデルの学習プロセスを設定する。<br>\n",
    "ここで損失関数、オプティマイザ、評価関数を指定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [損失関数](https://keras.io/api/losses/)\n",
    "こちらも参考：[tf.keras.losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses)\n",
    "\n",
    "|分類|キー|損失関数名|説明|\n",
    "|-|-|-|-|\n",
    "|確率的<br>損失関数|binary_crossentropy|2値交差エントロピー|2値分類問題で使用|\n",
    "||categorical_crossentropy|カテゴリカル交差エントロピー|多クラス分類問題で使用。使用する場合はラベルがone-hot表現である必要がある。|\n",
    "||sparse_categorical_crossentropy|スパースカテゴリカル交差エントロピー|多クラス分類問題で使用。基本はカテゴリカル交差エントロピーと同じだが、スパースな？ラベルを取る点が異なる。使用するにはラベルと出力の次元が同じである必要がある。|\n",
    "||KLdivergence|KLダイバージェンス|予測した確率分布と真の確率分布との分布の距離|\n",
    "||poisson|ピアソン損失|予測値-正解値*log(予測値)の平均|\n",
    "|回帰損失関数|mean_squared_error|平均二乗誤差|2点間の距離の平均。スケールが2乗になる。|\n",
    "||mean_absolute_error|平均絶対誤差|差の絶対値の平均|\n",
    "||mean_absolute_percentage_error|平均絶対パーセント誤差|パーセント誤差（=(予測値-正解値)/正解値）の絶対値の平均。正解に対して何パーセント誤差があるかを測る指標として用いる。|\n",
    "||mean_squared_logarithmic_error|平均二乗対数誤差|予測値と正解値の対数の平均二乗誤差。対数の引き算は割り算に変換できるため、予測値/正解値を測る指標と解釈できる。|\n",
    "||logcosh|||\n",
    "||cosine_similarity|||\n",
    "||huber|||\n",
    "|最大マージンの<br>ヒンジ損失関数|hinge|||\n",
    "||squared_hinge|||\n",
    "||categorical_hinge|||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [オプティマイザ](https://keras.io/ja/losses/)\n",
    "こちらも参考：[tf.keras.optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)\n",
    "\n",
    "|オプティマイザ|説明|\n",
    "|-|-|\n",
    "|SGD|確率的勾配降下法。モーメンタム，学習率減衰，Nesterov momentumをサポートしている。|\n",
    "|RMSprop|RNNと好相性らしい。|\n",
    "|Adagrad||\n",
    "|Adadelta||\n",
    "|Adam|RMSPropとmomumtumを組み合わせたもの。|\n",
    "|Adamax|無限ノルムに基づく拡張版Adamらしい。|\n",
    "|Nadam|RMSPropとNesterov momentumを組み合わせたもの。|\n",
    "|Ftrl||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [評価関数](https://keras.io/api/metrics/)\n",
    "こちらも参考：[tf.keras.metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)\n",
    "\n",
    "|分類|クラス名|説明|\n",
    "|-|-|-|\n",
    "|正解率|Accuracy||\n",
    "||BinaryAccuracy||\n",
    "||CategoricalAccuracy||\n",
    "||SparseCategoricalAccuracy||\n",
    "||TopKCategoricalAccuracy||\n",
    "||SparseTopKCategoricalAccuracy||\n",
    "|確率|BinaryCrossentropy||\n",
    "||CategoricalCrossentropy||\n",
    "||SparseCategoricalCrossentropy||\n",
    "||KLDivergence||\n",
    "||Poisson||\n",
    "|回帰|MeanSquaredError||\n",
    "||RootMeanSquaredError||\n",
    "||MeanAbsoluteError||\n",
    "||MeanAbsolutePercentageError||\n",
    "||MeanSquaredLogarithmicError||\n",
    "||CosineSimilarity||\n",
    "||LogCoshError||\n",
    "|正誤問題に基づく分類|AUC||\n",
    "||Precision||\n",
    "||Recall||\n",
    "||TruePositives||\n",
    "||TrueNegatives||\n",
    "||FalsePositives||\n",
    "||FalseNegatives||\n",
    "||PrecisionAtRecall||\n",
    "||SensitivityAtSpecificity||\n",
    "||SpecificityAtSensitivity||\n",
    "|画像セグメンテーション|MeanIoU||\n",
    "|最大マージンのヒンジ分類|Hinge||\n",
    "||SquaredHinge||\n",
    "||CategoricalHinge||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習と評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コールバックによる学習中のチェックポイント保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コールバックは訓練中で適用される関数の集合である。\n",
    "訓練中にモデル内部の状態と統計量を可視化するためにコールバックを使う。\n",
    "\n",
    "SequentialとModelクラスの.fit()メソッドに（キーワード引数callbacksとして）コールバックのリストを渡すことができる。<br>\n",
    "これを使って学習中のチェックポイントを保存することが出来る。\n",
    "\n",
    "大規模データや層が深いモデルを扱うときには学習に時間がかかるため、google colabなどクラウド実行時にセッションが切れてしまうような場合にこのような設定が有効である。\n",
    "\n",
    "今回はsave_best_only=Trueとしてvalidationに対して性能が最高のモデルの時に保存する（早期打ち切り）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各エポック終了時のモデルを保存するコールバック関数\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_sequential_classification_model.h5', save_best_only=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0937 - accuracy: 0.9639 - val_loss: 0.4451 - val_accuracy: 0.8998\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0821 - accuracy: 0.9683 - val_loss: 0.4516 - val_accuracy: 0.9026\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0787 - accuracy: 0.9703 - val_loss: 0.4582 - val_accuracy: 0.9012\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.0765 - accuracy: 0.9710 - val_loss: 0.4596 - val_accuracy: 0.9036\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0746 - accuracy: 0.9710 - val_loss: 0.4666 - val_accuracy: 0.9016\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0731 - accuracy: 0.9724 - val_loss: 0.4717 - val_accuracy: 0.9032\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.0719 - accuracy: 0.9724 - val_loss: 0.4750 - val_accuracy: 0.9018\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0711 - accuracy: 0.9730 - val_loss: 0.4783 - val_accuracy: 0.9012\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0699 - accuracy: 0.9733 - val_loss: 0.4821 - val_accuracy: 0.9022\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0691 - accuracy: 0.9745 - val_loss: 0.4842 - val_accuracy: 0.9034\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0681 - accuracy: 0.9741 - val_loss: 0.4863 - val_accuracy: 0.9040\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0673 - accuracy: 0.9746 - val_loss: 0.4903 - val_accuracy: 0.9018\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0666 - accuracy: 0.9747 - val_loss: 0.4954 - val_accuracy: 0.9030\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0658 - accuracy: 0.9752 - val_loss: 0.4956 - val_accuracy: 0.9032\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0653 - accuracy: 0.9752 - val_loss: 0.4980 - val_accuracy: 0.9032\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0646 - accuracy: 0.9758 - val_loss: 0.4986 - val_accuracy: 0.9020\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0639 - accuracy: 0.9761 - val_loss: 0.5078 - val_accuracy: 0.9026\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0631 - accuracy: 0.9765 - val_loss: 0.5092 - val_accuracy: 0.9028\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0626 - accuracy: 0.9765 - val_loss: 0.5138 - val_accuracy: 0.9022\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0621 - accuracy: 0.9765 - val_loss: 0.5159 - val_accuracy: 0.9010\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0614 - accuracy: 0.9773 - val_loss: 0.5240 - val_accuracy: 0.9032\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0608 - accuracy: 0.9773 - val_loss: 0.5246 - val_accuracy: 0.9028\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0603 - accuracy: 0.9778 - val_loss: 0.5268 - val_accuracy: 0.9020\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0596 - accuracy: 0.9775 - val_loss: 0.5305 - val_accuracy: 0.9016\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0592 - accuracy: 0.9778 - val_loss: 0.5352 - val_accuracy: 0.9022\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0585 - accuracy: 0.9781 - val_loss: 0.5350 - val_accuracy: 0.9032\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0581 - accuracy: 0.9783 - val_loss: 0.5365 - val_accuracy: 0.9018\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0576 - accuracy: 0.9787 - val_loss: 0.5407 - val_accuracy: 0.9020\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0570 - accuracy: 0.9789 - val_loss: 0.5465 - val_accuracy: 0.9046\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0566 - accuracy: 0.9789 - val_loss: 0.5425 - val_accuracy: 0.9014\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=30, validation_data=(x_valid, y_valid), callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))  # historyはエポック毎のloss, accuracy, val_loss, val_accuracyを保持する\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # 縦の範囲を 0 から 1 までに\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この例では、訓練の開始時には検証セットでの成績の方が訓練セットでの成績よりも高いように見えるが、実際にはそうではない。検証誤差は各エポックの最後に計算されるのに対し、訓練誤差は各エポックの途中で移動平均を使って計算されている。そのため、訓練セットの曲線は、半エポック分左にずらすべきところなのである。\n",
    "\n",
    "実際にそうすると、訓練セットと検証セットの曲線は、訓練開始時にはほぼ完全に重なり合うこと\n",
    "がわかる~~らしいがやり方は分からない~~。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 78.4538 - accuracy: 0.8826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[78.45384216308594, 0.8826000094413757]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コールバック関数で保存した最高性能のモデルにロールバック\n",
    "model = keras.models.load_model('my_keras_sequential_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 47.5977 - accuracy: 0.8630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[47.59771728515625, 0.8629999756813049]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ロールバック後のモデルで再評価\n",
    "mse_test = model.evaluate(x_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルを使った予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== predict : probability ==========\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "========== predict : class ==========\n",
      "[9 2 1]\n",
      "['Ankle boot' 'Pullover' 'Trouser']\n"
     ]
    }
   ],
   "source": [
    "# サンプル用にデータサイズを限定\n",
    "x_new = x_test[:3]\n",
    "\n",
    "# 各クラスに分類される確率を出力する\n",
    "print('========== predict : probability ==========')\n",
    "y_proba = model.predict(x_new)\n",
    "print(y_proba.round(2))\n",
    "\n",
    "print('========== predict : class ==========')\n",
    "# y_pred = model.predict_classes(x_new)  # 廃止メソッドのよう\n",
    "y_pred = np.argmax(model.predict(x_new), axis=1)  # 確率最大のクラスを出力する\n",
    "print(y_pred)\n",
    "print(np.array(class_names)[y_pred])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像を表示して確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure fashion_mnist_images_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 518.4x172.8 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \"..\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "plt.figure(figsize=(7.2, 2.4))\n",
    "for index, image in enumerate(x_new):\n",
    "    plt.subplot(1, 3, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
    "    plt.axis('off')\n",
    "    plt.title(class_names[y_test[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "save_fig('fashion_mnist_images_plot', tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの保存と復元"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras は HDF5 形式を使ってモデルのアーキテクチャ（すべてのハイパーパラメータを含む）とすべての層のモデルパラメータの値（たとえば接続重みやバイアス）を保存する。\n",
    "さらに、オプティマイザ（ハイパーパラメータやその他の状態情報を含む）も保存する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_keras_sequential_classification_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 復元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('my_keras_sequential_classification_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回帰問題：sklearn.datasets.fetch_california_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パッケージインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow ver.2.5.0\n",
      "keras ver.2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense  # layerクラスを直接インポートして使用出来る\n",
    "\n",
    "##### これうまくいくはずなんだけど学習できてない #####\n",
    "from tensorflow.keras.losses import MeanSquaredError  # 損失関数クラスを直接インポートして使用出来る\n",
    "from tensorflow.keras.optimizers import SGD  # オプティマイザクラスを直接インポートして使用出来る\n",
    "##################################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(f'tensorflow ver.{tf.__version__}')\n",
    "print(f'keras ver.{keras.__version__}')\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  データロードと前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape : (11610, 8)\n",
      "y_train.shape : (11610,)\n",
      "x_valid.shape : (3870, 8)\n",
      "y_valid.shape : (3870,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_full, y_train_full)\n",
    "\n",
    "# データサイズを確認\n",
    "print(f'x_train.shape : {x_train.shape}')\n",
    "print(f'y_train.shape : {y_train.shape}')\n",
    "print(f'x_valid.shape : {x_valid.shape}')\n",
    "print(f'y_valid.shape : {y_valid.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainデータを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5882</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.568627</td>\n",
       "      <td>2.788235</td>\n",
       "      <td>658.0</td>\n",
       "      <td>2.580392</td>\n",
       "      <td>33.71</td>\n",
       "      <td>-116.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.2303</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.090239</td>\n",
       "      <td>1.116022</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>3.029466</td>\n",
       "      <td>37.80</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.5078</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.510703</td>\n",
       "      <td>1.003058</td>\n",
       "      <td>806.0</td>\n",
       "      <td>2.464832</td>\n",
       "      <td>32.83</td>\n",
       "      <td>-117.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.7955</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.442424</td>\n",
       "      <td>1.151515</td>\n",
       "      <td>939.0</td>\n",
       "      <td>2.845455</td>\n",
       "      <td>38.69</td>\n",
       "      <td>-122.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.1064</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6.233818</td>\n",
       "      <td>1.001321</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>2.615588</td>\n",
       "      <td>37.51</td>\n",
       "      <td>-122.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11605</th>\n",
       "      <td>3.1403</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.541756</td>\n",
       "      <td>0.929336</td>\n",
       "      <td>1843.0</td>\n",
       "      <td>3.946467</td>\n",
       "      <td>33.74</td>\n",
       "      <td>-117.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11606</th>\n",
       "      <td>3.1563</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.109966</td>\n",
       "      <td>1.017182</td>\n",
       "      <td>863.0</td>\n",
       "      <td>2.965636</td>\n",
       "      <td>33.94</td>\n",
       "      <td>-118.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11607</th>\n",
       "      <td>1.6540</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.534307</td>\n",
       "      <td>1.197080</td>\n",
       "      <td>2971.0</td>\n",
       "      <td>4.337226</td>\n",
       "      <td>33.53</td>\n",
       "      <td>-116.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11608</th>\n",
       "      <td>3.7232</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.353474</td>\n",
       "      <td>1.018127</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>3.725076</td>\n",
       "      <td>33.76</td>\n",
       "      <td>-117.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11609</th>\n",
       "      <td>3.3177</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.459829</td>\n",
       "      <td>1.013675</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>1.803419</td>\n",
       "      <td>34.16</td>\n",
       "      <td>-118.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11610 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge   AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      3.5882      21.0  13.568627   2.788235       658.0  2.580392     33.71   \n",
       "1      2.2303      36.0   3.090239   1.116022      1645.0  3.029466     37.80   \n",
       "2      3.5078      36.0   4.510703   1.003058       806.0  2.464832     32.83   \n",
       "3      2.7955      23.0   5.442424   1.151515       939.0  2.845455     38.69   \n",
       "4      6.1064      33.0   6.233818   1.001321      1980.0  2.615588     37.51   \n",
       "...       ...       ...        ...        ...         ...       ...       ...   \n",
       "11605  3.1403      30.0   3.541756   0.929336      1843.0  3.946467     33.74   \n",
       "11606  3.1563      37.0   5.109966   1.017182       863.0  2.965636     33.94   \n",
       "11607  1.6540      17.0   3.534307   1.197080      2971.0  4.337226     33.53   \n",
       "11608  3.7232      33.0   4.353474   1.018127      1233.0  3.725076     33.76   \n",
       "11609  3.3177      46.0   4.459829   1.013675      1055.0  1.803419     34.16   \n",
       "\n",
       "       Longitude  \n",
       "0        -116.68  \n",
       "1        -122.25  \n",
       "2        -117.21  \n",
       "3        -122.03  \n",
       "4        -122.28  \n",
       "...          ...  \n",
       "11605    -117.93  \n",
       "11606    -118.32  \n",
       "11607    -116.12  \n",
       "11608    -117.94  \n",
       "11609    -118.38  \n",
       "\n",
       "[11610 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11610 entries, 0 to 11609\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   MedInc      11610 non-null  float64\n",
      " 1   HouseAge    11610 non-null  float64\n",
      " 2   AveRooms    11610 non-null  float64\n",
      " 3   AveBedrms   11610 non-null  float64\n",
      " 4   Population  11610 non-null  float64\n",
      " 5   AveOccup    11610 non-null  float64\n",
      " 6   Latitude    11610 non-null  float64\n",
      " 7   Longitude   11610 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 725.8 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11610.00000</td>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.85980</td>\n",
       "      <td>28.816193</td>\n",
       "      <td>5.425840</td>\n",
       "      <td>1.097243</td>\n",
       "      <td>1429.844789</td>\n",
       "      <td>3.115970</td>\n",
       "      <td>35.646934</td>\n",
       "      <td>-119.584694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.90188</td>\n",
       "      <td>12.647223</td>\n",
       "      <td>2.516702</td>\n",
       "      <td>0.450671</td>\n",
       "      <td>1132.545251</td>\n",
       "      <td>12.638810</td>\n",
       "      <td>2.136022</td>\n",
       "      <td>2.003952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.49990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>32.550000</td>\n",
       "      <td>-124.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.56030</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.429497</td>\n",
       "      <td>1.006270</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>2.426122</td>\n",
       "      <td>33.940000</td>\n",
       "      <td>-121.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.52135</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.213486</td>\n",
       "      <td>1.049261</td>\n",
       "      <td>1168.000000</td>\n",
       "      <td>2.816995</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>-118.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.71850</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.047830</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1721.000000</td>\n",
       "      <td>3.285622</td>\n",
       "      <td>37.720000</td>\n",
       "      <td>-118.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.00010</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>25.636364</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>1243.333333</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.310000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
       "count  11610.00000  11610.000000  11610.000000  11610.000000  11610.000000   \n",
       "mean       3.85980     28.816193      5.425840      1.097243   1429.844789   \n",
       "std        1.90188     12.647223      2.516702      0.450671   1132.545251   \n",
       "min        0.49990      1.000000      0.846154      0.500000      8.000000   \n",
       "25%        2.56030     18.000000      4.429497      1.006270    793.000000   \n",
       "50%        3.52135     29.000000      5.213486      1.049261   1168.000000   \n",
       "75%        4.71850     37.000000      6.047830      1.100000   1721.000000   \n",
       "max       15.00010     52.000000    141.909091     25.636364  35682.000000   \n",
       "\n",
       "           AveOccup      Latitude     Longitude  \n",
       "count  11610.000000  11610.000000  11610.000000  \n",
       "mean       3.115970     35.646934   -119.584694  \n",
       "std       12.638810      2.136022      2.003952  \n",
       "min        0.970588     32.550000   -124.350000  \n",
       "25%        2.426122     33.940000   -121.810000  \n",
       "50%        2.816995     34.260000   -118.510000  \n",
       "75%        3.285622     37.720000   -118.020000  \n",
       "max     1243.333333     41.950000   -114.310000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_x_train = pd.DataFrame(x_train, columns=housing.feature_names)\n",
    "display(pd_x_train)\n",
    "pd_x_train.info()\n",
    "pd_x_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### スケーリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "データの標準化を行う。\n",
    "\n",
    "代表的なメソッドは以下：\n",
    "\n",
    "|メソッド|説明|\n",
    "|---|---|\n",
    "|fit()|標準化するための平均と分散を計算する。|\n",
    "|trasform()|（事前に計算した平均と分散を使用して）標準化を行う。|\n",
    "|fit_transform()|平均と分散を計算し、標準化を行う。|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_valid = scaler.transform(x_valid)  # x_trainの平均・分散を使用する（のはなぜ？）\n",
    "x_test = scaler.transform(x_test)  # x_trainの平均・分散を使用する（のはなぜ？）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### レイヤ構成を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期化時にレイヤのリストを渡すことでレイヤ定義も同時に行う\n",
    "model = keras.models.Sequential([\n",
    "    Dense(30, activation='relu', input_shape=x_train.shape[1:])\n",
    "    , Dense(1)  # 予測値を出力するため出力層のノード数は1\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルのコンパイル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model.compile(loss=MeanSquaredError(), optimizer=SGD())  # なぜかこっちは学習結果がNaNになる\n",
    "# model.compile(loss=\"mean_squared_error\", optimizer=SGD())  # なぜか全然学習が進まない\n",
    "# model.compile(loss=MeanSquaredError(), optimizer='sgd')  # なぜか全然学習が進まない\n",
    "model.compile(loss=\"mean_squared_error\", optimizer='sgd')\n",
    "\n",
    "# モデルのレイヤ構成を表示\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習と評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コールバックによる学習中のチェックポイント保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回早期打ち切り設定を入れるためにEarlyStopping関数を使用する。<br>\n",
    "このコールバック関数は学習打ち切り時に性能が最高だった時の重みを自動で復元するかを選べる。これを使うと最良モデルの保存と復元は不要になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 早期打ち切りのコールバック関数\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)  # patienceで指定したエポック数学習が進まなかったときに学習を打ち切る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、コールバック関数は自作したものを使うことが出来る。<br>\n",
    "\n",
    "\n",
    "自作コールバックの作り方については以下を参照：<br>\n",
    "[TensorFlow.Kerasガイド_コールバックを書く](https://www.tensorflow.org/guide/keras/custom_callback?hl=ja)<br>\n",
    "以下のようなことが記載されている。\n",
    "* メソッド名と呼び出しタイミング\n",
    "\n",
    "|メソッドの種類|メソッド名|呼び出しタイミング|\n",
    "|-|-|-|\n",
    "|グローバルメソッド|on_(train/test/predict)_begin(self, logs=None)|fit/evalute/predictメソッドの先頭|\n",
    "||on_(train/test/predict)_end(self, logs=None)|fit/evaluate/predictメソッドの最後|\n",
    "|バッチレベルメソッド|on_(train/test/predict)_batch_begin(self, batch, logs=None)|トレーニング/テスト/予測の各バッチの直前|\n",
    "||on_(train/test/predict)_batch_end(self, batch, logs=None)|トレーニング/テスト/予測の各バッチの終了時|\n",
    "|エポックレベルメソッド|on_epoch_begin(self, epoch, logs=None)|トレーニングの各エポックの先頭|\n",
    "||on_epoch_end(self, epoch, logs=None)|トレーニングの各エポックの最後|\n",
    "\n",
    "* logs ディクショナリ<br>\n",
    "    →バッチまたはエポックの最後の損失値と全てのメトリクスを含む。これを利用して学習過程を出力したり早期打ち切りを実装したりできる。\n",
    "\n",
    "例として学習中の訓練データのlossとvalidationデータのlossの比率を表示する関数を作成する。（過学習を検知すること想定）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):  # トレーニングの各エポックの最後\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))  # logsディレクトリからval_lossとlossを取得\n",
    "\n",
    "print_valid_train_ration_cb = PrintValTrainRatioCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoardを使った可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoardを使って訓練中の学習曲線を表示したり、複数の実行の学習曲線を比較したり、計算グラフを表示したり、訓練の統計情報を解析したりすることが出来る。\n",
    "\n",
    "TensorBoardはコールバック関数として準備されている。<br>\n",
    "利用するにはイベントファイルと呼ばれるバイナリファイルを出力させる必要がある。\n",
    "\n",
    "また、TensorBoardサーバを立てる必要がある。<br>\n",
    "TensorBoardサーバはロートログディレクトリを参照し、プログラムには実行ごとに別のサブディレクトリをに出力するように設定する。こうすることで複数の実行から得た情報が混ざることなく使用することが出来る。\n",
    "\n",
    "ここでは実行ごとのログディレクトリ名を生成する関数を定義し、その関数を使って生成したログディレクトリ名をTensorBoardのコールバックに渡す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ログ出力のルートディレクトリ\n",
    "root_dir = os.path.join(os.curdir, 'my_logs')\n",
    "\n",
    "# ログディレクトリ名を生成する関数\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_dir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  3/363 [..............................] - ETA: 17s - loss: 4.7403 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0012s vs `on_train_batch_end` time: 0.0151s). Check your callbacks.\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8130 - val_loss: 0.5553\n",
      "\n",
      "val/train: 0.68\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 941us/step - loss: 0.5431 - val_loss: 0.4908\n",
      "\n",
      "val/train: 0.90\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 785us/step - loss: 0.4972 - val_loss: 0.4716\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 922us/step - loss: 0.4983 - val_loss: 0.4611\n",
      "\n",
      "val/train: 0.93\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4485 - val_loss: 0.4429\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 782us/step - loss: 0.4572 - val_loss: 0.4510\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 716us/step - loss: 0.4586 - val_loss: 0.4293\n",
      "\n",
      "val/train: 0.94\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4219 - val_loss: 0.4251\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 822us/step - loss: 0.4134 - val_loss: 0.4188\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 830us/step - loss: 0.4092 - val_loss: 0.4155\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 778us/step - loss: 0.4026 - val_loss: 0.4080\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 718us/step - loss: 0.4018 - val_loss: 0.4101\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 925us/step - loss: 0.3941 - val_loss: 0.4022\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 778us/step - loss: 0.3894 - val_loss: 0.4004\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.3899 - val_loss: 0.4002\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 769us/step - loss: 0.3842 - val_loss: 0.3922\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 706us/step - loss: 0.3843 - val_loss: 0.3990\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 707us/step - loss: 0.3799 - val_loss: 0.3909\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 760us/step - loss: 0.4366 - val_loss: 0.3919\n",
      "\n",
      "val/train: 0.90\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.3973\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 917us/step - loss: 0.3750 - val_loss: 0.3920\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.4135 - val_loss: 0.3892\n",
      "\n",
      "val/train: 0.94\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 817us/step - loss: 0.3756 - val_loss: 0.3886\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.3878\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 838us/step - loss: 0.3686 - val_loss: 0.3881\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 975us/step - loss: 0.3670 - val_loss: 0.3962\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 903us/step - loss: 0.3667 - val_loss: 0.3780\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3693 - val_loss: 0.3868\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3654 - val_loss: 0.3854\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.3654 - val_loss: 0.3794\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 947us/step - loss: 0.3936 - val_loss: 0.3768\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.3606 - val_loss: 0.3767\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.3744\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3598 - val_loss: 0.3863\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3576 - val_loss: 0.3774\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3656 - val_loss: 0.3775\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3552 - val_loss: 0.3777\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.3714\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3568 - val_loss: 0.3680\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3530 - val_loss: 0.3686\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.3678\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3629 - val_loss: 0.3814\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3619 - val_loss: 0.3674\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3512 - val_loss: 0.3663\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 980us/step - loss: 0.3478 - val_loss: 0.3766\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.3671\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3463 - val_loss: 0.3676\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3426 - val_loss: 0.3735\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.3614\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 872us/step - loss: 0.3489 - val_loss: 0.3730\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 832us/step - loss: 0.3445 - val_loss: 0.3664\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.3502 - val_loss: 0.3634\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.3439 - val_loss: 0.3623\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 820us/step - loss: 0.3412 - val_loss: 0.3588\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 841us/step - loss: 0.3403 - val_loss: 0.3611\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3689 - val_loss: 0.3610\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3478 - val_loss: 0.3589\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.3613\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3496 - val_loss: 0.3581\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3378 - val_loss: 0.3616\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.3547\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3365 - val_loss: 0.3567\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3395 - val_loss: 0.3725\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.3554\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.3353 - val_loss: 0.3556\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.3444 - val_loss: 0.3586\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 943us/step - loss: 0.3354 - val_loss: 0.4668\n",
      "\n",
      "val/train: 1.39\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3357 - val_loss: 0.5203\n",
      "\n",
      "val/train: 1.55\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.3582 - val_loss: 0.3508\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3321 - val_loss: 0.3496\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.3531\n",
      "\n",
      "val/train: 0.89\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3330 - val_loss: 0.3763\n",
      "\n",
      "val/train: 1.13\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.3419 - val_loss: 0.3520\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3401 - val_loss: 0.3503\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3338 - val_loss: 0.3567\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3304 - val_loss: 0.3480\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3397 - val_loss: 0.3500\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3509 - val_loss: 0.3494\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3315 - val_loss: 0.3548\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3270 - val_loss: 0.3477\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 0.3564\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3318 - val_loss: 0.3454\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 0.3495\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 0.3476\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.3466\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3251 - val_loss: 0.3409\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3247 - val_loss: 0.3407\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3217 - val_loss: 0.3412\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3251 - val_loss: 0.3447\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3203 - val_loss: 0.3432\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3291 - val_loss: 0.3432\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3638 - val_loss: 0.3413\n",
      "\n",
      "val/train: 0.94\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3205 - val_loss: 0.3396\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3202 - val_loss: 0.3382\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3183 - val_loss: 0.3385\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3193 - val_loss: 0.3356\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3192 - val_loss: 0.3377\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3173 - val_loss: 0.3382\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3163 - val_loss: 0.3360\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3150 - val_loss: 0.3349\n",
      "\n",
      "val/train: 1.06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_valid), callbacks=[early_stopping_cb, print_valid_train_ration_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12840), started 23:11:19 ago. (Use '!kill 12840' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-52bd1fbf2521ff87\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-52bd1fbf2521ff87\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir ./my_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3300407826900482"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(x_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルを使った予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict : [3.9114146 4.157746  1.7524736]\n",
      "correct : [3.93  4.42  3.625]\n"
     ]
    }
   ],
   "source": [
    "# サンプル用にデータサイズを限定\n",
    "x_new = x_test[:3]\n",
    "\n",
    "y_pred = model.predict(x_new)\n",
    "print(f'predict : {y_pred.reshape(-1)}')\n",
    "print(f'correct : {y_test[:3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの保存と復元"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras は HDF5 形式を使ってモデルのアーキテクチャ（すべてのハイパーパラメータを含む）とすべての層のモデルパラメータの値（たとえば接続重みやバイアス）を保存する。\n",
    "さらに、オプティマイザ（ハイパーパラメータやその他の状態情報を含む）も保存する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_keras_sequential_regression_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 復元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('my_keras_sequential_regression_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86c3969cb8e4d6528009ba441e3b227910147fcb8261d5b261fbcbb462fd60ef"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
