{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習において重要トピックの一つであるハイパーパラメータのチューニング方法を実装してみる。\n",
    "\n",
    "今回california_housingをつかって、ランダムサーチによる探索を試す。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ランダムサーチ：sklearn.datasets.fetch_california_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パッケージインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow ver.2.5.0\n",
      "keras ver.2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense  # layerクラスを直接インポートして使用出来る\n",
    "\n",
    "##### これうまくいくはずなんだけど学習できてない #####\n",
    "from tensorflow.keras.losses import MeanSquaredError  # 損失関数クラスを直接インポートして使用出来る\n",
    "from tensorflow.keras.optimizers import SGD  # オプティマイザクラスを直接インポートして使用出来る\n",
    "##################################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(f'tensorflow ver.{tf.__version__}')\n",
    "print(f'keras ver.{keras.__version__}')\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  データロードと前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape : (11610, 8)\n",
      "y_train.shape : (11610,)\n",
      "x_valid.shape : (3870, 8)\n",
      "y_valid.shape : (3870,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_full, y_train_full)\n",
    "\n",
    "# データサイズを確認\n",
    "print(f'x_train.shape : {x_train.shape}')\n",
    "print(f'y_train.shape : {y_train.shape}')\n",
    "print(f'x_valid.shape : {x_valid.shape}')\n",
    "print(f'y_valid.shape : {y_valid.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainデータを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.3241</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.556962</td>\n",
       "      <td>0.940928</td>\n",
       "      <td>1590.0</td>\n",
       "      <td>3.354430</td>\n",
       "      <td>33.96</td>\n",
       "      <td>-118.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.4338</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.719064</td>\n",
       "      <td>0.976589</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>3.478261</td>\n",
       "      <td>33.87</td>\n",
       "      <td>-117.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.9688</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.163934</td>\n",
       "      <td>0.963934</td>\n",
       "      <td>1857.0</td>\n",
       "      <td>3.044262</td>\n",
       "      <td>38.41</td>\n",
       "      <td>-122.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.8703</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.765926</td>\n",
       "      <td>1.143704</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>2.548148</td>\n",
       "      <td>33.73</td>\n",
       "      <td>-117.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.8266</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.746647</td>\n",
       "      <td>1.062593</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>3.233979</td>\n",
       "      <td>35.37</td>\n",
       "      <td>-119.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11605</th>\n",
       "      <td>2.5444</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.374622</td>\n",
       "      <td>1.040785</td>\n",
       "      <td>1334.0</td>\n",
       "      <td>2.015106</td>\n",
       "      <td>34.09</td>\n",
       "      <td>-118.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11606</th>\n",
       "      <td>2.8542</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.457831</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>257.0</td>\n",
       "      <td>1.548193</td>\n",
       "      <td>38.56</td>\n",
       "      <td>-121.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11607</th>\n",
       "      <td>1.8958</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.014409</td>\n",
       "      <td>1.011527</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>3.164265</td>\n",
       "      <td>36.74</td>\n",
       "      <td>-119.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11608</th>\n",
       "      <td>5.0947</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.076923</td>\n",
       "      <td>1.038462</td>\n",
       "      <td>943.0</td>\n",
       "      <td>3.626923</td>\n",
       "      <td>32.68</td>\n",
       "      <td>-117.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11609</th>\n",
       "      <td>4.4904</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.003120</td>\n",
       "      <td>1.029121</td>\n",
       "      <td>6296.0</td>\n",
       "      <td>3.274051</td>\n",
       "      <td>32.87</td>\n",
       "      <td>-117.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11610 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      2.3241      43.0  3.556962   0.940928      1590.0  3.354430     33.96   \n",
       "1      3.4338      34.0  4.719064   0.976589      1040.0  3.478261     33.87   \n",
       "2      3.9688      17.0  5.163934   0.963934      1857.0  3.044262     38.41   \n",
       "3      3.8703      23.0  3.765926   1.143704      1720.0  2.548148     33.73   \n",
       "4      4.8266      13.0  6.746647   1.062593      2170.0  3.233979     35.37   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "11605  2.5444      35.0  3.374622   1.040785      1334.0  2.015106     34.09   \n",
       "11606  2.8542      52.0  5.457831   0.993976       257.0  1.548193     38.56   \n",
       "11607  1.8958      39.0  5.014409   1.011527      1098.0  3.164265     36.74   \n",
       "11608  5.0947      14.0  5.076923   1.038462       943.0  3.626923     32.68   \n",
       "11609  4.4904      18.0  6.003120   1.029121      6296.0  3.274051     32.87   \n",
       "\n",
       "       Longitude  \n",
       "0        -118.21  \n",
       "1        -117.90  \n",
       "2        -122.75  \n",
       "3        -117.82  \n",
       "4        -119.12  \n",
       "...          ...  \n",
       "11605    -118.35  \n",
       "11606    -121.44  \n",
       "11607    -119.75  \n",
       "11608    -117.04  \n",
       "11609    -117.00  \n",
       "\n",
       "[11610 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11610 entries, 0 to 11609\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   MedInc      11610 non-null  float64\n",
      " 1   HouseAge    11610 non-null  float64\n",
      " 2   AveRooms    11610 non-null  float64\n",
      " 3   AveBedrms   11610 non-null  float64\n",
      " 4   Population  11610 non-null  float64\n",
      " 5   AveOccup    11610 non-null  float64\n",
      " 6   Latitude    11610 non-null  float64\n",
      " 7   Longitude   11610 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 725.8 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "      <td>11610.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.867776</td>\n",
       "      <td>28.548407</td>\n",
       "      <td>5.414145</td>\n",
       "      <td>1.094958</td>\n",
       "      <td>1434.260121</td>\n",
       "      <td>3.095149</td>\n",
       "      <td>35.635297</td>\n",
       "      <td>-119.570068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.914944</td>\n",
       "      <td>12.577928</td>\n",
       "      <td>2.150883</td>\n",
       "      <td>0.391669</td>\n",
       "      <td>1164.028593</td>\n",
       "      <td>12.818691</td>\n",
       "      <td>2.141518</td>\n",
       "      <td>2.006623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>-124.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.560075</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.442996</td>\n",
       "      <td>1.006508</td>\n",
       "      <td>783.000000</td>\n",
       "      <td>2.428093</td>\n",
       "      <td>33.940000</td>\n",
       "      <td>-121.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.531300</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.223172</td>\n",
       "      <td>1.049645</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>2.816695</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>-118.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.724300</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.057367</td>\n",
       "      <td>1.100295</td>\n",
       "      <td>1733.000000</td>\n",
       "      <td>3.279891</td>\n",
       "      <td>37.720000</td>\n",
       "      <td>-118.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>62.422222</td>\n",
       "      <td>15.312500</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>1243.333333</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.470000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
       "count  11610.000000  11610.000000  11610.000000  11610.000000  11610.000000   \n",
       "mean       3.867776     28.548407      5.414145      1.094958   1434.260121   \n",
       "std        1.914944     12.577928      2.150883      0.391669   1164.028593   \n",
       "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
       "25%        2.560075     18.000000      4.442996      1.006508    783.000000   \n",
       "50%        3.531300     29.000000      5.223172      1.049645   1166.000000   \n",
       "75%        4.724300     37.000000      6.057367      1.100295   1733.000000   \n",
       "max       15.000100     52.000000     62.422222     15.312500  35682.000000   \n",
       "\n",
       "           AveOccup      Latitude     Longitude  \n",
       "count  11610.000000  11610.000000  11610.000000  \n",
       "mean       3.095149     35.635297   -119.570068  \n",
       "std       12.818691      2.141518      2.006623  \n",
       "min        0.750000     32.540000   -124.350000  \n",
       "25%        2.428093     33.940000   -121.790000  \n",
       "50%        2.816695     34.250000   -118.490000  \n",
       "75%        3.279891     37.720000   -118.010000  \n",
       "max     1243.333333     41.950000   -114.470000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_x_train = pd.DataFrame(x_train, columns=housing.feature_names)\n",
    "display(pd_x_train)\n",
    "pd_x_train.info()\n",
    "pd_x_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### スケーリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "データの標準化を行う。\n",
    "\n",
    "代表的なメソッドは以下：\n",
    "\n",
    "|メソッド|説明|\n",
    "|---|---|\n",
    "|fit()|標準化するための平均と分散を計算する。|\n",
    "|trasform()|（事前に計算した平均と分散を使用して）標準化を行う。|\n",
    "|fit_transform()|平均と分散を計算し、標準化を行う。|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_valid = scaler.transform(x_valid)  # x_trainの平均・分散を使用する（のはなぜ？）\n",
    "x_test = scaler.transform(x_test)  # x_trainの平均・分散を使用する（のはなぜ？）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "複数のモデルを比較しやすくするようにモデルを作成する関数を定義しておく。\n",
    "\n",
    "この関数では引数で渡した層の数、各層のニューロン数、学習率でSequentialモデル作成→SGDオプティマイザでコンパイルまで行い、モデルを返す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[x_train.shape[1]]):\n",
    "    # Sequentialモデル生成\n",
    "    model = keras.models.Sequential()\n",
    "    # InputLayer追加\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    # hiddenLayer追加\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    # OutputLayer追加\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    # optimizer生成\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    # compile\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "\n",
    "    return model\n",
    "\n",
    "# build_modelを使ってKerasRegressorを作る\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KerasRegressorオブジェクトはbuild_modelを使って構築されるモデルに薄いラップをかぶせたものである。<br>\n",
    "（このラップによって？）scikit-learnの回帰モデルを同じようなユーザインタフェースを使用することが出来る。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習と評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コールバックによる学習中のチェックポイント保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回早期打ち切り設定を入れるためにEarlyStopping関数を使用する。\n",
    "\n",
    "また、コールバック関数は自作したものを使うことが出来る。<br>\n",
    "例として学習中の訓練データのlossとvalidationデータのlossの比率を表示する関数を作成する。（過学習を検知すること想定）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 早期打ち切りのコールバック関数\n",
    "# 学習打ち切り時に性能が最高だった時の重みを復元するので最良モデルの保存と復元は不要\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)  # patienceで指定したエポック数学習が進まなかったときに学習を打ち切る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))\n",
    "\n",
    "print_valid_train_ration_cb = PrintValTrainRatioCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoardを使った可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ログ出力のルートディレクトリ\n",
    "root_dir = os.path.join(os.curdir, 'my_logs')\n",
    "\n",
    "# ログディレクトリ名を生成する関数\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_dir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learnのようにfitメソッドで学習する。<br>\n",
    "ただし引数はbuild_modelの土台になっているkerasモデルに渡される。<br>\n",
    "その例として以下ではcallbackを渡している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  3/363 [..............................] - ETA: 9s - loss: 9.5909   WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0085s). Check your callbacks.\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.5222 - val_loss: 0.7017\n",
      "\n",
      "val/train: 0.46\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6771 - val_loss: 0.6008\n",
      "\n",
      "val/train: 0.89\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5856 - val_loss: 0.5612\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5494 - val_loss: 0.5393\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5273 - val_loss: 0.5227\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.5115 - val_loss: 0.5134\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.5006 - val_loss: 0.5005\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4926 - val_loss: 0.4928\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4869 - val_loss: 0.4878\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4805 - val_loss: 0.4820\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4746 - val_loss: 0.4783\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 925us/step - loss: 0.4696 - val_loss: 0.4737\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 915us/step - loss: 0.4643 - val_loss: 0.4674\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 695us/step - loss: 0.4599 - val_loss: 0.4624\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 665us/step - loss: 0.4556 - val_loss: 0.4617\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 701us/step - loss: 0.4523 - val_loss: 0.4562\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 696us/step - loss: 0.4487 - val_loss: 0.4522\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 658us/step - loss: 0.4452 - val_loss: 0.4497\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 677us/step - loss: 0.4423 - val_loss: 0.4483\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 658us/step - loss: 0.4394 - val_loss: 0.4455\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 662us/step - loss: 0.4363 - val_loss: 0.4421\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 668us/step - loss: 0.4342 - val_loss: 0.4397\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 659us/step - loss: 0.4312 - val_loss: 0.4375\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 637us/step - loss: 0.4289 - val_loss: 0.4352\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 682us/step - loss: 0.4265 - val_loss: 0.4316\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 660us/step - loss: 0.4239 - val_loss: 0.4305\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 678us/step - loss: 0.4222 - val_loss: 0.4275\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 689us/step - loss: 0.4197 - val_loss: 0.4254\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 796us/step - loss: 0.4176 - val_loss: 0.4237\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 698us/step - loss: 0.4158 - val_loss: 0.4215\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 811us/step - loss: 0.4135 - val_loss: 0.4218\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 692us/step - loss: 0.4124 - val_loss: 0.4184\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 749us/step - loss: 0.4104 - val_loss: 0.4194\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4086 - val_loss: 0.4161\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4076 - val_loss: 0.4127\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4056 - val_loss: 0.4145\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4043 - val_loss: 0.4122\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4029 - val_loss: 0.4094\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4013 - val_loss: 0.4085\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.4066\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.4081\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3973 - val_loss: 0.4019\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.4013\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3944 - val_loss: 0.4013\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3934 - val_loss: 0.4010\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.3913 - val_loss: 0.3985\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 901us/step - loss: 0.3911 - val_loss: 0.3962\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.3896 - val_loss: 0.4004\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.3884 - val_loss: 0.3958\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 915us/step - loss: 0.3872 - val_loss: 0.3931\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 893us/step - loss: 0.3864 - val_loss: 0.3946\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3849 - val_loss: 0.3916\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 829us/step - loss: 0.3844 - val_loss: 0.3889\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 814us/step - loss: 0.3827 - val_loss: 0.3927\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 922us/step - loss: 0.3819 - val_loss: 0.3882\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 831us/step - loss: 0.3809 - val_loss: 0.3860\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 801us/step - loss: 0.3799 - val_loss: 0.3854\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 815us/step - loss: 0.3789 - val_loss: 0.3846\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.3777 - val_loss: 0.3842\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 777us/step - loss: 0.3770 - val_loss: 0.3824\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 742us/step - loss: 0.3759 - val_loss: 0.3823\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 739us/step - loss: 0.3753 - val_loss: 0.3869\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 719us/step - loss: 0.3742 - val_loss: 0.3805\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 714us/step - loss: 0.3732 - val_loss: 0.3951\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 714us/step - loss: 0.3730 - val_loss: 0.3823\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 740us/step - loss: 0.3715 - val_loss: 0.3776\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 736us/step - loss: 0.3707 - val_loss: 0.3775\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3701 - val_loss: 0.3780\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 812us/step - loss: 0.3694 - val_loss: 0.3772\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.3761\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 760us/step - loss: 0.3678 - val_loss: 0.3733\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 758us/step - loss: 0.3676 - val_loss: 0.3723\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 825us/step - loss: 0.3667 - val_loss: 0.3751\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 711us/step - loss: 0.3651 - val_loss: 0.3774\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 688us/step - loss: 0.3641 - val_loss: 0.3737\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 714us/step - loss: 0.3644 - val_loss: 0.3721\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 712us/step - loss: 0.3642 - val_loss: 0.3721\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 711us/step - loss: 0.3624 - val_loss: 0.3684\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 699us/step - loss: 0.3625 - val_loss: 0.3693\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 775us/step - loss: 0.3614 - val_loss: 0.3718\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3615 - val_loss: 0.3671\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 878us/step - loss: 0.3603 - val_loss: 0.3698\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 753us/step - loss: 0.3601 - val_loss: 0.3661\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 706us/step - loss: 0.3595 - val_loss: 0.3651\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 706us/step - loss: 0.3586 - val_loss: 0.3662\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 741us/step - loss: 0.3582 - val_loss: 0.3640\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 703us/step - loss: 0.3573 - val_loss: 0.3689\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 687us/step - loss: 0.3566 - val_loss: 0.3632\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 684us/step - loss: 0.3567 - val_loss: 0.3641\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 695us/step - loss: 0.3559 - val_loss: 0.3733\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 706us/step - loss: 0.3556 - val_loss: 0.3623\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 703us/step - loss: 0.3546 - val_loss: 0.3629\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 704us/step - loss: 0.3543 - val_loss: 0.3633\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 755us/step - loss: 0.3538 - val_loss: 0.3610\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 716us/step - loss: 0.3529 - val_loss: 0.3615\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 722us/step - loss: 0.3525 - val_loss: 0.3646\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 704us/step - loss: 0.3525 - val_loss: 0.3614\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 704us/step - loss: 0.3514 - val_loss: 0.3644\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 841us/step - loss: 0.3513 - val_loss: 0.3574\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 738us/step - loss: 0.3511 - val_loss: 0.3580\n",
      "\n",
      "val/train: 1.02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f9fe1e7648>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scikit-learnのようにfitメソッドで学習.\n",
    "keras_reg.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_valid), callbacks=[early_stopping_cb,print_valid_train_ration_cb,tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 29808), started 4 days, 0:54:06 ago. (Use '!kill 29808' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-670d6ede072e395b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-670d6ede072e395b\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir ./my_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 531us/step - loss: 0.3509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.35093608498573303"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scikit-learnのようにscoreメソッドで評価(scoreは高いほぼ良い)\n",
    "mse_test = keras_reg.score(x_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルを使った予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict : [2.5911822 1.6748192 1.6262096]\n",
      "correct : [2.103 2.259 1.52 ]\n"
     ]
    }
   ],
   "source": [
    "# サンプル用にデータサイズを限定\n",
    "x_new = x_test[:3]\n",
    "\n",
    "# scikit-learnのようにpredictメソッドで予測\n",
    "y_pred = keras_reg.predict(x_new)\n",
    "print(f'predict : {y_pred.reshape(-1)}')\n",
    "print(f'correct : {y_test[:3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ランダムサーチによるパラメータ探索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまででパラメータ探索をするモデル側の準備が出来たので、実際にランダムサーチを使って探索を行う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの保存と復元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 7s - loss: 3.7157 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0098s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.3168 - val_loss: 1.4620\n",
      "\n",
      "val/train: 0.63\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1642 - val_loss: 0.9538\n",
      "\n",
      "val/train: 0.82\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8796 - val_loss: 0.7932\n",
      "\n",
      "val/train: 0.90\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7779 - val_loss: 0.7243\n",
      "\n",
      "val/train: 0.93\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7279 - val_loss: 0.6852\n",
      "\n",
      "val/train: 0.94\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6938 - val_loss: 0.6576\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6677 - val_loss: 0.6342\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6449 - val_loss: 0.6149\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6254 - val_loss: 0.5983\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6081 - val_loss: 0.5838\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5923 - val_loss: 0.5707\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5784 - val_loss: 0.5581\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5651 - val_loss: 0.5469\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5530 - val_loss: 0.5376\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5425 - val_loss: 0.5284\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5323 - val_loss: 0.5202\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5232 - val_loss: 0.5125\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5151 - val_loss: 0.5057\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5074 - val_loss: 0.4994\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5006 - val_loss: 0.4942\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4945 - val_loss: 0.4895\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4890 - val_loss: 0.4849\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4842 - val_loss: 0.4810\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4798 - val_loss: 0.4775\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4757 - val_loss: 0.4740\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4719 - val_loss: 0.4715\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4684 - val_loss: 0.4683\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4652 - val_loss: 0.4662\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4620 - val_loss: 0.4633\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4592 - val_loss: 0.4616\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4563 - val_loss: 0.4599\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4540 - val_loss: 0.4574\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4514 - val_loss: 0.4557\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4493 - val_loss: 0.4544\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4472 - val_loss: 0.4531\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4452 - val_loss: 0.4510\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4435 - val_loss: 0.4502\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.4418 - val_loss: 0.4492\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4401 - val_loss: 0.4478\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4386 - val_loss: 0.4465\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4370 - val_loss: 0.4466\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4357 - val_loss: 0.4444\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.4344 - val_loss: 0.4439\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4330 - val_loss: 0.4426\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4320 - val_loss: 0.4416\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4307 - val_loss: 0.4408\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4293 - val_loss: 0.4407\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4281 - val_loss: 0.4393\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4273 - val_loss: 0.4391\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4262 - val_loss: 0.4388\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4369\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4243 - val_loss: 0.4369\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4235 - val_loss: 0.4362\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4226 - val_loss: 0.4348\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.4353\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.4209 - val_loss: 0.4337\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4197 - val_loss: 0.4331\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.4190 - val_loss: 0.4328\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4181 - val_loss: 0.4324\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4172 - val_loss: 0.4318\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4166 - val_loss: 0.4308\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4156 - val_loss: 0.4305\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4148 - val_loss: 0.4298\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4142 - val_loss: 0.4291\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4134 - val_loss: 0.4286\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4128 - val_loss: 0.4283\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4119 - val_loss: 0.4278\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4113 - val_loss: 0.4265\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4106 - val_loss: 0.4260\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4098 - val_loss: 0.4255\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4095 - val_loss: 0.4248\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4085 - val_loss: 0.4244\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4079 - val_loss: 0.4243\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4073 - val_loss: 0.4238\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4066 - val_loss: 0.4231\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4059 - val_loss: 0.4229\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4054 - val_loss: 0.4218\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4042 - val_loss: 0.4213\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4040 - val_loss: 0.4213\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4036 - val_loss: 0.4205\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4030 - val_loss: 0.4202\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4025 - val_loss: 0.4198\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4015 - val_loss: 0.4188\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.4185\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4007 - val_loss: 0.4179\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.4173\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.4171\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3989 - val_loss: 0.4168\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3982 - val_loss: 0.4164\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.4159\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3973 - val_loss: 0.4148\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3967 - val_loss: 0.4143\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3962 - val_loss: 0.4151\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3955 - val_loss: 0.4138\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3952 - val_loss: 0.4131\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 0.4135\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3942 - val_loss: 0.4120\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3935 - val_loss: 0.4116\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3931 - val_loss: 0.4110\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.4107\n",
      "\n",
      "val/train: 1.05\n",
      "121/121 [==============================] - 0s 808us/step - loss: 0.4757\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 7.3337 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0083s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.6677 - val_loss: 1.2852\n",
      "\n",
      "val/train: 0.48\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9947 - val_loss: 0.8609\n",
      "\n",
      "val/train: 0.87\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8006 - val_loss: 0.7349\n",
      "\n",
      "val/train: 0.92\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7101 - val_loss: 0.6663\n",
      "\n",
      "val/train: 0.94\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6646 - val_loss: 0.6298\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6338 - val_loss: 0.6046\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6096 - val_loss: 0.5831\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5896 - val_loss: 0.5663\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5723 - val_loss: 0.5518\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5574 - val_loss: 0.5399\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5441 - val_loss: 0.5285\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5331 - val_loss: 0.5196\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5227 - val_loss: 0.5110\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5141 - val_loss: 0.5037\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5064 - val_loss: 0.4976\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5001 - val_loss: 0.4923\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4942 - val_loss: 0.4873\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4898 - val_loss: 0.4840\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4854 - val_loss: 0.4800\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4809 - val_loss: 0.4766\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4772 - val_loss: 0.4737\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4741 - val_loss: 0.4709\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4712 - val_loss: 0.4686\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4685 - val_loss: 0.4666\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4658 - val_loss: 0.4643\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4633 - val_loss: 0.4627\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4606 - val_loss: 0.4600\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4587 - val_loss: 0.4582\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4565 - val_loss: 0.4565\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4546 - val_loss: 0.4548\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4523 - val_loss: 0.4531\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4508 - val_loss: 0.4515\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4489 - val_loss: 0.4495\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4468 - val_loss: 0.4479\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4451 - val_loss: 0.4466\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4435 - val_loss: 0.4451\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4418 - val_loss: 0.4440\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4407 - val_loss: 0.4423\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4387 - val_loss: 0.4417\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4376 - val_loss: 0.4398\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4359 - val_loss: 0.4384\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4346 - val_loss: 0.4374\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4331 - val_loss: 0.4366\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4326 - val_loss: 0.4355\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4308 - val_loss: 0.4340\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4295 - val_loss: 0.4328\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4281 - val_loss: 0.4327\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4275 - val_loss: 0.4312\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4263 - val_loss: 0.4301\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4251 - val_loss: 0.4293\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4243 - val_loss: 0.4284\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4229 - val_loss: 0.4275\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4234 - val_loss: 0.4279\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4215 - val_loss: 0.4260\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4204 - val_loss: 0.4252\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4194 - val_loss: 0.4242\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4178 - val_loss: 0.4231\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4173 - val_loss: 0.4225\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4157 - val_loss: 0.4248\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4156 - val_loss: 0.4212\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4147 - val_loss: 0.4207\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4137 - val_loss: 0.4198\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4130 - val_loss: 0.4190\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4117 - val_loss: 0.4183\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.4176\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4115 - val_loss: 0.4168\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4099 - val_loss: 0.4163\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4091 - val_loss: 0.4151\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4079 - val_loss: 0.4154\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4067 - val_loss: 0.4163\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4065 - val_loss: 0.4141\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4064 - val_loss: 0.4131\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4053 - val_loss: 0.4130\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4047 - val_loss: 0.4119\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4036 - val_loss: 0.4117\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4031 - val_loss: 0.4112\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4023 - val_loss: 0.4105\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.4100\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4006 - val_loss: 0.4090\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.4092\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.4086\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.4081\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.4093\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3974 - val_loss: 0.4069\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.4064\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3957 - val_loss: 0.4054\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3948 - val_loss: 0.4056\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3945 - val_loss: 0.4044\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.4041\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 0.4036\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3924 - val_loss: 0.4035\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3919 - val_loss: 0.4023\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.4016\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.4018\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3901 - val_loss: 0.4007\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.4007\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.3998\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3886 - val_loss: 0.3994\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.3992\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3875 - val_loss: 0.3985\n",
      "\n",
      "val/train: 1.03\n",
      "121/121 [==============================] - 0s 719us/step - loss: 0.3851\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 6.2935 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0083s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.7588 - val_loss: 1.1970\n",
      "\n",
      "val/train: 0.43\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9110 - val_loss: 0.7610\n",
      "\n",
      "val/train: 0.84\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7305 - val_loss: 0.6959\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6848 - val_loss: 0.6632\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6541 - val_loss: 0.6364\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6299 - val_loss: 0.6153\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6090 - val_loss: 0.5976\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5908 - val_loss: 0.5821\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5751 - val_loss: 0.5685\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5612 - val_loss: 0.5580\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5496 - val_loss: 0.5474\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5392 - val_loss: 0.5389\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5299 - val_loss: 0.5308\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5214 - val_loss: 0.5240\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5142 - val_loss: 0.5175\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5076 - val_loss: 0.5121\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5014 - val_loss: 0.5067\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4956 - val_loss: 0.5021\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4905 - val_loss: 0.4978\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4857 - val_loss: 0.4935\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4813 - val_loss: 0.4896\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4772 - val_loss: 0.4861\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4732 - val_loss: 0.4837\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4700 - val_loss: 0.4800\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4668 - val_loss: 0.4770\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4635 - val_loss: 0.4746\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4609 - val_loss: 0.4719\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4579 - val_loss: 0.4696\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4550 - val_loss: 0.4677\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4523 - val_loss: 0.4662\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4501 - val_loss: 0.4628\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4475 - val_loss: 0.4612\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4453 - val_loss: 0.4597\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4431 - val_loss: 0.4568\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4411 - val_loss: 0.4549\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4392 - val_loss: 0.4530\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4370 - val_loss: 0.4523\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4352 - val_loss: 0.4503\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4334 - val_loss: 0.4488\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4317 - val_loss: 0.4474\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4299 - val_loss: 0.4455\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4285 - val_loss: 0.4457\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4271 - val_loss: 0.4431\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4255 - val_loss: 0.4416\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4239 - val_loss: 0.4413\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4228 - val_loss: 0.4383\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4214 - val_loss: 0.4372\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4200 - val_loss: 0.4368\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4186 - val_loss: 0.4378\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4176 - val_loss: 0.4336\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4164 - val_loss: 0.4326\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4150 - val_loss: 0.4315\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4141 - val_loss: 0.4307\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4129 - val_loss: 0.4304\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4116 - val_loss: 0.4312\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4107 - val_loss: 0.4276\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.4285\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4085 - val_loss: 0.4273\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4076 - val_loss: 0.4247\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.4272\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4056 - val_loss: 0.4230\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4046 - val_loss: 0.4216\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4036 - val_loss: 0.4210\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4027 - val_loss: 0.4210\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 0.4192\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4012 - val_loss: 0.4184\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4001 - val_loss: 0.4178\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3990 - val_loss: 0.4170\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3986 - val_loss: 0.4174\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.4211\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.4144\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.4149\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3953 - val_loss: 0.4153\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3945 - val_loss: 0.4123\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.4151\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3929 - val_loss: 0.4117\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3917 - val_loss: 0.4138\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.4112\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.4107\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3899 - val_loss: 0.4085\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.4093\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.4087\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.4074\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3870 - val_loss: 0.4056\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3862 - val_loss: 0.4062\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3856 - val_loss: 0.4065\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.4068\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3843 - val_loss: 0.4051\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.4056\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3830 - val_loss: 0.4039\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.4042\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.4031\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.4030\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.4011\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.4001\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3792 - val_loss: 0.3998\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.3985\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.3995\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.3980\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3768 - val_loss: 0.3997\n",
      "\n",
      "val/train: 1.06\n",
      "121/121 [==============================] - 0s 756us/step - loss: 0.4076\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 5.2975 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0005s vs `on_train_batch_end` time: 0.0092s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6875 - val_loss: 0.8313\n",
      "\n",
      "val/train: 0.49\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7362 - val_loss: 0.6531\n",
      "\n",
      "val/train: 0.89\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6431 - val_loss: 0.6057\n",
      "\n",
      "val/train: 0.94\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6063 - val_loss: 0.5822\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5825 - val_loss: 0.5651\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5654 - val_loss: 0.5513\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5509 - val_loss: 0.5421\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5388 - val_loss: 0.5326\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5290 - val_loss: 0.5254\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5206 - val_loss: 0.5175\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5128 - val_loss: 0.5125\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5069 - val_loss: 0.5051\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5007 - val_loss: 0.5030\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4969 - val_loss: 0.4968\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4921 - val_loss: 0.4933\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4886 - val_loss: 0.4900\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4848 - val_loss: 0.4886\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4819 - val_loss: 0.4832\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4789 - val_loss: 0.4805\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4758 - val_loss: 0.4782\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4733 - val_loss: 0.4756\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4706 - val_loss: 0.4731\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4678 - val_loss: 0.4716\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4656 - val_loss: 0.4696\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4637 - val_loss: 0.4673\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4612 - val_loss: 0.4658\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4591 - val_loss: 0.4638\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4573 - val_loss: 0.4619\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4555 - val_loss: 0.4607\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4539 - val_loss: 0.4595\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4525 - val_loss: 0.4578\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4511 - val_loss: 0.4563\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4494 - val_loss: 0.4546\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4479 - val_loss: 0.4557\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4466 - val_loss: 0.4521\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4454 - val_loss: 0.4500\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4441 - val_loss: 0.4486\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4430 - val_loss: 0.4465\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4415 - val_loss: 0.4453\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4402 - val_loss: 0.4443\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4390 - val_loss: 0.4420\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4374 - val_loss: 0.4426\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4360 - val_loss: 0.4397\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4349 - val_loss: 0.4378\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4334 - val_loss: 0.4363\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4323 - val_loss: 0.4362\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4314 - val_loss: 0.4337\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4302 - val_loss: 0.4319\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4286 - val_loss: 0.4308\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4270 - val_loss: 0.4300\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.4287\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4248 - val_loss: 0.4262\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4234 - val_loss: 0.4239\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4218 - val_loss: 0.4229\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4199 - val_loss: 0.4216\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4188 - val_loss: 0.4193\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4170 - val_loss: 0.4214\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4157 - val_loss: 0.4168\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4145 - val_loss: 0.4146\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4126 - val_loss: 0.4125\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4108 - val_loss: 0.4145\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4099 - val_loss: 0.4107\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4080 - val_loss: 0.4080\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.4063\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4045 - val_loss: 0.4062\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4030 - val_loss: 0.4029\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4012 - val_loss: 0.4025\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3998 - val_loss: 0.4017\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3991 - val_loss: 0.3979\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3972 - val_loss: 0.3975\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.3974\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.3939\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.3926\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.3915\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 0.3908\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.3886\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.3879\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.3865\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.3854\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3838\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.3839\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.3848\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.3812\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3789 - val_loss: 0.3811\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.3799\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3763 - val_loss: 0.3798\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.3773\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3738 - val_loss: 0.3818\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.3771\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.3743\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.3734\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3712 - val_loss: 0.3752\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3701 - val_loss: 0.3738\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.3709\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3686 - val_loss: 0.3708\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3674 - val_loss: 0.3733\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3668 - val_loss: 0.3684\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3660 - val_loss: 0.3696\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.3694\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3656 - val_loss: 0.3671\n",
      "\n",
      "val/train: 1.00\n",
      "121/121 [==============================] - 0s 731us/step - loss: 0.3936\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 5.7090  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0094s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9186 - val_loss: 0.8886\n",
      "\n",
      "val/train: 0.46\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7845 - val_loss: 0.7160\n",
      "\n",
      "val/train: 0.91\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6980 - val_loss: 0.6593\n",
      "\n",
      "val/train: 0.94\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6561 - val_loss: 0.6310\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6296 - val_loss: 0.6077\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6109 - val_loss: 0.5937\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5955 - val_loss: 0.5816\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5825 - val_loss: 0.5710\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5711 - val_loss: 0.5610\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5610 - val_loss: 0.5525\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5507 - val_loss: 0.5425\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5417 - val_loss: 0.5351\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5326 - val_loss: 0.5272\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 0.5197\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5169 - val_loss: 0.5135\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5100 - val_loss: 0.5078\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5037 - val_loss: 0.5023\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4979 - val_loss: 0.4984\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4931 - val_loss: 0.4940\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4894 - val_loss: 0.4909\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4875 - val_loss: 0.4894\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4848 - val_loss: 0.4870\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4839 - val_loss: 0.4856\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4809 - val_loss: 0.4847\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4790 - val_loss: 0.4820\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4782 - val_loss: 0.4821\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4764 - val_loss: 0.4797\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4750 - val_loss: 0.4782\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4733 - val_loss: 0.4784\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4726 - val_loss: 0.4760\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4708 - val_loss: 0.4769\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4708 - val_loss: 0.4755\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4698 - val_loss: 0.4738\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4687 - val_loss: 0.4737\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4680 - val_loss: 0.4728\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4671 - val_loss: 0.4720\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4660 - val_loss: 0.4716\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4665 - val_loss: 0.4714\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4652 - val_loss: 0.4707\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4644 - val_loss: 0.4696\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4632 - val_loss: 0.4686\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4629 - val_loss: 0.4681\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4623 - val_loss: 0.4670\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4605 - val_loss: 0.4682\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4608 - val_loss: 0.4660\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4616 - val_loss: 0.4654\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4600 - val_loss: 0.4632\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4601 - val_loss: 0.4633\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4577 - val_loss: 0.4615\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4584 - val_loss: 0.4628\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4569 - val_loss: 0.4614\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4564 - val_loss: 0.4619\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4557 - val_loss: 0.4598\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4546 - val_loss: 0.4598\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4539 - val_loss: 0.4582\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4529 - val_loss: 0.4590\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4520 - val_loss: 0.4576\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4512 - val_loss: 0.4559\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4507 - val_loss: 0.4554\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4497 - val_loss: 0.4558\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4487 - val_loss: 0.4565\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4485 - val_loss: 0.4531\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4477 - val_loss: 0.4530\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4466 - val_loss: 0.4519\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4456 - val_loss: 0.4509\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4451 - val_loss: 0.4506\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4438 - val_loss: 0.4506\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4429 - val_loss: 0.4474\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4422 - val_loss: 0.4478\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4415 - val_loss: 0.4470\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4405 - val_loss: 0.4455\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4395 - val_loss: 0.4439\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4385 - val_loss: 0.4433\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4365 - val_loss: 0.4465\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4363 - val_loss: 0.4410\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4351 - val_loss: 0.4387\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4340 - val_loss: 0.4384\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4329 - val_loss: 0.4370\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4320 - val_loss: 0.4365\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4306 - val_loss: 0.4368\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4295 - val_loss: 0.4337\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4286 - val_loss: 0.4354\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4275 - val_loss: 0.4325\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4265 - val_loss: 0.4310\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4258 - val_loss: 0.4299\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4245 - val_loss: 0.4297\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4242 - val_loss: 0.4274\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4226 - val_loss: 0.4269\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4221 - val_loss: 0.4260\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4212 - val_loss: 0.4247\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4203 - val_loss: 0.4241\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4187 - val_loss: 0.4250\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4187 - val_loss: 0.4245\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4175 - val_loss: 0.4213\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4168 - val_loss: 0.4194\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4152 - val_loss: 0.4196\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4144 - val_loss: 0.4201\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4141 - val_loss: 0.4196\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4134 - val_loss: 0.4164\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4123 - val_loss: 0.4168\n",
      "\n",
      "val/train: 1.01\n",
      "121/121 [==============================] - 0s 773us/step - loss: 0.4044\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 4.3466 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0091s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3186 - val_loss: 0.7702\n",
      "\n",
      "val/train: 0.58\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7266 - val_loss: 0.6683\n",
      "\n",
      "val/train: 0.92\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6531 - val_loss: 0.6162\n",
      "\n",
      "val/train: 0.94\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5985 - val_loss: 0.5718\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5541 - val_loss: 0.5416\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 0.5207\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5031 - val_loss: 0.5062\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4896 - val_loss: 0.4975\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4802 - val_loss: 0.4904\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4731 - val_loss: 0.4831\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4675 - val_loss: 0.4795\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4629 - val_loss: 0.4758\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4602 - val_loss: 0.4746\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.4733\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 0.4698\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4525 - val_loss: 0.4667\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4506 - val_loss: 0.4660\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4493 - val_loss: 0.4621\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4463 - val_loss: 0.4611\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4450 - val_loss: 0.4582\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4425 - val_loss: 0.4586\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4413 - val_loss: 0.4552\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4402 - val_loss: 0.4538\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4378 - val_loss: 0.4521\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4357 - val_loss: 0.4518\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4349 - val_loss: 0.4493\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4335 - val_loss: 0.4476\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4317 - val_loss: 0.4465\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4300 - val_loss: 0.4441\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4287 - val_loss: 0.4418\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4264 - val_loss: 0.4416\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4263 - val_loss: 0.4401\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4244 - val_loss: 0.4385\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4236 - val_loss: 0.4360\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4220 - val_loss: 0.4350\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 0.4343\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4191 - val_loss: 0.4351\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4180 - val_loss: 0.4313\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4165 - val_loss: 0.4326\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4154 - val_loss: 0.4293\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4146 - val_loss: 0.4269\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4139 - val_loss: 0.4255\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4123 - val_loss: 0.4293\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4115 - val_loss: 0.4252\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4101 - val_loss: 0.4243\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4094 - val_loss: 0.4212\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4080 - val_loss: 0.4213\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4072 - val_loss: 0.4189\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4061 - val_loss: 0.4200\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4057 - val_loss: 0.4193\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4040 - val_loss: 0.4202\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4031 - val_loss: 0.4212\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4026 - val_loss: 0.4134\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4017 - val_loss: 0.4131\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.4141\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4001 - val_loss: 0.4120\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3996 - val_loss: 0.4106\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3979 - val_loss: 0.4109\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3973 - val_loss: 0.4117\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.4084\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.4072\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.4072\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 0.4060\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.4047\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3931 - val_loss: 0.4025\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3921 - val_loss: 0.4036\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.4037\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.4001\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.4018\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.4018\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.3988\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.4002\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.3998\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.3956\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3862 - val_loss: 0.3959\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3858 - val_loss: 0.3973\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.3960\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.3962\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3950\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.3939\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.3957\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3814 - val_loss: 0.3919\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3803 - val_loss: 0.3896\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.3918\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.3884\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.3910\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.3870\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.3871\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.3865\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3772 - val_loss: 0.3889\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3858\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3754 - val_loss: 0.3843\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3742 - val_loss: 0.3859\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.3830\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3814\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.3817\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.3800\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.3825\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.3803\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3705 - val_loss: 0.3805\n",
      "\n",
      "val/train: 1.03\n",
      "121/121 [==============================] - 0s 682us/step - loss: 0.3901\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 5.5882 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0089s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.2190 - val_loss: 1.2011\n",
      "\n",
      "val/train: 0.54\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8878 - val_loss: 0.8228\n",
      "\n",
      "val/train: 0.93\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7515 - val_loss: 0.7407\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7019 - val_loss: 0.6986\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6681 - val_loss: 0.6669\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6402 - val_loss: 0.6401\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6163 - val_loss: 0.6172\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5959 - val_loss: 0.5978\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5781 - val_loss: 0.5808\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5628 - val_loss: 0.5658\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5486 - val_loss: 0.5545\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5375 - val_loss: 0.5416\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5270 - val_loss: 0.5317\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5179 - val_loss: 0.5231\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5097 - val_loss: 0.5150\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5026 - val_loss: 0.5082\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4959 - val_loss: 0.5021\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4906 - val_loss: 0.4965\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4855 - val_loss: 0.4908\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4809 - val_loss: 0.4864\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4768 - val_loss: 0.4824\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4731 - val_loss: 0.4786\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4696 - val_loss: 0.4749\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4665 - val_loss: 0.4723\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4637 - val_loss: 0.4688\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4608 - val_loss: 0.4665\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4581 - val_loss: 0.4636\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4557 - val_loss: 0.4612\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4535 - val_loss: 0.4589\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4513 - val_loss: 0.4574\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4493 - val_loss: 0.4547\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4472 - val_loss: 0.4529\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4453 - val_loss: 0.4516\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4435 - val_loss: 0.4489\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4416 - val_loss: 0.4476\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4399 - val_loss: 0.4461\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4381 - val_loss: 0.4445\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4366 - val_loss: 0.4425\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4352 - val_loss: 0.4412\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4336 - val_loss: 0.4399\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4320 - val_loss: 0.4387\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4307 - val_loss: 0.4373\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4291 - val_loss: 0.4362\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4279 - val_loss: 0.4348\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4263 - val_loss: 0.4336\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4325\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4239 - val_loss: 0.4318\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.4305\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.4296\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4205 - val_loss: 0.4287\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4193 - val_loss: 0.4276\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4183 - val_loss: 0.4269\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4173 - val_loss: 0.4261\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4163 - val_loss: 0.4259\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4151 - val_loss: 0.4243\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4146 - val_loss: 0.4237\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4133 - val_loss: 0.4231\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4124 - val_loss: 0.4220\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4116 - val_loss: 0.4214\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4105 - val_loss: 0.4207\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4095 - val_loss: 0.4205\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4088 - val_loss: 0.4193\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4081 - val_loss: 0.4186\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4071 - val_loss: 0.4192\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4062 - val_loss: 0.4173\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4055 - val_loss: 0.4167\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4046 - val_loss: 0.4161\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4038 - val_loss: 0.4155\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4030 - val_loss: 0.4150\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4023 - val_loss: 0.4146\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4013 - val_loss: 0.4138\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4006 - val_loss: 0.4134\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.4126\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3989 - val_loss: 0.4122\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3983 - val_loss: 0.4116\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.4118\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3969 - val_loss: 0.4116\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.4102\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3952 - val_loss: 0.4111\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.4122\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3940 - val_loss: 0.4091\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.4091\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.4082\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.4081\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.4070\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.4066\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3899 - val_loss: 0.4064\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3891 - val_loss: 0.4061\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.4065\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3879 - val_loss: 0.4051\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3875 - val_loss: 0.4046\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.4043\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.4039\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.4036\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.4034\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.4033\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.4027\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.4020\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.4016\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.4028\n",
      "\n",
      "val/train: 1.06\n",
      "121/121 [==============================] - 0s 765us/step - loss: 0.5302\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 5.1990 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0063s vs `on_train_batch_end` time: 0.0089s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.6389 - val_loss: 1.1204\n",
      "\n",
      "val/train: 0.42\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8936 - val_loss: 0.7491\n",
      "\n",
      "val/train: 0.84\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7366 - val_loss: 0.6730\n",
      "\n",
      "val/train: 0.91\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6876 - val_loss: 0.6426\n",
      "\n",
      "val/train: 0.93\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6591 - val_loss: 0.6190\n",
      "\n",
      "val/train: 0.94\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6356 - val_loss: 0.5996\n",
      "\n",
      "val/train: 0.94\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6146 - val_loss: 0.5817\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5954 - val_loss: 0.5654\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5778 - val_loss: 0.5503\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5615 - val_loss: 0.5375\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5471 - val_loss: 0.5246\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5346 - val_loss: 0.5146\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 0.5051\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5137 - val_loss: 0.4969\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5050 - val_loss: 0.4906\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4978 - val_loss: 0.4844\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4910 - val_loss: 0.4787\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4849 - val_loss: 0.4746\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4798 - val_loss: 0.4696\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4749 - val_loss: 0.4659\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4706 - val_loss: 0.4625\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4668 - val_loss: 0.4598\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4632 - val_loss: 0.4566\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4595 - val_loss: 0.4543\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4567 - val_loss: 0.4513\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4538 - val_loss: 0.4488\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4511 - val_loss: 0.4472\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4486 - val_loss: 0.4458\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4462 - val_loss: 0.4433\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4441 - val_loss: 0.4420\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4418 - val_loss: 0.4397\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4399 - val_loss: 0.4386\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.4372\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4362 - val_loss: 0.4360\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4345 - val_loss: 0.4343\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4327 - val_loss: 0.4334\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4312 - val_loss: 0.4318\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4295 - val_loss: 0.4310\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4279 - val_loss: 0.4291\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4265 - val_loss: 0.4293\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4275\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4238 - val_loss: 0.4264\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4225 - val_loss: 0.4256\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4213 - val_loss: 0.4241\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4199 - val_loss: 0.4234\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4188 - val_loss: 0.4227\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4176 - val_loss: 0.4219\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4164 - val_loss: 0.4213\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4153 - val_loss: 0.4197\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4142 - val_loss: 0.4188\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4131 - val_loss: 0.4195\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4121 - val_loss: 0.4181\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4108 - val_loss: 0.4169\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4098 - val_loss: 0.4177\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4091 - val_loss: 0.4161\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4080 - val_loss: 0.4155\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4071 - val_loss: 0.4145\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.4150\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.4134\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.4135\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4033 - val_loss: 0.4110\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4024 - val_loss: 0.4108\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4017 - val_loss: 0.4110\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4010 - val_loss: 0.4106\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4001 - val_loss: 0.4085\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3994 - val_loss: 0.4082\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.4086\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.4064\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3969 - val_loss: 0.4059\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3962 - val_loss: 0.4057\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.4053\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3949 - val_loss: 0.4044\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.4041\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3934 - val_loss: 0.4045\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.4040\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.4025\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.4019\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3906 - val_loss: 0.4003\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.4011\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.4002\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.3997\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.3993\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.3985\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.3977\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.3995\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.3967\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3850 - val_loss: 0.3966\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3843 - val_loss: 0.3972\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3970\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3965\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.3962\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.3952\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3813 - val_loss: 0.3938\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3807 - val_loss: 0.3942\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.3940\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3796 - val_loss: 0.3921\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3790 - val_loss: 0.3921\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3783 - val_loss: 0.3920\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3779 - val_loss: 0.3923\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3775 - val_loss: 0.3910\n",
      "\n",
      "val/train: 1.04\n",
      "121/121 [==============================] - 0s 739us/step - loss: 0.3782\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 6.3375 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0085s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.7341 - val_loss: 1.3659\n",
      "\n",
      "val/train: 0.50\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0440 - val_loss: 0.8751\n",
      "\n",
      "val/train: 0.84\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8093 - val_loss: 0.7525\n",
      "\n",
      "val/train: 0.93\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7286 - val_loss: 0.6939\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6819 - val_loss: 0.6557\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6484 - val_loss: 0.6273\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6224 - val_loss: 0.6051\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6007 - val_loss: 0.5874\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5831 - val_loss: 0.5727\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5682 - val_loss: 0.5598\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5557 - val_loss: 0.5493\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5442 - val_loss: 0.5402\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5342 - val_loss: 0.5322\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 0.5251\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5182 - val_loss: 0.5190\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5111 - val_loss: 0.5129\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.5087\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4991 - val_loss: 0.5048\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4936 - val_loss: 0.5000\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4888 - val_loss: 0.4956\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4844 - val_loss: 0.4933\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4803 - val_loss: 0.4897\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4764 - val_loss: 0.4853\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4727 - val_loss: 0.4828\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4693 - val_loss: 0.4795\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4659 - val_loss: 0.4765\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4632 - val_loss: 0.4737\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4598 - val_loss: 0.4721\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4571 - val_loss: 0.4685\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4544 - val_loss: 0.4681\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4521 - val_loss: 0.4643\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4495 - val_loss: 0.4621\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4472 - val_loss: 0.4615\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4453 - val_loss: 0.4585\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4430 - val_loss: 0.4568\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4410 - val_loss: 0.4551\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4391 - val_loss: 0.4533\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4372 - val_loss: 0.4517\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4355 - val_loss: 0.4502\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4333 - val_loss: 0.4498\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4320 - val_loss: 0.4467\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4303 - val_loss: 0.4455\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4284 - val_loss: 0.4452\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4271 - val_loss: 0.4427\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4259 - val_loss: 0.4412\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4242 - val_loss: 0.4404\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4231 - val_loss: 0.4398\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4214 - val_loss: 0.4373\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4203 - val_loss: 0.4367\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4192 - val_loss: 0.4364\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4180 - val_loss: 0.4345\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4170 - val_loss: 0.4336\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4156 - val_loss: 0.4319\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4144 - val_loss: 0.4308\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4136 - val_loss: 0.4305\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4123 - val_loss: 0.4302\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4118 - val_loss: 0.4288\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4105 - val_loss: 0.4276\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.4275\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4087 - val_loss: 0.4266\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4078 - val_loss: 0.4250\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4069 - val_loss: 0.4243\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.4241\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4050 - val_loss: 0.4243\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.4232\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.4222\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4027 - val_loss: 0.4214\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 0.4214\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4010 - val_loss: 0.4195\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4001 - val_loss: 0.4204\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3997 - val_loss: 0.4184\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.4183\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3982 - val_loss: 0.4174\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3971 - val_loss: 0.4173\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.4177\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.4160\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3953 - val_loss: 0.4150\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3945 - val_loss: 0.4139\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.4139\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.4133\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.4135\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3919 - val_loss: 0.4139\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.4125\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.4110\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3901 - val_loss: 0.4104\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3893 - val_loss: 0.4095\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.4100\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.4098\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.4090\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.4076\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 0.4075\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3858 - val_loss: 0.4065\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.4067\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3844 - val_loss: 0.4068\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.4058\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.4055\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.4051\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.4038\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.4023\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.4024\n",
      "\n",
      "val/train: 1.06\n",
      "121/121 [==============================] - 0s 798us/step - loss: 0.4096\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 5.9497  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0087s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.3635 - val_loss: 1.0430\n",
      "\n",
      "val/train: 0.44\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8833 - val_loss: 0.8139\n",
      "\n",
      "val/train: 0.92\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7616 - val_loss: 0.7495\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7202 - val_loss: 0.7211\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6977 - val_loss: 0.7015\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6804 - val_loss: 0.6846\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6649 - val_loss: 0.6723\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6512 - val_loss: 0.6582\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6399 - val_loss: 0.6444\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6282 - val_loss: 0.6333\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6175 - val_loss: 0.6228\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6075 - val_loss: 0.6128\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5979 - val_loss: 0.6045\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5895 - val_loss: 0.5946\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5810 - val_loss: 0.5863\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5730 - val_loss: 0.5790\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5661 - val_loss: 0.5709\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5592 - val_loss: 0.5640\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5529 - val_loss: 0.5571\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5464 - val_loss: 0.5506\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5404 - val_loss: 0.5461\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5349 - val_loss: 0.5388\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5294 - val_loss: 0.5344\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5248 - val_loss: 0.5284\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5200 - val_loss: 0.5239\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5154 - val_loss: 0.5198\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5115 - val_loss: 0.5155\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5074 - val_loss: 0.5128\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5039 - val_loss: 0.5084\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5005 - val_loss: 0.5064\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4973 - val_loss: 0.5026\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4947 - val_loss: 0.5001\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4918 - val_loss: 0.4978\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4892 - val_loss: 0.4958\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4865 - val_loss: 0.4962\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4845 - val_loss: 0.4918\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4825 - val_loss: 0.4899\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4801 - val_loss: 0.4885\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4782 - val_loss: 0.4869\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4762 - val_loss: 0.4856\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4743 - val_loss: 0.4845\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4729 - val_loss: 0.4827\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4709 - val_loss: 0.4822\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4697 - val_loss: 0.4802\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4680 - val_loss: 0.4791\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4665 - val_loss: 0.4779\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4655 - val_loss: 0.4769\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4642 - val_loss: 0.4759\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4630 - val_loss: 0.4747\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4615 - val_loss: 0.4750\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4605 - val_loss: 0.4732\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4590 - val_loss: 0.4716\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4578 - val_loss: 0.4710\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4566 - val_loss: 0.4706\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4558 - val_loss: 0.4699\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4547 - val_loss: 0.4684\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4535 - val_loss: 0.4675\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4522 - val_loss: 0.4682\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4514 - val_loss: 0.4661\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4503 - val_loss: 0.4654\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4492 - val_loss: 0.4649\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4481 - val_loss: 0.4637\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4473 - val_loss: 0.4631\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4463 - val_loss: 0.4624\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4453 - val_loss: 0.4618\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4445 - val_loss: 0.4611\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4436 - val_loss: 0.4605\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4427 - val_loss: 0.4597\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4591\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4410 - val_loss: 0.4597\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4401 - val_loss: 0.4575\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4392 - val_loss: 0.4582\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4381 - val_loss: 0.4584\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4376 - val_loss: 0.4551\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4363 - val_loss: 0.4555\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4360 - val_loss: 0.4540\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4351 - val_loss: 0.4544\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4344 - val_loss: 0.4528\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4338 - val_loss: 0.4522\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4329 - val_loss: 0.4513\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4318 - val_loss: 0.4509\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4307 - val_loss: 0.4532\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4307 - val_loss: 0.4498\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4296 - val_loss: 0.4493\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4289 - val_loss: 0.4485\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4280 - val_loss: 0.4478\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4277 - val_loss: 0.4471\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.4470\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4260 - val_loss: 0.4461\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.4455\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4246 - val_loss: 0.4449\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4239 - val_loss: 0.4443\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4235 - val_loss: 0.4437\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4224 - val_loss: 0.4437\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4222 - val_loss: 0.4427\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4212 - val_loss: 0.4419\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 0.4414\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4199 - val_loss: 0.4409\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4194 - val_loss: 0.4407\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4185 - val_loss: 0.4395\n",
      "\n",
      "val/train: 1.05\n",
      "121/121 [==============================] - 0s 790us/step - loss: 0.6255\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 5.7997  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0090s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.7156 - val_loss: 1.6239\n",
      "\n",
      "val/train: 0.60\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2910 - val_loss: 1.1817\n",
      "\n",
      "val/train: 0.92\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0580 - val_loss: 1.0046\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9279 - val_loss: 0.8937\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8516 - val_loss: 0.8283\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7974 - val_loss: 0.7791\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7565 - val_loss: 0.7388\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7243 - val_loss: 0.7065\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6972 - val_loss: 0.6799\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6747 - val_loss: 0.6561\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6544 - val_loss: 0.6355\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6372 - val_loss: 0.6180\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6222 - val_loss: 0.6028\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6088 - val_loss: 0.5896\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 0.5782\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5861 - val_loss: 0.5681\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5768 - val_loss: 0.5585\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5680 - val_loss: 0.5500\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5597 - val_loss: 0.5421\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5517 - val_loss: 0.5345\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5445 - val_loss: 0.5275\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5372 - val_loss: 0.5212\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5306 - val_loss: 0.5155\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 0.5104\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5177 - val_loss: 0.5052\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5120 - val_loss: 0.5002\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5069 - val_loss: 0.4955\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5020 - val_loss: 0.4916\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4970 - val_loss: 0.4877\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4927 - val_loss: 0.4840\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4885 - val_loss: 0.4806\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4847 - val_loss: 0.4775\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4810 - val_loss: 0.4742\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4774 - val_loss: 0.4716\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4739 - val_loss: 0.4692\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4712 - val_loss: 0.4661\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4682 - val_loss: 0.4637\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4656 - val_loss: 0.4618\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4628 - val_loss: 0.4598\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4604 - val_loss: 0.4576\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4580 - val_loss: 0.4557\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4555 - val_loss: 0.4537\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4532 - val_loss: 0.4531\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4513 - val_loss: 0.4506\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4490 - val_loss: 0.4488\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4470 - val_loss: 0.4479\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4452 - val_loss: 0.4451\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4436 - val_loss: 0.4441\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4418 - val_loss: 0.4420\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4401 - val_loss: 0.4408\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4382 - val_loss: 0.4389\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4370 - val_loss: 0.4373\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4356 - val_loss: 0.4362\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4342 - val_loss: 0.4348\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4326 - val_loss: 0.4341\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4318 - val_loss: 0.4325\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4304 - val_loss: 0.4317\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4293 - val_loss: 0.4307\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4280 - val_loss: 0.4297\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4272 - val_loss: 0.4280\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4258 - val_loss: 0.4272\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4249 - val_loss: 0.4259\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4240 - val_loss: 0.4249\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4228 - val_loss: 0.4249\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4220 - val_loss: 0.4231\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4210 - val_loss: 0.4224\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4200 - val_loss: 0.4220\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4192 - val_loss: 0.4207\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4184 - val_loss: 0.4195\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4174 - val_loss: 0.4185\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4164 - val_loss: 0.4178\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4151 - val_loss: 0.4194\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4150 - val_loss: 0.4160\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4134 - val_loss: 0.4156\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4130 - val_loss: 0.4147\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4122 - val_loss: 0.4142\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4114 - val_loss: 0.4133\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4105 - val_loss: 0.4123\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.4117\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4085 - val_loss: 0.4120\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4083 - val_loss: 0.4106\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4075 - val_loss: 0.4098\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4067 - val_loss: 0.4088\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4059 - val_loss: 0.4081\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.4078\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.4068\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4036 - val_loss: 0.4088\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4031 - val_loss: 0.4054\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.4056\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4018 - val_loss: 0.4044\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.4037\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.4034\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3996 - val_loss: 0.4027\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3991 - val_loss: 0.4019\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.4022\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.4017\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3970 - val_loss: 0.4003\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3967 - val_loss: 0.4000\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.3992\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3957 - val_loss: 0.3988\n",
      "\n",
      "val/train: 1.01\n",
      "121/121 [==============================] - 0s 752us/step - loss: 0.3950\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 5.5832  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0088s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.1887 - val_loss: 2.0173\n",
      "\n",
      "val/train: 0.63\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.7189 - val_loss: 1.5240\n",
      "\n",
      "val/train: 0.89\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3943 - val_loss: 1.2934\n",
      "\n",
      "val/train: 0.93\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1759 - val_loss: 1.0821\n",
      "\n",
      "val/train: 0.92\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9691 - val_loss: 0.8877\n",
      "\n",
      "val/train: 0.92\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8085 - val_loss: 0.7654\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7260 - val_loss: 0.7122\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6907 - val_loss: 0.6864\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6704 - val_loss: 0.6693\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6552 - val_loss: 0.6552\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6425 - val_loss: 0.6435\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6307 - val_loss: 0.6329\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6202 - val_loss: 0.6228\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6101 - val_loss: 0.6138\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6004 - val_loss: 0.6048\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5911 - val_loss: 0.5963\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5821 - val_loss: 0.5882\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5737 - val_loss: 0.5802\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5651 - val_loss: 0.5732\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5572 - val_loss: 0.5654\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5495 - val_loss: 0.5586\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5422 - val_loss: 0.5520\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5350 - val_loss: 0.5459\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5286 - val_loss: 0.5398\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5224 - val_loss: 0.5343\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5164 - val_loss: 0.5296\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5111 - val_loss: 0.5240\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5059 - val_loss: 0.5192\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5008 - val_loss: 0.5149\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4962 - val_loss: 0.5109\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4920 - val_loss: 0.5063\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4876 - val_loss: 0.5023\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4837 - val_loss: 0.4988\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4799 - val_loss: 0.4960\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4767 - val_loss: 0.4922\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4734 - val_loss: 0.4893\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4700 - val_loss: 0.4868\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4674 - val_loss: 0.4838\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4646 - val_loss: 0.4810\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4614 - val_loss: 0.4790\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4592 - val_loss: 0.4767\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4570 - val_loss: 0.4743\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4547 - val_loss: 0.4723\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4526 - val_loss: 0.4705\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4506 - val_loss: 0.4684\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4487 - val_loss: 0.4671\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4470 - val_loss: 0.4650\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4446 - val_loss: 0.4637\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4431 - val_loss: 0.4618\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4414 - val_loss: 0.4602\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4399 - val_loss: 0.4587\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4382 - val_loss: 0.4572\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4364 - val_loss: 0.4558\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4346 - val_loss: 0.4550\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4334 - val_loss: 0.4532\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4318 - val_loss: 0.4518\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4303 - val_loss: 0.4503\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4291 - val_loss: 0.4492\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4276 - val_loss: 0.4479\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4262 - val_loss: 0.4465\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4250 - val_loss: 0.4455\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4235 - val_loss: 0.4448\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4226 - val_loss: 0.4426\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4213 - val_loss: 0.4415\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4200 - val_loss: 0.4403\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4189 - val_loss: 0.4391\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4175 - val_loss: 0.4395\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4169 - val_loss: 0.4373\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4156 - val_loss: 0.4360\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4145 - val_loss: 0.4353\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4135 - val_loss: 0.4340\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4124 - val_loss: 0.4331\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.4321\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4104 - val_loss: 0.4311\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.4301\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4083 - val_loss: 0.4292\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4074 - val_loss: 0.4286\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4066 - val_loss: 0.4271\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4051 - val_loss: 0.4266\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4047 - val_loss: 0.4256\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4037 - val_loss: 0.4248\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4028 - val_loss: 0.4241\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 0.4233\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4010 - val_loss: 0.4224\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4004 - val_loss: 0.4216\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3991 - val_loss: 0.4215\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3988 - val_loss: 0.4199\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.4190\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3971 - val_loss: 0.4182\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.4192\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.4169\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3948 - val_loss: 0.4163\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3942 - val_loss: 0.4157\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.4147\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.4138\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.4132\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.4123\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3906 - val_loss: 0.4119\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.4111\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.4111\n",
      "\n",
      "val/train: 1.06\n",
      "121/121 [==============================] - 0s 685us/step - loss: 0.4263\n",
      "Epoch 1/100\n",
      "  5/242 [..............................] - ETA: 2s - loss: 5.3006 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0077s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.1198 - val_loss: 1.5555\n",
      "\n",
      "val/train: 0.50\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0519 - val_loss: 0.7853\n",
      "\n",
      "val/train: 0.75\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6933 - val_loss: 0.6473\n",
      "\n",
      "val/train: 0.93\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6238 - val_loss: 0.6182\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6037 - val_loss: 0.6019\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5935 - val_loss: 0.5961\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5854 - val_loss: 0.5913\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5787 - val_loss: 0.5842\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5728 - val_loss: 0.5799\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5675 - val_loss: 0.5752\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5628 - val_loss: 0.5731\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5585 - val_loss: 0.5674\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5547 - val_loss: 0.5637\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5514 - val_loss: 0.5617\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5483 - val_loss: 0.5593\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5456 - val_loss: 0.5583\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5432 - val_loss: 0.5564\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5409 - val_loss: 0.5565\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5388 - val_loss: 0.5526\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5369 - val_loss: 0.5551\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5354 - val_loss: 0.5530\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5339 - val_loss: 0.5514\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5322 - val_loss: 0.5481\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5309 - val_loss: 0.5514\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5299 - val_loss: 0.5482\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5286 - val_loss: 0.5465\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5277 - val_loss: 0.5467\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5269 - val_loss: 0.5484\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5256 - val_loss: 0.5470\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5252 - val_loss: 0.5501\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 0.5491\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 0.5475\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5231 - val_loss: 0.5480\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5225 - val_loss: 0.5484\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5222 - val_loss: 0.5489\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5208 - val_loss: 0.5472\n",
      "\n",
      "val/train: 1.05\n",
      "121/121 [==============================] - 0s 781us/step - loss: 1.0798\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 6.8296 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0083s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.1947 - val_loss: 1.7455\n",
      "\n",
      "val/train: 0.42\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1582 - val_loss: 0.8537\n",
      "\n",
      "val/train: 0.74\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7376 - val_loss: 0.6789\n",
      "\n",
      "val/train: 0.92\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6499 - val_loss: 0.6322\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6226 - val_loss: 0.6140\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6087 - val_loss: 0.5995\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5985 - val_loss: 0.5911\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5902 - val_loss: 0.5825\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5833 - val_loss: 0.5757\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5773 - val_loss: 0.5708\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5719 - val_loss: 0.5658\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5674 - val_loss: 0.5622\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5632 - val_loss: 0.5594\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5596 - val_loss: 0.5556\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5567 - val_loss: 0.5534\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5538 - val_loss: 0.5528\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5517 - val_loss: 0.5493\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5495 - val_loss: 0.5482\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5476 - val_loss: 0.5457\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5460 - val_loss: 0.5454\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5445 - val_loss: 0.5433\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5431 - val_loss: 0.5412\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5422 - val_loss: 0.5409\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5408 - val_loss: 0.5425\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5401 - val_loss: 0.5420\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5392 - val_loss: 0.5385\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5389 - val_loss: 0.5383\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5377 - val_loss: 0.5403\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5377 - val_loss: 0.5380\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5370 - val_loss: 0.5363\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5367 - val_loss: 0.5366\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5356 - val_loss: 0.5381\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5358 - val_loss: 0.5356\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5352 - val_loss: 0.5371\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.5352 - val_loss: 0.5360\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5349 - val_loss: 0.5361\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5346 - val_loss: 0.5353\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5344 - val_loss: 0.5342\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5342 - val_loss: 0.5338\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5340 - val_loss: 0.5336\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5337 - val_loss: 0.5349\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5337 - val_loss: 0.5350\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5332 - val_loss: 0.5366\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5334 - val_loss: 0.5340\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5333 - val_loss: 0.5342\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5327 - val_loss: 0.5327\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5333 - val_loss: 0.5335\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5331 - val_loss: 0.5334\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5326 - val_loss: 0.5330\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5330 - val_loss: 0.5335\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5328 - val_loss: 0.5334\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5325 - val_loss: 0.5326\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5327 - val_loss: 0.5325\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5326 - val_loss: 0.5335\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5325 - val_loss: 0.5334\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5322 - val_loss: 0.5325\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5324 - val_loss: 0.5336\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5325 - val_loss: 0.5331\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5324 - val_loss: 0.5336\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5322 - val_loss: 0.5348\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5325 - val_loss: 0.5328\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5320 - val_loss: 0.5346\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5325 - val_loss: 0.5328\n",
      "\n",
      "val/train: 1.00\n",
      "121/121 [==============================] - 0s 835us/step - loss: 0.5179\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 7s - loss: 7.3591 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0007s vs `on_train_batch_begin` time: 0.0008s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0007s vs `on_train_batch_end` time: 0.0093s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.8567 - val_loss: 1.5099\n",
      "\n",
      "val/train: 0.39\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9945 - val_loss: 0.7307\n",
      "\n",
      "val/train: 0.73\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6329 - val_loss: 0.5981\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5677 - val_loss: 0.5717\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5522 - val_loss: 0.5632\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5459 - val_loss: 0.5580\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5416 - val_loss: 0.5541\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5381 - val_loss: 0.5518\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5353 - val_loss: 0.5496\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5330 - val_loss: 0.5465\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5308 - val_loss: 0.5449\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5291 - val_loss: 0.5435\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5276 - val_loss: 0.5424\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 0.5396\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 0.5383\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5244 - val_loss: 0.5378\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 0.5368\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5226 - val_loss: 0.5366\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5221 - val_loss: 0.5365\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5217 - val_loss: 0.5354\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5212 - val_loss: 0.5350\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5208 - val_loss: 0.5351\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5206 - val_loss: 0.5347\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5204 - val_loss: 0.5340\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5201 - val_loss: 0.5341\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5198 - val_loss: 0.5339\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5197 - val_loss: 0.5337\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5194 - val_loss: 0.5329\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5193 - val_loss: 0.5327\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5194 - val_loss: 0.5328\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5327\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5335\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5189 - val_loss: 0.5326\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5186 - val_loss: 0.5337\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5188 - val_loss: 0.5333\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5190 - val_loss: 0.5327\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5190 - val_loss: 0.5329\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5188 - val_loss: 0.5328\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5186 - val_loss: 0.5338\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5187 - val_loss: 0.5327\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5188 - val_loss: 0.5329\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5187 - val_loss: 0.5336\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5187 - val_loss: 0.5330\n",
      "\n",
      "val/train: 1.03\n",
      "121/121 [==============================] - 0s 756us/step - loss: 0.5451\n",
      "Epoch 1/100\n",
      "  4/242 [..............................] - ETA: 3s - loss: 5.7782 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0079s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5862 - val_loss: 0.7616\n",
      "\n",
      "val/train: 0.48\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7251 - val_loss: 0.6700\n",
      "\n",
      "val/train: 0.92\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6632 - val_loss: 0.6239\n",
      "\n",
      "val/train: 0.94\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6177 - val_loss: 0.5833\n",
      "\n",
      "val/train: 0.94\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5812 - val_loss: 0.5535\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5525 - val_loss: 0.5325\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5305 - val_loss: 0.5132\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5132 - val_loss: 0.5027\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5008 - val_loss: 0.4924\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4914 - val_loss: 0.4851\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4846 - val_loss: 0.4801\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4778 - val_loss: 0.4775\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4737 - val_loss: 0.4735\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4681 - val_loss: 0.4700\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4653 - val_loss: 0.4659\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4611 - val_loss: 0.4641\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4582 - val_loss: 0.4613\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4547 - val_loss: 0.4609\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4523 - val_loss: 0.4584\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4496 - val_loss: 0.4567\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4470 - val_loss: 0.4550\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4445 - val_loss: 0.4552\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4427 - val_loss: 0.4519\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4404 - val_loss: 0.4498\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.4500\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4367 - val_loss: 0.4493\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4350 - val_loss: 0.4469\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4329 - val_loss: 0.4475\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4314 - val_loss: 0.4449\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4291 - val_loss: 0.4449\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4282 - val_loss: 0.4441\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4256 - val_loss: 0.4438\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4246 - val_loss: 0.4462\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4231 - val_loss: 0.4427\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4221 - val_loss: 0.4412\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4204 - val_loss: 0.4408\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4196 - val_loss: 0.4398\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4182 - val_loss: 0.4404\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4170 - val_loss: 0.4399\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4157 - val_loss: 0.4379\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4142 - val_loss: 0.4375\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4129 - val_loss: 0.4384\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4121 - val_loss: 0.4385\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.4375\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4101 - val_loss: 0.4372\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4086 - val_loss: 0.4359\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4077 - val_loss: 0.4391\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4071 - val_loss: 0.4347\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4061 - val_loss: 0.4338\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4049 - val_loss: 0.4366\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4044 - val_loss: 0.4327\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4029 - val_loss: 0.4320\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4017 - val_loss: 0.4323\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4015 - val_loss: 0.4314\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4006 - val_loss: 0.4310\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4001 - val_loss: 0.4303\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3989 - val_loss: 0.4304\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3979 - val_loss: 0.4307\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.4299\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.4295\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.4284\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 0.4281\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3940 - val_loss: 0.4274\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 0.4273\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3922 - val_loss: 0.4262\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.4267\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.4267\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3901 - val_loss: 0.4310\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.4246\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.4267\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.4249\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.4259\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.4237\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.4227\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.4239\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3843 - val_loss: 0.4237\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.4206\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.4286\n",
      "\n",
      "val/train: 1.12\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.4202\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.4198\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.4217\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.4209\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.4204\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.4228\n",
      "\n",
      "val/train: 1.12\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 0.4163\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3780 - val_loss: 0.4176\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.4175\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3775 - val_loss: 0.4151\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3767 - val_loss: 0.4171\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3760 - val_loss: 0.4139\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3753 - val_loss: 0.4137\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3760 - val_loss: 0.4122\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.4142\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3742 - val_loss: 0.4156\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3751 - val_loss: 0.4119\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.4104\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.4103\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.4106\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3709 - val_loss: 0.4088\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3708 - val_loss: 0.4127\n",
      "\n",
      "val/train: 1.11\n",
      "121/121 [==============================] - 0s 830us/step - loss: 1.4641\n",
      "Epoch 1/100\n",
      "  4/242 [..............................] - ETA: 4s - loss: 5.1640 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0078s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6478 - val_loss: 0.7777\n",
      "\n",
      "val/train: 0.47\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7878 - val_loss: 0.6817\n",
      "\n",
      "val/train: 0.87\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6764 - val_loss: 0.6173\n",
      "\n",
      "val/train: 0.91\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6202 - val_loss: 0.5827\n",
      "\n",
      "val/train: 0.94\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5783 - val_loss: 0.5543\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5518 - val_loss: 0.5326\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5303 - val_loss: 0.5191\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5149 - val_loss: 0.5097\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5056 - val_loss: 0.4962\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4968 - val_loss: 0.4889\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4902 - val_loss: 0.4830\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4844 - val_loss: 0.4814\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4803 - val_loss: 0.4756\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4766 - val_loss: 0.4734\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4727 - val_loss: 0.4692\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4697 - val_loss: 0.4683\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4658 - val_loss: 0.4681\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4632 - val_loss: 0.4607\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4608 - val_loss: 0.4596\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4583 - val_loss: 0.4568\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4555 - val_loss: 0.4553\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4532 - val_loss: 0.4546\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4510 - val_loss: 0.4530\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4491 - val_loss: 0.4495\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4467 - val_loss: 0.4465\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4451 - val_loss: 0.4462\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4435 - val_loss: 0.4454\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4414 - val_loss: 0.4423\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4398 - val_loss: 0.4404\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4378 - val_loss: 0.4391\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4367 - val_loss: 0.4378\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4349 - val_loss: 0.4379\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4332 - val_loss: 0.4356\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4319 - val_loss: 0.4345\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4308 - val_loss: 0.4326\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4290 - val_loss: 0.4315\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4277 - val_loss: 0.4311\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4292\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4251 - val_loss: 0.4289\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4241 - val_loss: 0.4296\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4225 - val_loss: 0.4292\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4217 - val_loss: 0.4251\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4200 - val_loss: 0.4251\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4195 - val_loss: 0.4228\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4180 - val_loss: 0.4216\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4172 - val_loss: 0.4215\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4159 - val_loss: 0.4242\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4146 - val_loss: 0.4198\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4142 - val_loss: 0.4205\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4126 - val_loss: 0.4173\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4118 - val_loss: 0.4168\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4107 - val_loss: 0.4168\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.4197\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4088 - val_loss: 0.4138\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4075 - val_loss: 0.4135\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4071 - val_loss: 0.4134\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.4120\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4051 - val_loss: 0.4131\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4040 - val_loss: 0.4102\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4030 - val_loss: 0.4094\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4029 - val_loss: 0.4096\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4014 - val_loss: 0.4106\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.4069\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.4101\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3991 - val_loss: 0.4060\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.4112\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3973 - val_loss: 0.4077\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3969 - val_loss: 0.4062\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 0.4076\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.4028\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3948 - val_loss: 0.4034\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.4031\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.4080\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.4004\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.3995\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.3988\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.3985\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3899 - val_loss: 0.3974\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.4019\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.3961\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.3961\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.3999\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3864 - val_loss: 0.3946\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3860 - val_loss: 0.3968\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3942\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3845 - val_loss: 0.3942\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.3946\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3927\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3913\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3956\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.3935\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3810 - val_loss: 0.3930\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3799 - val_loss: 0.3897\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.3919\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3791 - val_loss: 0.3896\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.3886\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.3888\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3777 - val_loss: 0.3921\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3889\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3766 - val_loss: 0.3865\n",
      "\n",
      "val/train: 1.03\n",
      "121/121 [==============================] - 0s 931us/step - loss: 0.3754\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 5.2976 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0085s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5520 - val_loss: 0.7481\n",
      "\n",
      "val/train: 0.48\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7290 - val_loss: 0.6666\n",
      "\n",
      "val/train: 0.91\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6502 - val_loss: 0.6177\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6004 - val_loss: 0.5823\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5728 - val_loss: 0.5567\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5404 - val_loss: 0.5374\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5200 - val_loss: 0.5224\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5068 - val_loss: 0.5106\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4976 - val_loss: 0.5027\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 0.4968\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.4902\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4736 - val_loss: 0.4852\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4683 - val_loss: 0.4809\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4651 - val_loss: 0.4766\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4604 - val_loss: 0.4734\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4564 - val_loss: 0.4705\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4533 - val_loss: 0.4691\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4505 - val_loss: 0.4650\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4471 - val_loss: 0.4630\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4451 - val_loss: 0.4594\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4416 - val_loss: 0.4573\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4390 - val_loss: 0.4563\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4365 - val_loss: 0.4538\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4343 - val_loss: 0.4523\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4329 - val_loss: 0.4492\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4315 - val_loss: 0.4499\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4291 - val_loss: 0.4461\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4282 - val_loss: 0.4452\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4256 - val_loss: 0.4444\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4241 - val_loss: 0.4420\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4221 - val_loss: 0.4405\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4228 - val_loss: 0.4394\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4196 - val_loss: 0.4371\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4181 - val_loss: 0.4380\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4174 - val_loss: 0.4358\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4158 - val_loss: 0.4342\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4141 - val_loss: 0.4329\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4143 - val_loss: 0.4312\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4123 - val_loss: 0.4303\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4109 - val_loss: 0.4297\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4097 - val_loss: 0.4299\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4087 - val_loss: 0.4277\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4078 - val_loss: 0.4275\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4071 - val_loss: 0.4250\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.4244\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4048 - val_loss: 0.4232\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4034 - val_loss: 0.4238\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4028 - val_loss: 0.4214\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4019 - val_loss: 0.4206\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.4202\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3999 - val_loss: 0.4184\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3996 - val_loss: 0.4179\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.4175\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3967 - val_loss: 0.4167\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.4157\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3947 - val_loss: 0.4157\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3940 - val_loss: 0.4138\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.4121\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3922 - val_loss: 0.4120\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.4115\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.4100\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.4091\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.4080\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.4078\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.4079\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3864 - val_loss: 0.4061\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.4054\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.4042\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3838 - val_loss: 0.4048\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.4038\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.4063\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.4019\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3814 - val_loss: 0.4010\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3802 - val_loss: 0.3999\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.3992\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.4008\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3778 - val_loss: 0.3975\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3778 - val_loss: 0.3969\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3769 - val_loss: 0.3967\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3758 - val_loss: 0.3959\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.3952\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.3957\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.3942\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3733 - val_loss: 0.3943\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.3923\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.3920\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3710 - val_loss: 0.3917\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3701 - val_loss: 0.3907\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.3906\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.3895\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.3889\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3678 - val_loss: 0.3884\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3670 - val_loss: 0.3873\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.3870\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.3862\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3651 - val_loss: 0.3868\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3645 - val_loss: 0.3863\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3638 - val_loss: 0.3846\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3631 - val_loss: 0.3855\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3625 - val_loss: 0.3845\n",
      "\n",
      "val/train: 1.06\n",
      "121/121 [==============================] - 0s 781us/step - loss: 0.3944\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 7.3352  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0086s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2327 - val_loss: 0.6715\n",
      "\n",
      "val/train: 0.54\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6386 - val_loss: 0.5805\n",
      "\n",
      "val/train: 0.91\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5632 - val_loss: 0.5260\n",
      "\n",
      "val/train: 0.93\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5140 - val_loss: 0.4931\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.4725\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4658 - val_loss: 0.4597\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4525 - val_loss: 0.4592\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4418 - val_loss: 0.4446\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4332 - val_loss: 0.4399\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4265 - val_loss: 0.4357\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4206 - val_loss: 0.4328\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4160 - val_loss: 0.4295\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4112 - val_loss: 0.4298\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4077 - val_loss: 0.4242\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4040 - val_loss: 0.4222\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4004 - val_loss: 0.4200\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.4248\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3951 - val_loss: 0.4193\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.4199\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.4165\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.4144\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3838 - val_loss: 0.4191\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.4139\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3803 - val_loss: 0.4119\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.4099\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3758 - val_loss: 0.4066\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3734 - val_loss: 0.4037\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3713 - val_loss: 0.4032\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 0.4110\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3680 - val_loss: 0.4026\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3669 - val_loss: 0.4016\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.4023\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.4163\n",
      "\n",
      "val/train: 1.15\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.4165\n",
      "\n",
      "val/train: 1.14\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3621 - val_loss: 0.4014\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.3939\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3583 - val_loss: 0.3933\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3563 - val_loss: 0.3905\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3555 - val_loss: 0.3886\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3539 - val_loss: 0.3888\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3521 - val_loss: 0.3831\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.3801\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3498 - val_loss: 0.4041\n",
      "\n",
      "val/train: 1.16\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.3873\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3491 - val_loss: 0.3770\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3468 - val_loss: 0.3801\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3440 - val_loss: 0.3865\n",
      "\n",
      "val/train: 1.12\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.3712\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.3767\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3416 - val_loss: 0.3687\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.3672\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.3648\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3388 - val_loss: 0.3645\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3601\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3346 - val_loss: 0.3660\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3350 - val_loss: 0.3606\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3324 - val_loss: 0.3619\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.3547\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 0.3556\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 0.3566\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3278 - val_loss: 0.3520\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 0.3508\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3259 - val_loss: 0.3511\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3259 - val_loss: 0.3484\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3235 - val_loss: 0.3615\n",
      "\n",
      "val/train: 1.12\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3226 - val_loss: 0.3465\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3226 - val_loss: 0.3462\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3207 - val_loss: 0.3426\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3206 - val_loss: 0.3383\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3200 - val_loss: 0.3524\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.3436\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.3362\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3160 - val_loss: 0.3398\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3154 - val_loss: 0.3343\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3159 - val_loss: 0.3341\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3125 - val_loss: 0.3452\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3145 - val_loss: 0.3302\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3133 - val_loss: 0.3330\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3102 - val_loss: 0.3317\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3101 - val_loss: 0.3275\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3099 - val_loss: 0.3311\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.3358\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3079 - val_loss: 0.3261\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3061 - val_loss: 0.3273\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3057 - val_loss: 0.3254\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3034 - val_loss: 0.3271\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3260 - val_loss: 0.3272\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3063 - val_loss: 0.3242\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3334 - val_loss: 0.3320\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3125 - val_loss: 0.3247\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3036 - val_loss: 0.3218\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3019 - val_loss: 0.3183\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2994 - val_loss: 0.3255\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3012 - val_loss: 0.3180\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2991 - val_loss: 0.3214\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2984 - val_loss: 0.3201\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2981 - val_loss: 0.3188\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2962 - val_loss: 0.3321\n",
      "\n",
      "val/train: 1.12\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3029 - val_loss: 0.3190\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2954 - val_loss: 0.3175\n",
      "\n",
      "val/train: 1.07\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3524\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 6.6997 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0090s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2311 - val_loss: 0.6731\n",
      "\n",
      "val/train: 0.55\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6443 - val_loss: 0.5880\n",
      "\n",
      "val/train: 0.91\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5692 - val_loss: 0.5311\n",
      "\n",
      "val/train: 0.93\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5212 - val_loss: 0.4980\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4910 - val_loss: 0.4780\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.4628\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4586 - val_loss: 0.4536\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4489 - val_loss: 0.4456\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4403 - val_loss: 0.4436\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4350 - val_loss: 0.4375\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4287 - val_loss: 0.4413\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4230 - val_loss: 0.4270\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4186 - val_loss: 0.4278\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4141 - val_loss: 0.4203\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4109 - val_loss: 0.4228\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4127 - val_loss: 0.4168\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4038 - val_loss: 0.4088\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3996 - val_loss: 0.4104\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.4081\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3940 - val_loss: 0.4033\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.4054\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.3987\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.3963\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.3957\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.3991\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 0.3930\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.3933\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.3932\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3731 - val_loss: 0.3863\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3708 - val_loss: 0.3854\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3696 - val_loss: 0.3820\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3681 - val_loss: 0.3781\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.3757\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.3752\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3614 - val_loss: 0.3771\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3597 - val_loss: 0.3712\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3582 - val_loss: 0.3755\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3553 - val_loss: 0.3726\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.3784\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3540 - val_loss: 0.3699\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.3652\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3509 - val_loss: 0.3657\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3577 - val_loss: 0.3610\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.3656\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3450 - val_loss: 0.3597\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3443 - val_loss: 0.3584\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3446 - val_loss: 0.3634\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3414 - val_loss: 0.3609\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.3532\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3383 - val_loss: 0.3619\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3372 - val_loss: 0.3576\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3803 - val_loss: 0.3535\n",
      "\n",
      "val/train: 0.93\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3363 - val_loss: 0.3504\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3332 - val_loss: 0.3522\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3329 - val_loss: 0.3519\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3321 - val_loss: 0.3454\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 0.3485\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3292 - val_loss: 0.3424\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3282 - val_loss: 0.3420\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 0.3439\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3261 - val_loss: 0.3405\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3246 - val_loss: 0.3457\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3241 - val_loss: 0.3377\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3227 - val_loss: 0.3366\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3225 - val_loss: 0.3396\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3214 - val_loss: 0.3373\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3200 - val_loss: 0.3347\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3188 - val_loss: 0.3416\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.3339\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3183 - val_loss: 0.3372\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.3295\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3162 - val_loss: 0.3360\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3174 - val_loss: 0.3293\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3129 - val_loss: 0.3301\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3125 - val_loss: 0.3315\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3123 - val_loss: 0.3286\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3109 - val_loss: 0.3307\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3113 - val_loss: 0.3272\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3094 - val_loss: 0.3358\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3099 - val_loss: 0.3272\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3082 - val_loss: 0.3271\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3077 - val_loss: 0.3244\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3067 - val_loss: 0.3225\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3080 - val_loss: 0.3227\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3398 - val_loss: 0.3346\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3060 - val_loss: 0.3202\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3049 - val_loss: 0.3257\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3038 - val_loss: 0.3239\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3023 - val_loss: 0.3217\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3020 - val_loss: 0.3200\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3011 - val_loss: 0.3215\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3007 - val_loss: 0.3166\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3003 - val_loss: 0.3208\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2999 - val_loss: 0.3179\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2991 - val_loss: 0.3160\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2974 - val_loss: 0.3205\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2987 - val_loss: 0.3172\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2981 - val_loss: 0.3150\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2990 - val_loss: 0.3205\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2969 - val_loss: 0.3171\n",
      "\n",
      "val/train: 1.07\n",
      "121/121 [==============================] - 0s 790us/step - loss: 0.3129\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 6.2443  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0088s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2760 - val_loss: 0.6985\n",
      "\n",
      "val/train: 0.55\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8500 - val_loss: 0.6084\n",
      "\n",
      "val/train: 0.72\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5891 - val_loss: 0.5445\n",
      "\n",
      "val/train: 0.92\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5259 - val_loss: 0.5080\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4926 - val_loss: 0.4853\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.4722\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.4626\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4465 - val_loss: 0.4522\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4384 - val_loss: 0.4463\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4308 - val_loss: 0.4402\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4247 - val_loss: 0.4352\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4183 - val_loss: 0.4333\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4134 - val_loss: 0.4288\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4094 - val_loss: 0.4290\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4046 - val_loss: 0.4222\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4013 - val_loss: 0.4183\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3972 - val_loss: 0.4168\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3943 - val_loss: 0.4121\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.4174\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.4047\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.4104\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.4011\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3803 - val_loss: 0.4033\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3783 - val_loss: 0.3979\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.3969\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3740 - val_loss: 0.3941\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.3921\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.3927\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3682 - val_loss: 0.3886\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.3863\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3639 - val_loss: 0.3858\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.3832\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3609 - val_loss: 0.3807\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.3825\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3568 - val_loss: 0.3762\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3544 - val_loss: 0.3786\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.3733\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.3727\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3503 - val_loss: 0.3716\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3486 - val_loss: 0.3728\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.3682\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3452 - val_loss: 0.3688\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3451 - val_loss: 0.3666\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.3651\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3419 - val_loss: 0.3645\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3398 - val_loss: 0.3660\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3391 - val_loss: 0.3620\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3384 - val_loss: 0.3613\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3355 - val_loss: 0.3592\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.3610\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3339 - val_loss: 0.3592\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3333 - val_loss: 0.3559\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.3546\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3332 - val_loss: 0.3523\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.3520\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3295 - val_loss: 0.3511\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 0.3509\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3265 - val_loss: 0.3543\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3260 - val_loss: 0.3517\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3246 - val_loss: 0.3486\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 0.3490\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.3473\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3227 - val_loss: 0.3473\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3218 - val_loss: 0.3463\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3209 - val_loss: 0.3453\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3196 - val_loss: 0.3429\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3186 - val_loss: 0.3471\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3182 - val_loss: 0.3438\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3175 - val_loss: 0.3443\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3153 - val_loss: 0.3474\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3161 - val_loss: 0.3446\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3137 - val_loss: 0.3451\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3139 - val_loss: 0.3499\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3134 - val_loss: 0.3436\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3126 - val_loss: 0.3379\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3111 - val_loss: 0.3414\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3112 - val_loss: 0.3375\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3100 - val_loss: 0.3406\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3096 - val_loss: 0.3344\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3085 - val_loss: 0.3355\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3080 - val_loss: 0.3350\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3070 - val_loss: 0.3426\n",
      "\n",
      "val/train: 1.12\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3070 - val_loss: 0.3331\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3057 - val_loss: 0.3315\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3054 - val_loss: 0.3308\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3040 - val_loss: 0.3301\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3039 - val_loss: 0.3319\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3025 - val_loss: 0.3305\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3023 - val_loss: 0.3328\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3027 - val_loss: 0.3341\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3016 - val_loss: 0.3406\n",
      "\n",
      "val/train: 1.13\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3025 - val_loss: 0.3266\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2997 - val_loss: 0.3270\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2984 - val_loss: 0.3423\n",
      "\n",
      "val/train: 1.15\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2989 - val_loss: 0.3298\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2987 - val_loss: 0.3321\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2971 - val_loss: 0.3261\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2985 - val_loss: 0.3319\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2971 - val_loss: 0.3248\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2960 - val_loss: 0.3272\n",
      "\n",
      "val/train: 1.11\n",
      "121/121 [==============================] - 0s 983us/step - loss: 0.3365\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 5.1452 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0007s vs `on_train_batch_end` time: 0.0090s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9953 - val_loss: 0.5498\n",
      "\n",
      "val/train: 0.55\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5408 - val_loss: 0.5391\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5337 - val_loss: 0.5382\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5308 - val_loss: 0.5368\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5296 - val_loss: 0.5396\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 0.5517\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5209 - val_loss: 0.5466\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5223 - val_loss: 0.5574\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5201 - val_loss: 0.5525\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5189 - val_loss: 0.5633\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5187 - val_loss: 0.5614\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5163 - val_loss: 0.5820\n",
      "\n",
      "val/train: 1.13\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5153 - val_loss: 0.5780\n",
      "\n",
      "val/train: 1.12\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5180 - val_loss: 0.5775\n",
      "\n",
      "val/train: 1.11\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.8346\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 7s - loss: 6.3433  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0007s vs `on_train_batch_end` time: 0.0102s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5220 - val_loss: 0.9714\n",
      "\n",
      "val/train: 0.64\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.1794 - val_loss: 3.5452\n",
      "\n",
      "val/train: 1.12\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 298.6781 - val_loss: 22.5497\n",
      "\n",
      "val/train: 0.08\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2295.5085 - val_loss: 160.5967\n",
      "\n",
      "val/train: 0.07\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 16604.1816 - val_loss: 1191.2797\n",
      "\n",
      "val/train: 0.07\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 116578.4922 - val_loss: 10027.1104\n",
      "\n",
      "val/train: 0.09\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 887373.7500 - val_loss: 71270.8828\n",
      "\n",
      "val/train: 0.08\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6354991.5000 - val_loss: 486196.8750\n",
      "\n",
      "val/train: 0.08\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 48205076.0000 - val_loss: 3413434.5000\n",
      "\n",
      "val/train: 0.07\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 335579776.0000 - val_loss: 34455444.0000\n",
      "\n",
      "val/train: 0.10\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 157258336.0000 - val_loss: 184365056.0000\n",
      "\n",
      "val/train: 1.17\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5507\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 7s - loss: 4.5275  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0104s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 6.0217 - val_loss: 1.0443\n",
      "\n",
      "val/train: 0.17\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 36.1229 - val_loss: 3.3567\n",
      "\n",
      "val/train: 0.09\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 265.6751 - val_loss: 27.4954\n",
      "\n",
      "val/train: 0.10\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1899.1469 - val_loss: 147.6587\n",
      "\n",
      "val/train: 0.08\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 917.2376 - val_loss: 1060.5555\n",
      "\n",
      "val/train: 1.16\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 6825.2236 - val_loss: 7771.2998\n",
      "\n",
      "val/train: 1.14\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 50543.6523 - val_loss: 56648.5430\n",
      "\n",
      "val/train: 1.12\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 356234.8438 - val_loss: 438282.7812\n",
      "\n",
      "val/train: 1.23\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2642287.2500 - val_loss: 3136981.5000\n",
      "\n",
      "val/train: 1.19\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 20466704.0000 - val_loss: 22579468.0000\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2331073280.0000 - val_loss: 173361680.0000\n",
      "\n",
      "val/train: 0.07\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.7120\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 8s - loss: 6.8033  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0012s vs `on_train_batch_end` time: 0.0122s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4499 - val_loss: 0.7856\n",
      "\n",
      "val/train: 0.54\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7477 - val_loss: 0.6818\n",
      "\n",
      "val/train: 0.91\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6705 - val_loss: 0.6279\n",
      "\n",
      "val/train: 0.94\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6200 - val_loss: 0.5890\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5813 - val_loss: 0.5610\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5520 - val_loss: 0.5362\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5293 - val_loss: 0.5192\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5126 - val_loss: 0.5066\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4993 - val_loss: 0.4953\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4890 - val_loss: 0.4890\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.4805\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4743 - val_loss: 0.4771\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4681 - val_loss: 0.4708\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4631 - val_loss: 0.4665\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4581 - val_loss: 0.4638\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.4598\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4503 - val_loss: 0.4579\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4473 - val_loss: 0.4543\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4440 - val_loss: 0.4518\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4415 - val_loss: 0.4506\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4387 - val_loss: 0.4490\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4364 - val_loss: 0.4458\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4335 - val_loss: 0.4445\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4311 - val_loss: 0.4424\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4285 - val_loss: 0.4441\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4269 - val_loss: 0.4406\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4248 - val_loss: 0.4408\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4232 - val_loss: 0.4371\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4207 - val_loss: 0.4377\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4196 - val_loss: 0.4362\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4178 - val_loss: 0.4340\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4160 - val_loss: 0.4325\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4143 - val_loss: 0.4328\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4129 - val_loss: 0.4313\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4117 - val_loss: 0.4307\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4102 - val_loss: 0.4324\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4088 - val_loss: 0.4300\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4073 - val_loss: 0.4308\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.4307\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4051 - val_loss: 0.4294\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4037 - val_loss: 0.4293\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4024 - val_loss: 0.4291\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4015 - val_loss: 0.4296\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4010 - val_loss: 0.4271\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.4276\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3986 - val_loss: 0.4262\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.4269\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3969 - val_loss: 0.4240\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.4245\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3947 - val_loss: 0.4242\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3942 - val_loss: 0.4236\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3931 - val_loss: 0.4219\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.4221\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.4207\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.4192\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3891 - val_loss: 0.4182\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.4169\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3865 - val_loss: 0.4206\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.4177\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.4139\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.4165\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.4131\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.4120\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3819 - val_loss: 0.4107\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.4102\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.4106\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.4093\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.4091\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3783 - val_loss: 0.4074\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.4056\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3759 - val_loss: 0.4070\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.4028\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.4014\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.4002\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.4014\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3731 - val_loss: 0.3983\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.3974\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3712 - val_loss: 0.3963\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3703 - val_loss: 0.3961\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3696 - val_loss: 0.3956\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3696 - val_loss: 0.3932\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.3922\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3678 - val_loss: 0.3915\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3663 - val_loss: 0.3927\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3663 - val_loss: 0.3906\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3652 - val_loss: 0.3893\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3653 - val_loss: 0.3866\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.3853\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3629 - val_loss: 0.3878\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3628 - val_loss: 0.3828\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.3817\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3612 - val_loss: 0.3817\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.3805\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.3794\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.3789\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.3824\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3589 - val_loss: 0.3769\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.3775\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.3794\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3569 - val_loss: 0.3744\n",
      "\n",
      "val/train: 1.05\n",
      "121/121 [==============================] - 0s 790us/step - loss: 0.5808\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 9.6448 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0087s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6860 - val_loss: 0.6647\n",
      "\n",
      "val/train: 0.39\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6707 - val_loss: 0.5725\n",
      "\n",
      "val/train: 0.85\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5652 - val_loss: 0.5312\n",
      "\n",
      "val/train: 0.94\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5280 - val_loss: 0.5197\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5103 - val_loss: 0.4876\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4928 - val_loss: 0.4827\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4818 - val_loss: 0.4730\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4823 - val_loss: 0.4677\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4700 - val_loss: 0.4657\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4648 - val_loss: 0.4633\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.4550\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4561 - val_loss: 0.4531\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4519 - val_loss: 0.4470\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4498 - val_loss: 0.4420\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4446 - val_loss: 0.4441\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4414 - val_loss: 0.4384\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4390 - val_loss: 0.4410\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4368 - val_loss: 0.4316\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4342 - val_loss: 0.4347\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4315 - val_loss: 0.4271\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4303 - val_loss: 0.4271\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4280 - val_loss: 0.4252\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.4253\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4247 - val_loss: 0.4214\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4217 - val_loss: 0.4257\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4205 - val_loss: 0.4191\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4189 - val_loss: 0.4156\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4170 - val_loss: 0.4219\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4154 - val_loss: 0.4171\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4146 - val_loss: 0.4138\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4137 - val_loss: 0.4126\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4117 - val_loss: 0.4078\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4097 - val_loss: 0.4077\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4082 - val_loss: 0.4058\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4066 - val_loss: 0.4069\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4053 - val_loss: 0.4071\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.4179\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4028 - val_loss: 0.4014\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 0.4028\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4004 - val_loss: 0.3997\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3993 - val_loss: 0.3992\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3988 - val_loss: 0.3999\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3971 - val_loss: 0.3984\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3965 - val_loss: 0.4064\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3949 - val_loss: 0.4043\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.3953\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3929 - val_loss: 0.3986\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.3923\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.4009\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.4017\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.3904\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3889 - val_loss: 0.3972\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.3877\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.4013\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.3868\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.3895\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.3983\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3894\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3914\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3842\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3852\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.3936\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3812 - val_loss: 0.3884\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.3828\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3795 - val_loss: 0.3815\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.3850\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.3837\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3775 - val_loss: 0.3797\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3775 - val_loss: 0.3806\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3813\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.3853\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.3808\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3790\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3948\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.3773\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3780 - val_loss: 0.3798\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3728 - val_loss: 0.3789\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.3765\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3727 - val_loss: 0.3790\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.3765\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.3754\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3724 - val_loss: 0.3757\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3721 - val_loss: 0.3792\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3706 - val_loss: 0.3784\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.3803\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3700 - val_loss: 0.3726\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3811 - val_loss: 0.3732\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3702 - val_loss: 0.3716\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.3724\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3684 - val_loss: 0.3763\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3838 - val_loss: 0.3814\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3727 - val_loss: 0.3710\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3681 - val_loss: 0.3851\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.3710\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.3712\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.3702\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3670 - val_loss: 0.3679\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3673 - val_loss: 0.3717\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.3689\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3670 - val_loss: 0.3737\n",
      "\n",
      "val/train: 1.02\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3664\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 6s - loss: 6.7598 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0085s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4149 - val_loss: 0.6901\n",
      "\n",
      "val/train: 0.49\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6345 - val_loss: 0.5844\n",
      "\n",
      "val/train: 0.92\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5643 - val_loss: 0.5446\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5376 - val_loss: 0.5205\n",
      "\n",
      "val/train: 0.97\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5089 - val_loss: 0.5047\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4936 - val_loss: 0.4983\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.4846\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 0.4799\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4648 - val_loss: 0.4796\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.4670\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4542 - val_loss: 0.4616\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4508 - val_loss: 0.4594\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4646 - val_loss: 0.4542\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4470 - val_loss: 0.4508\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4401 - val_loss: 0.4464\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4372 - val_loss: 0.4451\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4315 - val_loss: 0.4408\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4285 - val_loss: 0.4412\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4256 - val_loss: 0.4378\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4230 - val_loss: 0.4372\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4201 - val_loss: 0.4313\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4186 - val_loss: 0.4305\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4165 - val_loss: 0.4283\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4143 - val_loss: 0.4254\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4113 - val_loss: 0.4264\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4123 - val_loss: 0.4217\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4126 - val_loss: 0.4236\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4079 - val_loss: 0.4192\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.4171\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4037 - val_loss: 0.4167\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4027 - val_loss: 0.4151\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4007 - val_loss: 0.4126\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4007 - val_loss: 0.4167\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3990 - val_loss: 0.4101\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4045 - val_loss: 0.4093\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3970 - val_loss: 0.4059\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4028 - val_loss: 0.4074\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3953 - val_loss: 0.4074\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.4075\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3902 - val_loss: 0.4031\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.4003\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3888 - val_loss: 0.4011\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.3986\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.3968\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3921 - val_loss: 0.3971\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3844 - val_loss: 0.3941\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.3963\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3858 - val_loss: 0.3978\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.3942\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.3957\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 0.3988\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.3913\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3780 - val_loss: 0.3874\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.3896\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.3861\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3756 - val_loss: 0.3875\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3771 - val_loss: 0.3865\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3749 - val_loss: 0.3853\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3745 - val_loss: 0.3852\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.3892\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3731 - val_loss: 0.3879\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3719 - val_loss: 0.3834\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.3849\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3769 - val_loss: 0.3793\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3702 - val_loss: 0.3790\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3699 - val_loss: 0.3820\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3705 - val_loss: 0.3816\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.3786\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3684 - val_loss: 0.3826\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3672 - val_loss: 0.3790\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.3833\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.3774\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.3748\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.3818\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3645 - val_loss: 0.3761\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.3721\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3647 - val_loss: 0.3727\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3689 - val_loss: 0.3753\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3626 - val_loss: 0.3737\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3746\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3624 - val_loss: 0.3830\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3677 - val_loss: 0.3735\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3670 - val_loss: 0.3704\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3612 - val_loss: 0.3695\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3620 - val_loss: 0.3737\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3602 - val_loss: 0.3688\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3602 - val_loss: 0.3704\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3593 - val_loss: 0.3685\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.3674\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.3673\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3582 - val_loss: 0.3698\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.3704\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.3684\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.3712\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3692 - val_loss: 0.3656\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3676 - val_loss: 0.3704\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3556 - val_loss: 0.3700\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3558 - val_loss: 0.3637\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3622 - val_loss: 0.3730\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.3699\n",
      "\n",
      "val/train: 1.04\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3804\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 7s - loss: 5.1804  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0099s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8059 - val_loss: 0.5051\n",
      "\n",
      "val/train: 0.63\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4736 - val_loss: 0.4524\n",
      "\n",
      "val/train: 0.96\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4307 - val_loss: 0.4313\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4094 - val_loss: 0.4184\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4033 - val_loss: 0.3995\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3856 - val_loss: 0.4005\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3733 - val_loss: 0.3746\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3691 - val_loss: 0.3686\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3579 - val_loss: 0.3648\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3506 - val_loss: 0.3564\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3466 - val_loss: 0.3412\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3428 - val_loss: 0.3609\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3374 - val_loss: 0.3311\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3275 - val_loss: 0.3585\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3256 - val_loss: 0.3672\n",
      "\n",
      "val/train: 1.13\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3229 - val_loss: 0.3264\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3180 - val_loss: 0.3379\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3117 - val_loss: 0.3445\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3130 - val_loss: 0.3424\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3103 - val_loss: 0.3210\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.3586\n",
      "\n",
      "val/train: 1.16\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3042 - val_loss: 0.3967\n",
      "\n",
      "val/train: 1.30\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3055 - val_loss: 0.3637\n",
      "\n",
      "val/train: 1.19\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3012 - val_loss: 0.3281\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2972 - val_loss: 0.3370\n",
      "\n",
      "val/train: 1.13\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2950 - val_loss: 0.3643\n",
      "\n",
      "val/train: 1.23\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2944 - val_loss: 0.3181\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2906 - val_loss: 0.3338\n",
      "\n",
      "val/train: 1.15\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2964 - val_loss: 0.3254\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2913 - val_loss: 0.3557\n",
      "\n",
      "val/train: 1.22\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2908 - val_loss: 0.3785\n",
      "\n",
      "val/train: 1.30\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2862 - val_loss: 0.3264\n",
      "\n",
      "val/train: 1.14\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2845 - val_loss: 0.3593\n",
      "\n",
      "val/train: 1.26\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2823 - val_loss: 0.3235\n",
      "\n",
      "val/train: 1.15\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 0.3255\n",
      "\n",
      "val/train: 1.16\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2838 - val_loss: 0.3556\n",
      "\n",
      "val/train: 1.25\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2802 - val_loss: 0.3355\n",
      "\n",
      "val/train: 1.20\n",
      "121/121 [==============================] - 0s 998us/step - loss: 0.9071\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 7s - loss: 4.4520  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0100s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7922 - val_loss: 0.4812\n",
      "\n",
      "val/train: 0.61\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4590 - val_loss: 0.4269\n",
      "\n",
      "val/train: 0.93\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4242 - val_loss: 0.4050\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4096 - val_loss: 0.4085\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3961 - val_loss: 0.3862\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.4091\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.3839\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.3686\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3629 - val_loss: 0.3798\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3594 - val_loss: 0.3556\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3599 - val_loss: 0.3566\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3498 - val_loss: 0.3689\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.343 - 0s 2ms/step - loss: 0.3410 - val_loss: 0.3612\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3443 - val_loss: 0.3479\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3382 - val_loss: 0.4282\n",
      "\n",
      "val/train: 1.27\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3306 - val_loss: 0.3597\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3248 - val_loss: 0.3232\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3215 - val_loss: 0.4033\n",
      "\n",
      "val/train: 1.25\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3226 - val_loss: 0.3328\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3189 - val_loss: 0.3769\n",
      "\n",
      "val/train: 1.18\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3157 - val_loss: 0.3435\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3191 - val_loss: 0.3195\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3152 - val_loss: 0.3199\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3056 - val_loss: 0.4036\n",
      "\n",
      "val/train: 1.32\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3073 - val_loss: 0.3702\n",
      "\n",
      "val/train: 1.20\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3047 - val_loss: 0.3087\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3017 - val_loss: 0.3401\n",
      "\n",
      "val/train: 1.13\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2989 - val_loss: 0.3245\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2957 - val_loss: 0.3200\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2932 - val_loss: 0.3295\n",
      "\n",
      "val/train: 1.12\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2929 - val_loss: 0.3811\n",
      "\n",
      "val/train: 1.30\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2923 - val_loss: 0.3138\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2925 - val_loss: 0.3101\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2877 - val_loss: 0.3042\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2848 - val_loss: 0.3463\n",
      "\n",
      "val/train: 1.22\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2841 - val_loss: 0.3317\n",
      "\n",
      "val/train: 1.17\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2836 - val_loss: 0.3072\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2829 - val_loss: 0.3084\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2782 - val_loss: 0.3437\n",
      "\n",
      "val/train: 1.24\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2785 - val_loss: 0.3036\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2808 - val_loss: 0.3225\n",
      "\n",
      "val/train: 1.15\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2781 - val_loss: 0.3030\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2761 - val_loss: 0.3195\n",
      "\n",
      "val/train: 1.16\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2770 - val_loss: 0.3179\n",
      "\n",
      "val/train: 1.15\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2740 - val_loss: 0.2985\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2717 - val_loss: 0.3282\n",
      "\n",
      "val/train: 1.21\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2725 - val_loss: 0.2982\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2688 - val_loss: 0.3244\n",
      "\n",
      "val/train: 1.21\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2711 - val_loss: 0.3009\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2687 - val_loss: 0.3288\n",
      "\n",
      "val/train: 1.22\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2675 - val_loss: 0.3270\n",
      "\n",
      "val/train: 1.22\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2678 - val_loss: 0.3068\n",
      "\n",
      "val/train: 1.15\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2646 - val_loss: 0.3145\n",
      "\n",
      "val/train: 1.19\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2631 - val_loss: 0.2990\n",
      "\n",
      "val/train: 1.14\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2635 - val_loss: 0.3225\n",
      "\n",
      "val/train: 1.22\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2645 - val_loss: 0.2943\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2602 - val_loss: 0.2976\n",
      "\n",
      "val/train: 1.14\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2612 - val_loss: 0.3028\n",
      "\n",
      "val/train: 1.16\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2615 - val_loss: 0.3181\n",
      "\n",
      "val/train: 1.22\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2582 - val_loss: 0.3124\n",
      "\n",
      "val/train: 1.21\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2590 - val_loss: 0.2981\n",
      "\n",
      "val/train: 1.15\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2591 - val_loss: 0.3004\n",
      "\n",
      "val/train: 1.16\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2560 - val_loss: 0.3236\n",
      "\n",
      "val/train: 1.26\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2564 - val_loss: 0.3073\n",
      "\n",
      "val/train: 1.20\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2517 - val_loss: 0.3371\n",
      "\n",
      "val/train: 1.34\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2514 - val_loss: 0.3292\n",
      "\n",
      "val/train: 1.31\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.2855\n",
      "Epoch 1/100\n",
      "  3/242 [..............................] - ETA: 8s - loss: 4.7078  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0112s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8306 - val_loss: 0.5739\n",
      "\n",
      "val/train: 0.69\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5648 - val_loss: 0.4389\n",
      "\n",
      "val/train: 0.78\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4267 - val_loss: 0.4253\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4049 - val_loss: 0.4116\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3931 - val_loss: 0.4038\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3818 - val_loss: 0.4056\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3722 - val_loss: 0.3798\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3659 - val_loss: 0.3697\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3568 - val_loss: 0.3636\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3517 - val_loss: 0.3645\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3470 - val_loss: 0.3485\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3377 - val_loss: 0.3694\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3387 - val_loss: 0.3475\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 0.3404\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3266 - val_loss: 0.3580\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3188 - val_loss: 0.4231\n",
      "\n",
      "val/train: 1.33\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3163 - val_loss: 0.3367\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3130 - val_loss: 0.4486\n",
      "\n",
      "val/train: 1.43\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3135 - val_loss: 0.3262\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3098 - val_loss: 0.3209\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3069 - val_loss: 0.3238\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3131 - val_loss: 0.3176\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3015 - val_loss: 0.3195\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3008 - val_loss: 0.3174\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2954 - val_loss: 0.3533\n",
      "\n",
      "val/train: 1.20\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2939 - val_loss: 0.3260\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2903 - val_loss: 0.3610\n",
      "\n",
      "val/train: 1.24\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2899 - val_loss: 0.3323\n",
      "\n",
      "val/train: 1.15\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2848 - val_loss: 0.3153\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2857 - val_loss: 0.3064\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2889 - val_loss: 0.3339\n",
      "\n",
      "val/train: 1.16\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2862 - val_loss: 0.3149\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 0.3074\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2810 - val_loss: 0.3177\n",
      "\n",
      "val/train: 1.13\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 0.3292\n",
      "\n",
      "val/train: 1.18\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2792 - val_loss: 0.3043\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2742 - val_loss: 0.3015\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2761 - val_loss: 0.2964\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2725 - val_loss: 0.3074\n",
      "\n",
      "val/train: 1.13\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2745 - val_loss: 0.3123\n",
      "\n",
      "val/train: 1.14\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2735 - val_loss: 0.3642\n",
      "\n",
      "val/train: 1.33\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2716 - val_loss: 0.3258\n",
      "\n",
      "val/train: 1.20\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2694 - val_loss: 0.3326\n",
      "\n",
      "val/train: 1.23\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2642 - val_loss: 0.2945\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2703 - val_loss: 0.3329\n",
      "\n",
      "val/train: 1.23\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2681 - val_loss: 0.2952\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2677 - val_loss: 0.2952\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2658 - val_loss: 0.3262\n",
      "\n",
      "val/train: 1.23\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2624 - val_loss: 0.2873\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2604 - val_loss: 0.3024\n",
      "\n",
      "val/train: 1.16\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2597 - val_loss: 0.3359\n",
      "\n",
      "val/train: 1.29\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2590 - val_loss: 0.2942\n",
      "\n",
      "val/train: 1.14\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2618 - val_loss: 0.2959\n",
      "\n",
      "val/train: 1.13\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2594 - val_loss: 0.3046\n",
      "\n",
      "val/train: 1.17\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2565 - val_loss: 0.2988\n",
      "\n",
      "val/train: 1.16\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2586 - val_loss: 0.3041\n",
      "\n",
      "val/train: 1.18\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2582 - val_loss: 0.2876\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2560 - val_loss: 0.4053\n",
      "\n",
      "val/train: 1.58\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2747 - val_loss: 0.3083\n",
      "\n",
      "val/train: 1.12\n",
      "121/121 [==============================] - 0s 952us/step - loss: 0.2974\n",
      "Epoch 1/100\n",
      "  3/363 [..............................] - ETA: 9s - loss: 7.6229  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0088s). Check your callbacks.\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0838 - val_loss: 0.6629\n",
      "\n",
      "val/train: 0.61\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6675 - val_loss: 0.5455\n",
      "\n",
      "val/train: 0.82\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5223 - val_loss: 0.4966\n",
      "\n",
      "val/train: 0.95\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4848 - val_loss: 0.4742\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4637 - val_loss: 0.4578\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4494 - val_loss: 0.4501\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4389 - val_loss: 0.4380\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4295 - val_loss: 0.4309\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4219 - val_loss: 0.4240\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4281 - val_loss: 0.4228\n",
      "\n",
      "val/train: 0.99\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4094 - val_loss: 0.4134\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4037 - val_loss: 0.4076\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3981 - val_loss: 0.4036\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4094 - val_loss: 0.4026\n",
      "\n",
      "val/train: 0.98\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3895 - val_loss: 0.3964\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.3927\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3890\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3797 - val_loss: 0.3846\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3828\n",
      "\n",
      "val/train: 1.00\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3731 - val_loss: 0.3803\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.3766\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3679 - val_loss: 0.3756\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3630 - val_loss: 0.3718\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3604 - val_loss: 0.3746\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3576 - val_loss: 0.3677\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3561 - val_loss: 0.3628\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3524 - val_loss: 0.3601\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.3582\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3514 - val_loss: 0.3557\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.3539\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.3521\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3415 - val_loss: 0.3522\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3412 - val_loss: 0.3479\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3388 - val_loss: 0.3538\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3545\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3337 - val_loss: 0.3509\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3368 - val_loss: 0.3435\n",
      "\n",
      "val/train: 1.02\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3297 - val_loss: 0.3405\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 0.3410\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3273 - val_loss: 0.3377\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 0.3370\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 0.3362\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 0.3378\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3217 - val_loss: 0.3324\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3229 - val_loss: 0.3347\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3190 - val_loss: 0.3337\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3169 - val_loss: 0.3292\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3163 - val_loss: 0.3312\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3157 - val_loss: 0.3259\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3125 - val_loss: 0.3275\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3123 - val_loss: 0.3265\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3106 - val_loss: 0.3224\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3093 - val_loss: 0.3302\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3088 - val_loss: 0.3240\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3097 - val_loss: 0.3225\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3056 - val_loss: 0.3206\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3046 - val_loss: 0.3195\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3081 - val_loss: 0.3242\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3034 - val_loss: 0.3201\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3022 - val_loss: 0.3240\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3020 - val_loss: 0.3142\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3015 - val_loss: 0.3138\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2993 - val_loss: 0.3154\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3008 - val_loss: 0.3123\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2998 - val_loss: 0.3147\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2977 - val_loss: 0.3163\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2962 - val_loss: 0.3118\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2959 - val_loss: 0.3161\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2942 - val_loss: 0.3148\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2937 - val_loss: 0.3069\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2959 - val_loss: 0.3154\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2919 - val_loss: 0.3128\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2956 - val_loss: 0.3051\n",
      "\n",
      "val/train: 1.03\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.3189\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2892 - val_loss: 0.3063\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2894 - val_loss: 0.3073\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2886 - val_loss: 0.3071\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2882 - val_loss: 0.3010\n",
      "\n",
      "val/train: 1.04\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3254 - val_loss: 0.3034\n",
      "\n",
      "val/train: 0.93\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2870 - val_loss: 0.3018\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2868 - val_loss: 0.3082\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2851 - val_loss: 0.2993\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2847 - val_loss: 0.3035\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2827 - val_loss: 0.3083\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.284 - 0s 1ms/step - loss: 0.2827 - val_loss: 0.3001\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2833 - val_loss: 0.2992\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2833 - val_loss: 0.2996\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2809 - val_loss: 0.2995\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 0.2977\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 0.2974\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2789 - val_loss: 0.2981\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2795 - val_loss: 0.2970\n",
      "\n",
      "val/train: 1.06\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 0.2949\n",
      "\n",
      "val/train: 1.05\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 0.2971\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2782 - val_loss: 0.3044\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2778 - val_loss: 0.2964\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2760 - val_loss: 0.2953\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2762 - val_loss: 0.3045\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2750 - val_loss: 0.2956\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2776 - val_loss: 0.2935\n",
      "\n",
      "val/train: 1.06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000001F9F7AA3848>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001F9FE740B08>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal  # 逆分布（対数一様分布）\n",
    "from sklearn.model_selection import RandomizedSearchCV  # ランダムサーチ\n",
    "\n",
    "param_distribs = {\n",
    "    'n_hidden' : [0, 1, 2, 3],\n",
    "    'n_neurons' : np.arange(1, 100),\n",
    "    'learning_rate' : reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(estimator=keras_reg  # パラメータ探索を行うモデル\n",
    "                                    , param_distributions=param_distribs  # パラメータ探索を試すパラメータの分布またはリストの辞書\n",
    "                                    , n_iter=10  # 試行回数\n",
    "                                    , cv=3  # 交差検証の分割数\n",
    "                                    )\n",
    "rnd_search_cv.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_valid), callbacks=[early_stopping_cb,print_valid_train_ration_cb,tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fitメソッドに渡した引数はその下のkerasモデルにリレーされている。<br>\n",
    "また、RandomizedSearchCVは交差検証を使用するため学習精度を評価するためにx_valid, y_validは使わない。これらは早期打ち切りのために使用される。\n",
    "\n",
    "次のように最良のパラメータ、スコア、モデルを取得できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "{'learning_rate': 0.0036801093876061867, 'n_hidden': 2, 'n_neurons': 92}\n",
      "-0.3339237868785858\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.2912\n",
      "0.2911567687988281\n"
     ]
    }
   ],
   "source": [
    "# 最良モデルのインデックス\n",
    "print(rnd_search_cv.best_index_)\n",
    "\n",
    "# 最良モデルのパラメータ\n",
    "print(rnd_search_cv.best_params_)\n",
    "\n",
    "# 最良モデルのスコア\n",
    "print(rnd_search_cv.best_score_)\n",
    "\n",
    "# 最良モデル\n",
    "model = rnd_search_cv.best_estimator_.model\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 補足"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scipy.statsは確率分布、統計量、仮説検定などの統計に関するモジュールを収録している. <br>\n",
    "reciprocal は逆分布（対数一様分布）<br>\n",
    "確率密度関数は\n",
    "$$ f(x;a,b)={\\frac {1}{x[\\log _{e}(b)-\\log _{e}(a)]}}\\quad {\\text{ for }}a\\leq x\\leq b{\\text{ and }}a>0. $$\n",
    "パラメータの説明をすると、$a$は下限, $b$は上限を与える.（←本当かな？）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal  # 逆分布（対数一様分布）\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = np.linspace(start=0, stop=11, num=10000) \n",
    "dist = reciprocal(1, 10)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(x, dist.pdf(x), 'k-', lw=2, label='frozen pdf')\n",
    "ax.legend(loc='best', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86c3969cb8e4d6528009ba441e3b227910147fcb8261d5b261fbcbb462fd60ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
