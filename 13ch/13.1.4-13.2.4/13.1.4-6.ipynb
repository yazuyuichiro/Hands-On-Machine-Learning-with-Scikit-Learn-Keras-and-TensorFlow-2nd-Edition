{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.1 データAPI\n",
    "\n",
    "## このNotebookの対応するセクションとその概要\n",
    "\n",
    "- 13.1.4: 1つにまとめる\n",
    "    - これまで学んだDATA APIを1つにまとめてコードの再利用性を高める\n",
    "        - `csv_reader_dataset()` 関数を作成\n",
    "- 13.1.5: プリフェッチ\n",
    "    - trainingの時間を短縮化するためのテクニック\n",
    "- 13.1.6: tf.kerasのもとでのデータセットの使い方\n",
    "    - データAPIを利用した `csv_reader_dataset()`関数をtf.kerasで適用してみる\n",
    "    - データAPIを利用することで、これまでよりコードをより簡潔にかくことができるようになる\n",
    "        - つまりこれまでのコードの書き方と少し異なるのでそれについて学ぶ。\n",
    "\n",
    "### Note\n",
    "\n",
    "- 13.1では、`CSV`形式を取り扱っていることを必ず忘れないようにしよう。\n",
    "- 13.2でもっと効率的なデータ形式 `TRRecord` 形式を学ぶ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 事前準備 (前回の復習)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "if IS_COLAB or IS_KAGGLE:\n",
    "    %pip install -q -U tfx\n",
    "    print(\"You can safely ignore the package incompatibility errors.\")\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"data\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the California dataset to multiple CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、California housing datasetのロードと準備から始めましょう。まずロードして、トレーニングセット、検証セット、テストセットに分割し、最後にスケーリングします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# データセットの読み込み\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# 学習用とテスト用に分ける\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "                                                housing.data, \n",
    "                                                housing.target.reshape(-1, 1), \n",
    "                                                random_state=42)\n",
    "\n",
    "# 先程つくた学習用データセットをさらに学習用と検証用に分ける\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "                                        X_train_full, \n",
    "                                        y_train_full, \n",
    "                                        random_state=42)\n",
    "\n",
    "# データの標準化\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_mean = scaler.mean_   # 平均\n",
    "X_std = scaler.scale_   # 標準偏差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メモリに収まらないような非常に大きなデータセットの場合、通常はまず多くのファイルに分割し、TensorFlowにこれらのファイルを並行して読み込ませることになるでしょう。このことを示すために、まず住宅データセットを分割し、20個のCSVファイルに保存してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ファイル分割して保存する関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
    "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
    "    # ディレクトリ作成\n",
    "    os.makedirs(housing_dir, exist_ok=True)\n",
    "    # PATH & ファイル名\n",
    "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
    "\n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        # \"my_{}_{:02d}.csv\" に値が渡される\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        # path information\n",
    "        filepaths.append(part_csv)\n",
    "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "            if header is not None:\n",
    "                f.write(header)\n",
    "                f.write(\"\\n\")\n",
    "            # 大きく分割した中に存在するIDのループ\n",
    "            for row_idx in row_indices:\n",
    "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                f.write(\"\\n\")\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成した関数の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.c_[X_train, y_train]\n",
    "valid_data = np.c_[X_valid, y_valid]\n",
    "test_data = np.c_[X_test, y_test]\n",
    "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
    "header = \",\".join(header_cols)\n",
    "\n",
    "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header, n_parts=20)\n",
    "valid_filepaths = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
    "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、そのCSVファイルの最初の数行を覗いてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5214</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.049945</td>\n",
       "      <td>1.106548</td>\n",
       "      <td>1447.0</td>\n",
       "      <td>1.605993</td>\n",
       "      <td>37.63</td>\n",
       "      <td>-122.43</td>\n",
       "      <td>1.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.3275</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.490060</td>\n",
       "      <td>0.991054</td>\n",
       "      <td>3464.0</td>\n",
       "      <td>3.443340</td>\n",
       "      <td>33.69</td>\n",
       "      <td>-117.39</td>\n",
       "      <td>1.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.1000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.542373</td>\n",
       "      <td>1.591525</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>2.250847</td>\n",
       "      <td>38.44</td>\n",
       "      <td>-122.98</td>\n",
       "      <td>1.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.1736</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.289003</td>\n",
       "      <td>0.997442</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>2.695652</td>\n",
       "      <td>33.55</td>\n",
       "      <td>-117.70</td>\n",
       "      <td>2.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0549</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.312457</td>\n",
       "      <td>1.085092</td>\n",
       "      <td>3297.0</td>\n",
       "      <td>2.244384</td>\n",
       "      <td>33.93</td>\n",
       "      <td>-116.93</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  3.5214      15.0  3.049945   1.106548      1447.0  1.605993     37.63   \n",
       "1  5.3275       5.0  6.490060   0.991054      3464.0  3.443340     33.69   \n",
       "2  3.1000      29.0  7.542373   1.591525      1328.0  2.250847     38.44   \n",
       "3  7.1736      12.0  6.289003   0.997442      1054.0  2.695652     33.55   \n",
       "4  2.0549      13.0  5.312457   1.085092      3297.0  2.244384     33.93   \n",
       "\n",
       "   Longitude  MedianHouseValue  \n",
       "0    -122.43             1.442  \n",
       "1    -117.39             1.687  \n",
       "2    -122.98             1.621  \n",
       "3    -117.70             2.621  \n",
       "4    -116.93             0.956  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv(train_filepaths[0]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `list_files()`メソッドを使うことでfile pathがシャフルされる\n",
    "- `seed` を指定しない場合はコールするたびにシャフルされる内容が変わる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "tf.Tensor(b'datasets/housing/my_train_05.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_16.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_01.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_17.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_00.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_14.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_10.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_02.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_12.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_19.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_07.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_09.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_13.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_15.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_11.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_18.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_04.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_06.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_03.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_08.csv', shape=(), dtype=string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 16:41:50.210534: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-02 16:41:50.210650: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)\n",
    "for filename in filepath_dataset:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue\n",
      "4.7361,7.0,7.464968152866242,1.1178343949044587,846.0,2.694267515923567,34.49,-117.27,1.745\n",
      "8.944,30.0,7.170454545454546,1.0875,1776.0,2.018181818181818,34.1,-118.39,5.00001\n",
      "3.0568,41.0,5.95320197044335,1.0714285714285714,973.0,2.396551724137931,35.38,-118.96,0.856\n",
      "3.2569,15.0,5.444444444444445,1.08994708994709,891.0,2.357142857142857,36.84,-119.77,1.244\n"
     ]
    }
   ],
   "source": [
    "! cat datasets/housing/my_train_15.csv | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "複数ファイルのインターリーブ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_readers = 5  # 同時5個からファイル読み出し\n",
    "dataset = filepath_dataset.interleave(\n",
    "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "    cycle_length=n_readers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前処理関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 8 # X_train.shape[-1]\n",
    "\n",
    "@tf.function\n",
    "def preprocess(line):\n",
    "    # csvの各行のデフォルト値を定義する\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    # ここでparseする\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    return (x - X_mean) / X_std, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1.4 ひとつにまとめる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ひとつにまとめた関数を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "    # ファイルパスのリストをシャフルして出力\n",
    "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
    "    # この例だとファイル数は5で中のデータをインターリーブする\n",
    "    # <Input>\n",
    "    # - File1: a1, a2, a3 ...\n",
    "    # - File2: b1, b2, b3 ...\n",
    "    # - File3: c1, c2, c3 ...\n",
    "    # - File4: d1, d2, d3 ...\n",
    "    # - File5: e1, e2, e3 ...\n",
    "    # <output>\n",
    "    # - a1, b1, c1, d1, e1, a2, b2, c2, d2, e2, a3, b3, c3, d3, e3,.... \n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    # shuffle_buffer_size で再度シャフル\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    # 要素１つずつに前処理を施す\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    # batch化する\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 関数の動作確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変数の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets/housing/my_train_00.csv',\n",
       " 'datasets/housing/my_train_01.csv',\n",
       " 'datasets/housing/my_train_02.csv',\n",
       " 'datasets/housing/my_train_03.csv',\n",
       " 'datasets/housing/my_train_04.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filepaths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "関数の動作テスト.確認テストのため`batch_size=3`と少なめにした"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "train_set = csv_reader_dataset(train_filepaths, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 0 -----------\n",
      "X = tf.Tensor(\n",
      "[[ 0.5804519  -0.20762321  0.05616303 -0.15191229  0.01343246  0.00604472\n",
      "   1.2525111  -1.3671792 ]\n",
      " [ 5.818099    1.8491895   1.1784915   0.28173092 -1.2496178  -0.3571987\n",
      "   0.7231292  -1.0023477 ]\n",
      " [-0.9253566   0.5834586  -0.7807257  -0.28213993 -0.36530012  0.27389365\n",
      "  -0.76194876  0.72684526]], shape=(3, 8), dtype=float32)\n",
      "y = tf.Tensor(\n",
      "[[1.752]\n",
      " [1.313]\n",
      " [1.535]], shape=(3, 1), dtype=float32)\n",
      "\n",
      "--------- 1 -----------\n",
      "X = tf.Tensor(\n",
      "[[-0.8324941   0.6625668  -0.20741376 -0.18699841 -0.14536144  0.09635526\n",
      "   0.9807942  -0.67250353]\n",
      " [-0.62183803  0.5834586  -0.19862501 -0.3500319  -1.1437552  -0.3363751\n",
      "   1.107282   -0.8674123 ]\n",
      " [ 0.8683102   0.02970133  0.3427381  -0.29872298  0.7124906   0.28026953\n",
      "  -0.72915536  0.86178064]], shape=(3, 8), dtype=float32)\n",
      "y = tf.Tensor(\n",
      "[[0.919]\n",
      " [1.028]\n",
      " [2.182]], shape=(3, 1), dtype=float32)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 17:26:46.685021: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# 2データ分を試しに出力\n",
    "for i, (X_batch, y_batch) in enumerate(train_set.take(2)):\n",
    "    print(f\"--------- {i} -----------\")\n",
    "    print(\"X =\", X_batch)\n",
    "    print(\"y =\", y_batch)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1.5 プリフェッチ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プリフェッチのコード\n",
    "\n",
    "- 上記のコードを抜き出すと以下の`dataset.prefetch(1)`がプリフェッチのコードである。\n",
    "- `n_parse_threads` も重要\n",
    "\n",
    "```python\n",
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "\n",
    "    ~~~~ (省略) ~~~~\n",
    "    \n",
    "    return dataset.prefetch(1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![prefetch](./13.1.5_prefetch.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1.6 tf.kerasのもとでのデータセットの使い方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- california_housing のデータを使って実際に学習、推論を行ってみる\n",
    "- 先程作成した　`csv_reader_dataset()` が、学習だけでなく検証, テスト用でも使えることを示す\n",
    "- 従来と引数の指定方法が若干異なることを理解する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習用だけでなく、検証, テスト用データにも前処理を行う\n",
    "\n",
    "- 先程作った関数を利用して前処理を実行する\n",
    "- 学習用だけでなく検証用とテスト用のデータもこの関数で作成可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat=Noneで永遠に繰り返す。\n",
    "# repeat=Noneもしくはrepeat=10以上(今回のエポック数)にしないとうまく学習できないことに注意\n",
    "train_set = csv_reader_dataset(train_filepaths, repeat=None)\n",
    "valid_set = csv_reader_dataset(valid_filepaths)\n",
    "test_set = csv_reader_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32, 8), dtype=float32, numpy=\n",
      "array([[ 1.18324661e+00, -2.86731392e-01,  2.56954998e-01,\n",
      "        -9.14653018e-02,  6.74161077e-01,  5.36658242e-02,\n",
      "        -7.43209183e-01,  7.11849034e-01],\n",
      "       [-4.45226371e-01,  1.84918952e+00, -3.20666254e-01,\n",
      "        -1.40449286e-01, -1.06119268e-01, -6.69142455e-02,\n",
      "        -6.91677988e-01,  7.31840193e-01],\n",
      "       [ 3.09196889e-01,  5.04350424e-01,  2.08594278e-01,\n",
      "        -2.77027190e-01,  6.08453274e-01,  2.73698270e-01,\n",
      "        -8.46275151e-01,  7.81819880e-01],\n",
      "       [-1.28795540e+00,  1.45364857e+00, -5.05224824e-01,\n",
      "         2.03960374e-01, -4.95803148e-01,  4.35151726e-01,\n",
      "        -7.66634524e-01,  6.56878173e-01],\n",
      "       [-6.46088064e-01, -1.07781315e+00, -3.59055459e-01,\n",
      "         9.48920622e-02,  1.03099108e+00, -2.29778379e-01,\n",
      "        -7.24471331e-01,  9.76728678e-01],\n",
      "       [ 1.76200092e+00, -6.82272315e-01,  7.48218775e-01,\n",
      "        -2.33296052e-01, -6.32694423e-01, -3.28950375e-01,\n",
      "        -1.32412410e+00,  1.17163742e+00],\n",
      "       [-8.82408321e-01, -6.03164136e-01,  1.27520874e-01,\n",
      "        -8.90796334e-02, -4.89414871e-01, -2.11330920e-01,\n",
      "         2.01613259e+00, -1.32220197e+00],\n",
      "       [-2.11472481e-01, -4.44947749e-01, -2.81041592e-01,\n",
      "        -7.66088367e-02,  1.64973962e+00,  9.41126049e-02,\n",
      "        -7.99427927e-01,  7.81819880e-01],\n",
      "       [ 7.31399357e-01, -2.86731392e-01,  2.08306715e-01,\n",
      "        -1.28486872e-01,  1.04376757e+00,  2.93916881e-01,\n",
      "         8.87098014e-01, -1.23224378e+00],\n",
      "       [-9.08962905e-01,  2.97013279e-02, -3.84408563e-01,\n",
      "         5.40421605e-02,  3.62961560e-01,  4.81269434e-02,\n",
      "        -7.15101540e-01,  1.17163742e+00],\n",
      "       [ 9.88669991e-01,  5.04350424e-01,  1.47498306e-02,\n",
      "        -2.81318069e-01,  1.73138961e-01,  5.72082074e-03,\n",
      "        -7.10415781e-01,  6.81864262e-01],\n",
      "       [-7.34393954e-01, -2.07623214e-01, -3.63375694e-01,\n",
      "        -8.05393681e-02, -6.79237485e-01, -7.10713029e-01,\n",
      "         1.04169524e+00, -1.24723625e+00],\n",
      "       [ 3.27503729e+00, -2.07623214e-01,  6.85181141e-01,\n",
      "        -2.23821998e-01,  1.01821446e+00, -3.07035856e-02,\n",
      "        -8.79068553e-01,  6.06898427e-01],\n",
      "       [ 1.53954521e-01,  4.25242215e-01, -6.55603707e-02,\n",
      "        -1.34625837e-01,  4.68824148e-01,  1.91881478e-01,\n",
      "        -6.68252587e-01,  5.81912398e-01],\n",
      "       [-3.83894116e-01,  1.08809508e-01, -5.43491721e-01,\n",
      "        -2.14056507e-01, -6.14014454e-02,  1.80052847e-01,\n",
      "        -6.35459185e-01,  5.71914911e-01],\n",
      "       [-8.74447227e-01, -6.82272315e-01, -1.05253473e-01,\n",
      "        -1.88480273e-01, -3.12853642e-02,  4.98876870e-01,\n",
      "         3.29606682e-01,  8.71404409e-02],\n",
      "       [-7.42474571e-02, -5.24055958e-01, -5.07303655e-01,\n",
      "        -1.65777594e-01, -1.59963176e-01, -4.04022664e-01,\n",
      "         7.69978225e-01, -1.17726910e+00],\n",
      "       [ 3.58849287e-01,  5.04350424e-01,  1.70763180e-01,\n",
      "        -8.68478864e-02, -3.98154020e-01,  1.23289488e-01,\n",
      "         9.76108432e-01, -1.41715515e+00],\n",
      "       [ 4.24319208e-01, -1.15692139e+00,  3.96204680e-01,\n",
      "        -2.82479785e-02,  1.36135530e+00, -2.99455851e-01,\n",
      "        -1.16952515e+00,  1.23660576e+00],\n",
      "       [ 1.11421525e+00, -1.63157046e+00,  3.49512666e-01,\n",
      "        -1.11953646e-01,  1.28520098e+01,  4.73563746e-02,\n",
      "        -7.57264733e-01,  9.01762903e-01],\n",
      "       [-9.77732539e-01,  1.13721585e+00, -4.51955080e-01,\n",
      "        -1.43616855e-01, -5.51472247e-01,  1.70150116e-01,\n",
      "        -7.38525152e-01,  7.31840193e-01],\n",
      "       [-6.94640577e-01, -9.98705029e-01, -1.96070284e-01,\n",
      "        -1.87727824e-01, -2.72214025e-01, -8.42992365e-02,\n",
      "         9.90162194e-01, -6.42518759e-01],\n",
      "       [ 3.18572164e-01,  5.83458602e-01,  3.43575895e-01,\n",
      "        -9.57274958e-02, -5.31879701e-02, -2.57369697e-01,\n",
      "         9.43315029e-01, -7.12485790e-01],\n",
      "       [-5.63700676e-01, -1.28515035e-01, -4.69962627e-01,\n",
      "        -1.54817089e-01,  5.36357164e-01,  3.13233227e-01,\n",
      "        -7.76002586e-01,  7.31840193e-01],\n",
      "       [-3.70800078e-01,  2.67025858e-01,  9.16407779e-02,\n",
      "         6.74595460e-02, -2.74039239e-01,  3.88330251e-01,\n",
      "        -7.29155362e-01,  1.05169070e+00],\n",
      "       [-2.41902903e-01, -4.94068526e-02, -1.66961759e-01,\n",
      "        -3.02063674e-01,  5.54609358e-01, -2.16260672e-01,\n",
      "         1.39305460e+00, -8.82404685e-01],\n",
      "       [ 2.53102243e-01,  5.83458602e-01, -2.55851120e-01,\n",
      "        -3.70137751e-01, -6.54597044e-01,  2.64679715e-02,\n",
      "        -8.04111958e-01,  7.41837621e-01],\n",
      "       [ 3.45283955e-01, -1.31513774e+00,  3.90285879e-01,\n",
      "        -1.37683287e-01,  4.17718053e-01, -2.11980641e-02,\n",
      "         1.32746780e+00, -1.57708037e+00],\n",
      "       [ 1.31853390e+00, -1.15692139e+00,  4.20707822e-01,\n",
      "        -2.45102882e-01, -2.71301419e-01,  1.26349360e-01,\n",
      "         1.17287052e+00, -1.51711082e+00],\n",
      "       [ 5.23152709e-01,  5.83458602e-01,  3.49397093e-01,\n",
      "        -1.06145307e-01, -6.76499665e-01,  6.76955208e-02,\n",
      "        -8.41591120e-01,  6.11897171e-01],\n",
      "       [-2.55258679e-01, -8.40488672e-01,  2.80466467e-01,\n",
      "         8.02463815e-02, -4.37396199e-01,  1.17488399e-01,\n",
      "         4.84205663e-01,  8.71404409e-02],\n",
      "       [-3.89707774e-01,  1.84918952e+00,  5.20540588e-02,\n",
      "        -2.85251409e-01, -4.07280117e-01, -4.45685834e-01,\n",
      "        -7.24471331e-01,  9.31747675e-01]], dtype=float32)>, <tf.Tensor: shape=(32, 1), dtype=float32, numpy=\n",
      "array([[3.151  ],\n",
      "       [2.226  ],\n",
      "       [2.141  ],\n",
      "       [1.141  ],\n",
      "       [1.228  ],\n",
      "       [3.923  ],\n",
      "       [0.864  ],\n",
      "       [1.918  ],\n",
      "       [2.231  ],\n",
      "       [0.723  ],\n",
      "       [2.724  ],\n",
      "       [0.734  ],\n",
      "       [5.00001],\n",
      "       [1.986  ],\n",
      "       [1.601  ],\n",
      "       [0.529  ],\n",
      "       [2.125  ],\n",
      "       [2.545  ],\n",
      "       [1.911  ],\n",
      "       [2.539  ],\n",
      "       [2.156  ],\n",
      "       [1.164  ],\n",
      "       [1.514  ],\n",
      "       [1.768  ],\n",
      "       [0.986  ],\n",
      "       [1.64   ],\n",
      "       [1.745  ],\n",
      "       [1.783  ],\n",
      "       [3.349  ],\n",
      "       [3.344  ],\n",
      "       [1.153  ],\n",
      "       [2.912  ]], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(32, 8), dtype=float32, numpy=\n",
      "array([[-0.39965922,  1.6909732 , -0.38753408, -0.14806423, -0.49397793,\n",
      "         0.02320052, -0.7104158 ,  0.6968566 ],\n",
      "       [-0.21686716,  1.4536486 , -0.22849748, -0.07112679,  0.1028681 ,\n",
      "         0.10017852, -0.68699217,  0.7318402 ],\n",
      "       [ 0.645241  ,  1.8491895 ,  0.128179  , -0.27741444, -0.3862901 ,\n",
      "        -0.11655063, -0.82753557,  0.82679707],\n",
      "       [ 1.9263043 , -1.9480032 ,  1.0077876 ,  0.12339026, -0.80243963,\n",
      "        -0.0446618 , -0.3637422 , -0.43261376],\n",
      "       [-0.8723521 , -1.9480032 , -0.5661001 ,  0.02117113, -0.35982445,\n",
      "        -0.19174539, -0.9352855 ,  0.8717781 ],\n",
      "       [ 1.0126582 , -1.7106786 , -0.12214744, -0.07160956,  0.9753219 ,\n",
      "        -0.29413363, -0.9259175 ,  0.8018072 ],\n",
      "       [-0.39997354, -0.7613805 , -0.01095384, -0.16249451,  0.36387417,\n",
      "         0.29098797, -0.13418664,  0.3220315 ],\n",
      "       [ 0.19046068,  1.6909732 ,  0.3565931 , -0.247109  , -0.68653834,\n",
      "        -0.15848827, -0.76194876,  0.63188833],\n",
      "       [-1.6179761 , -0.44494775, -0.03399715,  0.10985789, -0.33792186,\n",
      "         0.12035774,  1.0135876 , -1.3521868 ],\n",
      "       [-1.0205761 ,  0.82078314,  0.04300878, -0.11334971, -0.5323075 ,\n",
      "        -0.14006282, -0.70573175,  1.1416489 ],\n",
      "       [-1.235527  ,  0.5834586 , -1.1312624 ,  0.13113786,  1.4653927 ,\n",
      "         0.18871489, -0.72447133,  0.6368871 ],\n",
      "       [-0.36975253,  0.42524222,  0.34905273,  0.4965719 , -0.97583526,\n",
      "        -0.09659495,  1.4071101 , -0.8973971 ],\n",
      "       [-0.7741472 , -0.60316414, -0.02739217,  0.071492  , -0.07052753,\n",
      "         0.55213106,  0.5076293 , -0.12276073],\n",
      "       [ 0.05234518, -0.91959685, -0.4163298 , -0.19726102,  1.1532806 ,\n",
      "        -0.51144934, -0.94465536,  0.81680346],\n",
      "       [-1.6073438 ,  0.10880951, -0.6634764 , -0.05211595, -0.8097405 ,\n",
      "        -0.11026349,  0.2640199 ,  0.12212779],\n",
      "       [-0.26248664,  1.5327568 ,  0.10838237, -0.41625994, -0.5487344 ,\n",
      "        -0.22795069, -0.76194876,  0.63188833],\n",
      "       [-0.24153627,  1.6118649 , -0.22316031, -0.12487724, -0.60166574,\n",
      "        -0.03052205, -0.75726473,  0.62189466],\n",
      "       [-0.03302755,  0.5043504 , -0.23478593, -0.01420415,  0.22880809,\n",
      "        -0.07473364, -0.86969876,  0.63188833],\n",
      "       [ 2.363591  , -1.7106786 ,  0.85449886, -0.11943591,  9.836751  ,\n",
      "         0.14328495,  0.8824122 , -1.1672716 ],\n",
      "       [ 0.2772476 ,  0.5043504 , -0.05880151, -0.15526913,  0.04446115,\n",
      "         0.2986865 , -0.9352855 ,  0.82679707],\n",
      "       [ 0.5287568 ,  1.2954322 ,  0.07029681, -0.32890868, -0.5432588 ,\n",
      "        -0.14904343,  0.8964678 , -1.3621805 ],\n",
      "       [-0.64048386, -1.3151377 , -0.9906055 , -0.06704336,  5.479958  ,\n",
      "        -0.3290766 , -0.81348175,  0.62189466],\n",
      "       [-1.0179049 , -0.998705  , -0.4859051 , -0.24854141, -0.33792186,\n",
      "        -0.5365729 ,  0.54979247, -0.06778607],\n",
      "       [ 0.4411842 , -1.9480032 , -0.07104149,  0.06660695,  3.0460308 ,\n",
      "        -0.20760317, -0.93060154,  0.9567376 ],\n",
      "       [ 0.62140983, -0.04940685,  0.11451133, -0.2140565 , -0.12528405,\n",
      "        -0.15419309, -0.7994279 ,  0.81680346],\n",
      "       [ 0.27237654,  0.1879177 , -0.3330575 , -0.199481  ,  0.4213685 ,\n",
      "        -0.16932614, -0.80411196,  0.7868148 ],\n",
      "       [-0.6609628 , -1.1569214 ,  1.5562632 ,  1.9773234 ,  0.261662  ,\n",
      "        -0.5284479 , -0.86969876,  1.5514575 ],\n",
      "       [-0.6912886 ,  0.5043504 , -0.12633327,  0.06020879,  0.04628637,\n",
      "         0.64556134,  0.39987928,  0.16210623],\n",
      "       [ 2.2584202 , -1.7106786 ,  0.21660301, -0.193111  ,  0.2507107 ,\n",
      "        -0.2509427 , -0.8181658 ,  0.5969048 ],\n",
      "       [ 1.1431266 , -2.0271113 ,  0.43965957, -0.03938879, -0.6518592 ,\n",
      "        -0.03078184, -0.9821345 ,  0.9467401 ],\n",
      "       [-0.829142  ,  1.8491895 , -0.55567265, -0.07249442,  0.01251985,\n",
      "        -0.0728578 ,  0.9807942 , -1.4171551 ],\n",
      "       [-1.21531   ,  0.74167496, -0.5974942 ,  0.34293905, -0.6801501 ,\n",
      "         0.52193683, -0.7994279 ,  0.65187943]], dtype=float32)>, <tf.Tensor: shape=(32, 1), dtype=float32, numpy=\n",
      "array([[1.98   ],\n",
      "       [2.306  ],\n",
      "       [2.4    ],\n",
      "       [3.287  ],\n",
      "       [2.25   ],\n",
      "       [2.647  ],\n",
      "       [0.762  ],\n",
      "       [1.943  ],\n",
      "       [1.125  ],\n",
      "       [0.89   ],\n",
      "       [2.5    ],\n",
      "       [1.095  ],\n",
      "       [0.621  ],\n",
      "       [2.716  ],\n",
      "       [0.684  ],\n",
      "       [1.897  ],\n",
      "       [1.302  ],\n",
      "       [2.799  ],\n",
      "       [4.511  ],\n",
      "       [2.152  ],\n",
      "       [3.301  ],\n",
      "       [1.923  ],\n",
      "       [1.125  ],\n",
      "       [2.374  ],\n",
      "       [2.641  ],\n",
      "       [1.744  ],\n",
      "       [1.452  ],\n",
      "       [0.743  ],\n",
      "       [5.00001],\n",
      "       [2.743  ],\n",
      "       [2.586  ],\n",
      "       [0.897  ]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "icount = 0\n",
    "for tmp in train_set.take(2):\n",
    "    print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 次にSequential API を使ってNeuralNetモデルを作成する\n",
    "\n",
    "このステップは従来どおりである"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://docs.google.com/drawings/d/e/2PACX-1vSiIQ399T-rsCxEeqT4aD1vTE7YFMjmQRXDfz-4T3PmWcFAl_RYkyeyKzwozmJAFWfMrH949cPjMCN-/pub?w=583&h=402)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                270       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習の開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 従来方法 (10.2.3 参照)\n",
    "\n",
    "- 従来方法は、引数に `X_train, y_train`, `validation_data=(X_varid, y_valid)` と値を渡している\n",
    "- 今回はデータとラベルが１つにまとまっている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "従来の前処理は以下\n",
    "\n",
    "```python\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "```\n",
    "\n",
    "モデル作成方法は今回と同様で、学習開始の`fit()`メソッドおける引数の渡し方が従来方法と異なる\n",
    "\n",
    "```python\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(X_valid, y_valid))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 本章で作成したデータセットを使った学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 17/362 [>.............................] - ETA: 1s - loss: 4.9388  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 17:38:27.081323: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/362 [============================>.] - ETA: 0s - loss: 2.3133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 17:38:28.210116: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362/362 [==============================] - 2s 4ms/step - loss: 2.3069 - val_loss: 0.9083\n",
      "Epoch 2/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.7222 - val_loss: 0.6887\n",
      "Epoch 3/10\n",
      "362/362 [==============================] - 1s 4ms/step - loss: 0.6173 - val_loss: 0.6139\n",
      "Epoch 4/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.5631 - val_loss: 0.5646\n",
      "Epoch 5/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.5647 - val_loss: 0.5061\n",
      "Epoch 6/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.4986 - val_loss: 0.5157\n",
      "Epoch 7/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.5014 - val_loss: 0.4664\n",
      "Epoch 8/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.4725 - val_loss: 0.4468\n",
      "Epoch 9/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.4710 - val_loss: 0.4398\n",
      "Epoch 10/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.4618 - val_loss: 0.4285\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "res = model.fit(train_set,                                           # 学習データ\n",
    "                steps_per_epoch=(len(X_train) // batch_size),    # エポックあたり、なんステップあるか？\n",
    "                epochs=num_epochs,                               # エポック数\n",
    "                validation_data=valid_set)                       # 検証用データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(range(1, num_epochs+1), res.history['loss'], label=\"training\")\n",
    "plt.plot(range(1, num_epochs+1), res.history['val_loss'], label=\"validation\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### この前処理したデータは`evaluate()`, `predict()` でも使うことができる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学習モデルの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 2ms/step - loss: 0.4432\n"
     ]
    }
   ],
   "source": [
    "# \"//\" であまりは無視\n",
    "res = model.evaluate(test_set, steps=len(X_test) // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 推論時はラベル情報はいらない。もしラベル情報を削除したいなら以下のように処理する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/161 [======================>.......] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 17:38:57.703305: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.9054303],\n",
       "       [2.515842 ],\n",
       "       [1.1908185],\n",
       "       ...,\n",
       "       [3.3227916],\n",
       "       [1.3247879],\n",
       "       [3.2831535]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_set = test_set.map(lambda X, y: X) \n",
    "X_new = X_test\n",
    "model.predict(new_set, steps=len(X_new) // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kerasはラベルを無視することができる。めんどくさければそのままでもOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/161 [======================>.......] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 17:39:01.140545: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.5967462 ],\n",
       "       [3.1248822 ],\n",
       "       [3.4969707 ],\n",
       "       ...,\n",
       "       [2.9878387 ],\n",
       "       [1.5033703 ],\n",
       "       [0.99150753]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_set, steps=len(X_new) // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 独自ループを作りたい場合、ごく自然に訓練セットを反復処理できる (12.3.9 参照)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12.3.9 のコード 抜粋\n",
    "\n",
    "```python\n",
    "# エポックのループ\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    # バッチのループ\n",
    "    for step in range(1, n_steps + 1):\n",
    "        # 適当にバッチサイズを取得, デフォルトは32に設定\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 順伝搬\n",
    "            y_pred = model(X_batch)\n",
    "            # lossの計算, reduce_meanでバッチ毎の平均ロスを計算\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            # メインのロスの他に、レイヤ毎の正則化ロスを加えている\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        # 逆伝搬の計算\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        # オプティマイザー従って重みなど値を更新する\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.1.6のコード\n",
    "\n",
    "- ループ処理の工程が簡単にかけるようになっていることに注目する\n",
    "- ちゃんと学習工程を動かすには、12.3.9のコードを参照して付け加えること"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step 1810/1810"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps_per_epoch = len(X_train) // batch_size\n",
    "total_steps = n_epochs * n_steps_per_epoch\n",
    "global_step = 0\n",
    "for X_batch, y_batch in train_set.take(total_steps):                          # ここが異なる\n",
    "    global_step += 1                                                          # ここが異なる\n",
    "    print(\"\\rGlobal step {}/{}\".format(global_step, total_steps), end=\"\")\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X_batch)\n",
    "        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "        loss = tf.add_n([main_loss] + model.losses)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練ループ全体を実行するTF関数にも対応可能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python関数からTF関数に変換することで、計算グラフが最適化され、高速に計算することができる\n",
    "- 以下のコードは、前処理も含めて`@tf.function`のデコレータを用い、tf関数化されている。データAPIはtf関数化をサポートしていることを知っていればOK\n",
    "- 以下、なぜ２つのTF関数が紹介されているかはよくわからない。２つ目のコードのほうを見ればよいと思う。そちらはちゃんと学習の動作をする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 17:40:53.018745: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-02 17:40:53.056207: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-02 17:40:53.091515: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# こっちではなく、次のコードを参照したほうが参考になる\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "@tf.function\n",
    "def train(model, n_epochs, batch_size=32,\n",
    "          n_readers=5, n_read_threads=5, shuffle_buffer_size=10000, n_parse_threads=5):\n",
    "    train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs, n_readers=n_readers,\n",
    "                       n_read_threads=n_read_threads, shuffle_buffer_size=shuffle_buffer_size,\n",
    "                       n_parse_threads=n_parse_threads, batch_size=batch_size)\n",
    "    for X_batch, y_batch in train_set:\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "train(model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 17:41:03.966944: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-02 17:41:04.007108: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-02 17:41:04.044925: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step 100 / 1810\n",
      "Global step 200 / 1810\n",
      "Global step 300 / 1810\n",
      "Global step 400 / 1810\n",
      "Global step 500 / 1810\n",
      "Global step 600 / 1810\n",
      "Global step 700 / 1810\n",
      "Global step 800 / 1810\n",
      "Global step 900 / 1810\n",
      "Global step 1000 / 1810\n",
      "Global step 1100 / 1810\n",
      "Global step 1200 / 1810\n",
      "Global step 1300 / 1810\n",
      "Global step 1400 / 1810\n",
      "Global step 1500 / 1810\n",
      "Global step 1600 / 1810\n",
      "Global step 1700 / 1810\n",
      "Global step 1800 / 1810\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "@tf.function\n",
    "def train(model, n_epochs, batch_size=32,\n",
    "          n_readers=5, n_read_threads=5, shuffle_buffer_size=10000, n_parse_threads=5):\n",
    "    train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs, n_readers=n_readers,\n",
    "                       n_read_threads=n_read_threads, shuffle_buffer_size=shuffle_buffer_size,\n",
    "                       n_parse_threads=n_parse_threads, batch_size=batch_size)\n",
    "    n_steps_per_epoch = len(X_train) // batch_size                      # 追加\n",
    "    total_steps = n_epochs * n_steps_per_epoch                          # 追加\n",
    "    global_step = 0                                                     # 追加\n",
    "    for X_batch, y_batch in train_set.take(total_steps):                # 変更\n",
    "        global_step += 1                                                # 追加\n",
    "        if tf.equal(global_step % 100, 0):                              # 追加\n",
    "            tf.print(\"\\rGlobal step\", global_step, \"/\", total_steps)    # 追加\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "train(model, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以下 `Dataset` クラスの各メソッドの簡単な説明\n",
    "\n",
    "- 以下のコードは便利かも。いろいろ使えそう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "● apply()              Applies a transformation function to this dataset.\n",
      "● as_numpy_iterator()  Returns an iterator which converts all elements of the dataset to numpy.\n",
      "● batch()              Combines consecutive elements of this dataset into batches.\n",
      "● bucket_by_sequence_length()A transformation that buckets elements in a `Dataset` by length.\n",
      "● cache()              Caches the elements in this dataset.\n",
      "● cardinality()        Returns the cardinality of the dataset, if known.\n",
      "● choose_from_datasets()Creates a dataset that deterministically chooses elements from `datasets`.\n",
      "● concatenate()        Creates a `Dataset` by concatenating the given dataset with this dataset.\n",
      "● element_spec()       The type specification of an element of this dataset.\n",
      "● enumerate()          Enumerates the elements of this dataset.\n",
      "● filter()             Filters this dataset according to `predicate`.\n",
      "● flat_map()           Maps `map_func` across this dataset and flattens the result.\n",
      "● from_generator()     Creates a `Dataset` whose elements are generated by `generator`. (deprecated arguments)\n",
      "● from_tensor_slices() Creates a `Dataset` whose elements are slices of the given tensors.\n",
      "● from_tensors()       Creates a `Dataset` with a single element, comprising the given tensors.\n",
      "● get_single_element() Returns the single element of the `dataset`.\n",
      "● group_by_window()    Groups windows of elements by key and reduces them.\n",
      "● interleave()         Maps `map_func` across this dataset, and interleaves the results.\n",
      "● list_files()         A dataset of all files matching one or more glob patterns.\n",
      "● load()               Loads a previously saved dataset.\n",
      "● map()                Maps `map_func` across the elements of this dataset.\n",
      "● options()            Returns the options for this dataset and its inputs.\n",
      "● padded_batch()       Combines consecutive elements of this dataset into padded batches.\n",
      "● prefetch()           Creates a `Dataset` that prefetches elements from this dataset.\n",
      "● random()             Creates a `Dataset` of pseudorandom values.\n",
      "● range()              Creates a `Dataset` of a step-separated range of values.\n",
      "● reduce()             Reduces the input dataset to a single element.\n",
      "● rejection_resample() A transformation that resamples a dataset to a target distribution.\n",
      "● repeat()             Repeats this dataset so each original value is seen `count` times.\n",
      "● sample_from_datasets()Samples elements at random from the datasets in `datasets`.\n",
      "● save()               Saves the content of the given dataset.\n",
      "● scan()               A transformation that scans a function across an input dataset.\n",
      "● shard()              Creates a `Dataset` that includes only 1/`num_shards` of this dataset.\n",
      "● shuffle()            Randomly shuffles the elements of this dataset.\n",
      "● skip()               Creates a `Dataset` that skips `count` elements from this dataset.\n",
      "● snapshot()           API to persist the output of the input dataset.\n",
      "● take()               Creates a `Dataset` with at most `count` elements from this dataset.\n",
      "● take_while()         A transformation that stops dataset iteration based on a `predicate`.\n",
      "● unbatch()            Splits elements of a dataset into multiple elements.\n",
      "● unique()             A transformation that discards duplicate elements of a `Dataset`.\n",
      "● window()             Returns a dataset of \"windows\".\n",
      "● with_options()       Returns a new `tf.data.Dataset` with the given options set.\n",
      "● zip()                Creates a `Dataset` by zipping together the given datasets.\n"
     ]
    }
   ],
   "source": [
    "for m in dir(tf.data.Dataset):\n",
    "    if not (m.startswith(\"_\") or m.endswith(\"_\")):\n",
    "        func = getattr(tf.data.Dataset, m)\n",
    "        if hasattr(func, \"__doc__\"):         # __doc__というメソッドがTrueならば\n",
    "            print(\"● {:21s}{}\".format(m + \"()\", func.__doc__.split(\"\\n\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 補足"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演算子 `//` の挙動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362.8125\n",
      "362\n",
      "362\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "print(len(X_train) / batch_size)\n",
    "print(len(X_train) // batch_size)\n",
    "print(int(len(X_train) / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `getattr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "1\n",
      "None\n",
      "I got Hello World\n"
     ]
    }
   ],
   "source": [
    "class hello():\n",
    "    def __init__(self):\n",
    "        self.x = 1\n",
    "        self.y = 2\n",
    "    def plus(self):\n",
    "        return self.x + self.y\n",
    "    def minus(self):\n",
    "        return self.y - self.x\n",
    "    def args(self, s):\n",
    "        return \"I got {}\".format(s)\n",
    "\n",
    "test = hello() \n",
    "print(getattr(test, \"x\"))\n",
    "print(getattr(test, \"plus\")())\n",
    "print(getattr(test, \"minus\")())\n",
    "print(getattr(test, \"multi\", \"None\"))\n",
    "print(getattr(test, \"args\")(\"Hello World\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `hasattr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "class AttrTest():\n",
    " \n",
    "    def __init__(self):\n",
    "        self.code = -1\n",
    " \n",
    " \n",
    "test = AttrTest()\n",
    "test.name = 'python-izm'\n",
    " \n",
    "print(hasattr(test, 'code'))\n",
    "print(hasattr(test, 'name'))\n",
    "print(hasattr(test, 'kana'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考\n",
    "\n",
    "- https://qiita.com/typecprint/items/3d10e77e76e74db6e9e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## メモ\n",
    "\n",
    "- `repeat()`メソッドの使い所がよくわからない\n",
    "- TF関数の使い所。Pythonコードは高速化のためにとりあえず変換しちゃえば良い？\n",
    "    - ルールはあるので注意"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('kinocode')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c222fa9c04e7ed09ba82d4b2c90d6d09380978bc4549bc0b0460fb9c58f648a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
