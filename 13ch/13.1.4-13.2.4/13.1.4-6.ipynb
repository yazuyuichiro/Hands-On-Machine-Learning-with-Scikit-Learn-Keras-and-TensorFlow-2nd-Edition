{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.1 データAPI\n",
    "\n",
    "## このNotebookの対応するセクションとそのOverview\n",
    "\n",
    "- 13.1.4: 1つにまとめる\n",
    "    - 1つにまとめてコードの再利用性を高める\n",
    "        - `csv_reader_dataset()` 関数を作成\n",
    "- 13.1.5: プリフェッチ\n",
    "    - 学習時間を短縮化するためのテクニック\n",
    "- 13.1.6: tf.kerasのもとでのデータセットの使い方\n",
    "    - データAPIを利用した `csv_reader_dataset()`関数をtf.kerasで適用してみる\n",
    "    - データAPIを利用することで、これまでよりコードをより簡潔にかくことができるようになる\n",
    "        - つまりこれまでのコードの書き方と少し異なるのでそれについて学ぶ。\n",
    "\n",
    "### Note\n",
    "\n",
    "- 13.1では、`CSV`形式を取り扱っていることを必ず忘れないようにしよう。\n",
    "- 13.2でもっと効率的なデータ形式 `TRRecord` 形式を学ぶ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 事前準備 (前回の復習)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "if IS_COLAB or IS_KAGGLE:\n",
    "    %pip install -q -U tfx\n",
    "    print(\"You can safely ignore the package incompatibility errors.\")\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"data\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the California dataset to multiple CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、California housing datasetのロードと準備から始めましょう。まずロードして、トレーニングセット、検証セット、テストセットに分割し、最後にスケーリングします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# データセットの読み込み\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# 学習用とテスト用に分ける\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "                                                housing.data, \n",
    "                                                housing.target.reshape(-1, 1), \n",
    "                                                random_state=42)\n",
    "\n",
    "# 先程つくた学習用データセットをさらに学習用と検証用に分ける\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "                                        X_train_full, \n",
    "                                        y_train_full, \n",
    "                                        random_state=42)\n",
    "\n",
    "# データの標準化\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_mean = scaler.mean_   # 平均\n",
    "X_std = scaler.scale_   # 標準偏差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メモリに収まらないような非常に大きなデータセットの場合、通常はまず多くのファイルに分割し、TensorFlowにこれらのファイルを並行して読み込ませることになるでしょう。このことを示すために、まず住宅データセットを分割し、20個のCSVファイルに保存してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ファイル分割して保存する関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
    "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
    "    # ディレクトリ作成\n",
    "    os.makedirs(housing_dir, exist_ok=True)\n",
    "    # PATH & ファイル名\n",
    "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
    "\n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        # \"my_{}_{:02d}.csv\" に値が渡される\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        # path information\n",
    "        filepaths.append(part_csv)\n",
    "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "            if header is not None:\n",
    "                f.write(header)\n",
    "                f.write(\"\\n\")\n",
    "            # 大きく分割した中に存在するIDのループ\n",
    "            for row_idx in row_indices:\n",
    "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                f.write(\"\\n\")\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成した関数の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.c_[X_train, y_train]\n",
    "valid_data = np.c_[X_valid, y_valid]\n",
    "test_data = np.c_[X_test, y_test]\n",
    "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
    "header = \",\".join(header_cols)\n",
    "\n",
    "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header, n_parts=20)\n",
    "valid_filepaths = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
    "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、そのCSVファイルの最初の数行を覗いてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5214</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.049945</td>\n",
       "      <td>1.106548</td>\n",
       "      <td>1447.0</td>\n",
       "      <td>1.605993</td>\n",
       "      <td>37.63</td>\n",
       "      <td>-122.43</td>\n",
       "      <td>1.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.3275</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.490060</td>\n",
       "      <td>0.991054</td>\n",
       "      <td>3464.0</td>\n",
       "      <td>3.443340</td>\n",
       "      <td>33.69</td>\n",
       "      <td>-117.39</td>\n",
       "      <td>1.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.1000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.542373</td>\n",
       "      <td>1.591525</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>2.250847</td>\n",
       "      <td>38.44</td>\n",
       "      <td>-122.98</td>\n",
       "      <td>1.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.1736</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.289003</td>\n",
       "      <td>0.997442</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>2.695652</td>\n",
       "      <td>33.55</td>\n",
       "      <td>-117.70</td>\n",
       "      <td>2.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0549</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.312457</td>\n",
       "      <td>1.085092</td>\n",
       "      <td>3297.0</td>\n",
       "      <td>2.244384</td>\n",
       "      <td>33.93</td>\n",
       "      <td>-116.93</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  3.5214      15.0  3.049945   1.106548      1447.0  1.605993     37.63   \n",
       "1  5.3275       5.0  6.490060   0.991054      3464.0  3.443340     33.69   \n",
       "2  3.1000      29.0  7.542373   1.591525      1328.0  2.250847     38.44   \n",
       "3  7.1736      12.0  6.289003   0.997442      1054.0  2.695652     33.55   \n",
       "4  2.0549      13.0  5.312457   1.085092      3297.0  2.244384     33.93   \n",
       "\n",
       "   Longitude  MedianHouseValue  \n",
       "0    -122.43             1.442  \n",
       "1    -117.39             1.687  \n",
       "2    -122.98             1.621  \n",
       "3    -117.70             2.621  \n",
       "4    -116.93             0.956  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv(train_filepaths[0]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `list_files()`メソッドを使うことでfile pathがシャフルされる\n",
    "- `seed` を指定しない場合はコールするたびにシャフルされる内容が変わる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "tf.Tensor(b'datasets/housing/my_train_05.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_16.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_01.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_17.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_00.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_14.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_10.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_02.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_12.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_19.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_07.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_09.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_13.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_15.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_11.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_18.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_04.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_06.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_03.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_08.csv', shape=(), dtype=string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 13:21:29.578639: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-02 13:21:29.578892: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)\n",
    "for filename in filepath_dataset:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue\n",
      "4.7361,7.0,7.464968152866242,1.1178343949044587,846.0,2.694267515923567,34.49,-117.27,1.745\n",
      "8.944,30.0,7.170454545454546,1.0875,1776.0,2.018181818181818,34.1,-118.39,5.00001\n",
      "3.0568,41.0,5.95320197044335,1.0714285714285714,973.0,2.396551724137931,35.38,-118.96,0.856\n",
      "3.2569,15.0,5.444444444444445,1.08994708994709,891.0,2.357142857142857,36.84,-119.77,1.244\n"
     ]
    }
   ],
   "source": [
    "! cat datasets/housing/my_train_15.csv | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "複数ファイルのインターリーブ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_readers = 5  # 同時5個からファイル読み出し\n",
    "dataset = filepath_dataset.interleave(\n",
    "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "    cycle_length=n_readers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前処理関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 8 # X_train.shape[-1]\n",
    "\n",
    "@tf.function\n",
    "def preprocess(line):\n",
    "    # csvの各行のデフォルト値を定義する\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    # ここでparseする\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    return (x - X_mean) / X_std, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1.4 ひとつにまとめる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ひとつにまとめた関数を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "    # ファイルパスのリストをシャフルして出力\n",
    "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
    "    # この例だとファイル数は5で中のデータをインターリーブする\n",
    "    # <Input>\n",
    "    # - File1: a1, a2, a3 ...\n",
    "    # - File2: b1, b2, b3 ...\n",
    "    # - File3: c1, c2, c3 ...\n",
    "    # - File4: d1, d2, d3 ...\n",
    "    # - File5: e1, e2, e3 ...\n",
    "    # <output>\n",
    "    # - a1, b1, c1, d1, e1, a2, b2, c2, d2, e2, a3, b3, c3, d3, e3,.... \n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    # shuffle_buffer_size で再度シャフル\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    # 要素１つずつに前処理を施す\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    # batch化する\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 関数の動作確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変数の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets/housing/my_train_00.csv',\n",
       " 'datasets/housing/my_train_01.csv',\n",
       " 'datasets/housing/my_train_02.csv',\n",
       " 'datasets/housing/my_train_03.csv',\n",
       " 'datasets/housing/my_train_04.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filepaths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "関数の動作テスト.確認テストのため`batch_size=3`と少なめにした"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "train_set = csv_reader_dataset(train_filepaths, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 0 -----------\n",
      "X = tf.Tensor(\n",
      "[[ 0.5804519  -0.20762321  0.05616303 -0.15191229  0.01343246  0.00604472\n",
      "   1.2525111  -1.3671792 ]\n",
      " [ 5.818099    1.8491895   1.1784915   0.28173092 -1.2496178  -0.3571987\n",
      "   0.7231292  -1.0023477 ]\n",
      " [-0.9253566   0.5834586  -0.7807257  -0.28213993 -0.36530012  0.27389365\n",
      "  -0.76194876  0.72684526]], shape=(3, 8), dtype=float32)\n",
      "y = tf.Tensor(\n",
      "[[1.752]\n",
      " [1.313]\n",
      " [1.535]], shape=(3, 1), dtype=float32)\n",
      "\n",
      "--------- 1 -----------\n",
      "X = tf.Tensor(\n",
      "[[-0.8324941   0.6625668  -0.20741376 -0.18699841 -0.14536144  0.09635526\n",
      "   0.9807942  -0.67250353]\n",
      " [-0.62183803  0.5834586  -0.19862501 -0.3500319  -1.1437552  -0.3363751\n",
      "   1.107282   -0.8674123 ]\n",
      " [ 0.8683102   0.02970133  0.3427381  -0.29872298  0.7124906   0.28026953\n",
      "  -0.72915536  0.86178064]], shape=(3, 8), dtype=float32)\n",
      "y = tf.Tensor(\n",
      "[[0.919]\n",
      " [1.028]\n",
      " [2.182]], shape=(3, 1), dtype=float32)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 13:21:30.155170: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# 2データ分を試しに出力\n",
    "for i, (X_batch, y_batch) in enumerate(train_set.take(2)):\n",
    "    print(f\"--------- {i} -----------\")\n",
    "    print(\"X =\", X_batch)\n",
    "    print(\"y =\", y_batch)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1.5 プリフェッチ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プリフェッチのコード\n",
    "\n",
    "- 上記のコードを抜き出すと以下の`dataset.prefetch(1)`がプリフェッチのコードである。\n",
    "- `n_parse_threads` も重要\n",
    "\n",
    "```python\n",
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "\n",
    "    ~~~~ (省略) ~~~~\n",
    "    \n",
    "    return dataset.prefetch(1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![prefetch](./13.1.5_prefetch.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1.6 tf.kerasのもとでのデータセットの使い方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- california_housing のデータを使って実際に学習、推論を行ってみる\n",
    "- 先程作成した　`csv_reader_dataset()` が、学習だけでなく検証, テスト用でも使えることを示す\n",
    "- 従来と値の渡し方が若干異なることを理解する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習用だけでなく、検証, テスト用データにも前処理を行う\n",
    "\n",
    "- 先程作った関数を利用して前処理を実行する\n",
    "- 学習用だけでなく検証用とテスト用のデータもこの関数で作成可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat=Noneで永遠に繰り返す。\n",
    "# repeat=Noneもしくはrepeat=10以上(今回のエポック数)にしないとうまく学習できないことに注意\n",
    "train_set = csv_reader_dataset(train_filepaths, repeat=None)\n",
    "valid_set = csv_reader_dataset(valid_filepaths)\n",
    "test_set = csv_reader_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32, 8), dtype=float32, numpy=\n",
      "array([[ 1.18324661e+00, -2.86731392e-01,  2.56954998e-01,\n",
      "        -9.14653018e-02,  6.74161077e-01,  5.36658242e-02,\n",
      "        -7.43209183e-01,  7.11849034e-01],\n",
      "       [-4.45226371e-01,  1.84918952e+00, -3.20666254e-01,\n",
      "        -1.40449286e-01, -1.06119268e-01, -6.69142455e-02,\n",
      "        -6.91677988e-01,  7.31840193e-01],\n",
      "       [ 3.09196889e-01,  5.04350424e-01,  2.08594278e-01,\n",
      "        -2.77027190e-01,  6.08453274e-01,  2.73698270e-01,\n",
      "        -8.46275151e-01,  7.81819880e-01],\n",
      "       [-1.28795540e+00,  1.45364857e+00, -5.05224824e-01,\n",
      "         2.03960374e-01, -4.95803148e-01,  4.35151726e-01,\n",
      "        -7.66634524e-01,  6.56878173e-01],\n",
      "       [-6.46088064e-01, -1.07781315e+00, -3.59055459e-01,\n",
      "         9.48920622e-02,  1.03099108e+00, -2.29778379e-01,\n",
      "        -7.24471331e-01,  9.76728678e-01],\n",
      "       [ 1.76200092e+00, -6.82272315e-01,  7.48218775e-01,\n",
      "        -2.33296052e-01, -6.32694423e-01, -3.28950375e-01,\n",
      "        -1.32412410e+00,  1.17163742e+00],\n",
      "       [-8.82408321e-01, -6.03164136e-01,  1.27520874e-01,\n",
      "        -8.90796334e-02, -4.89414871e-01, -2.11330920e-01,\n",
      "         2.01613259e+00, -1.32220197e+00],\n",
      "       [-2.11472481e-01, -4.44947749e-01, -2.81041592e-01,\n",
      "        -7.66088367e-02,  1.64973962e+00,  9.41126049e-02,\n",
      "        -7.99427927e-01,  7.81819880e-01],\n",
      "       [ 7.31399357e-01, -2.86731392e-01,  2.08306715e-01,\n",
      "        -1.28486872e-01,  1.04376757e+00,  2.93916881e-01,\n",
      "         8.87098014e-01, -1.23224378e+00],\n",
      "       [-9.08962905e-01,  2.97013279e-02, -3.84408563e-01,\n",
      "         5.40421605e-02,  3.62961560e-01,  4.81269434e-02,\n",
      "        -7.15101540e-01,  1.17163742e+00],\n",
      "       [ 9.88669991e-01,  5.04350424e-01,  1.47498306e-02,\n",
      "        -2.81318069e-01,  1.73138961e-01,  5.72082074e-03,\n",
      "        -7.10415781e-01,  6.81864262e-01],\n",
      "       [-7.34393954e-01, -2.07623214e-01, -3.63375694e-01,\n",
      "        -8.05393681e-02, -6.79237485e-01, -7.10713029e-01,\n",
      "         1.04169524e+00, -1.24723625e+00],\n",
      "       [ 3.27503729e+00, -2.07623214e-01,  6.85181141e-01,\n",
      "        -2.23821998e-01,  1.01821446e+00, -3.07035856e-02,\n",
      "        -8.79068553e-01,  6.06898427e-01],\n",
      "       [ 1.53954521e-01,  4.25242215e-01, -6.55603707e-02,\n",
      "        -1.34625837e-01,  4.68824148e-01,  1.91881478e-01,\n",
      "        -6.68252587e-01,  5.81912398e-01],\n",
      "       [-3.83894116e-01,  1.08809508e-01, -5.43491721e-01,\n",
      "        -2.14056507e-01, -6.14014454e-02,  1.80052847e-01,\n",
      "        -6.35459185e-01,  5.71914911e-01],\n",
      "       [-8.74447227e-01, -6.82272315e-01, -1.05253473e-01,\n",
      "        -1.88480273e-01, -3.12853642e-02,  4.98876870e-01,\n",
      "         3.29606682e-01,  8.71404409e-02],\n",
      "       [-7.42474571e-02, -5.24055958e-01, -5.07303655e-01,\n",
      "        -1.65777594e-01, -1.59963176e-01, -4.04022664e-01,\n",
      "         7.69978225e-01, -1.17726910e+00],\n",
      "       [ 3.58849287e-01,  5.04350424e-01,  1.70763180e-01,\n",
      "        -8.68478864e-02, -3.98154020e-01,  1.23289488e-01,\n",
      "         9.76108432e-01, -1.41715515e+00],\n",
      "       [ 4.24319208e-01, -1.15692139e+00,  3.96204680e-01,\n",
      "        -2.82479785e-02,  1.36135530e+00, -2.99455851e-01,\n",
      "        -1.16952515e+00,  1.23660576e+00],\n",
      "       [ 1.11421525e+00, -1.63157046e+00,  3.49512666e-01,\n",
      "        -1.11953646e-01,  1.28520098e+01,  4.73563746e-02,\n",
      "        -7.57264733e-01,  9.01762903e-01],\n",
      "       [-9.77732539e-01,  1.13721585e+00, -4.51955080e-01,\n",
      "        -1.43616855e-01, -5.51472247e-01,  1.70150116e-01,\n",
      "        -7.38525152e-01,  7.31840193e-01],\n",
      "       [-6.94640577e-01, -9.98705029e-01, -1.96070284e-01,\n",
      "        -1.87727824e-01, -2.72214025e-01, -8.42992365e-02,\n",
      "         9.90162194e-01, -6.42518759e-01],\n",
      "       [ 3.18572164e-01,  5.83458602e-01,  3.43575895e-01,\n",
      "        -9.57274958e-02, -5.31879701e-02, -2.57369697e-01,\n",
      "         9.43315029e-01, -7.12485790e-01],\n",
      "       [-5.63700676e-01, -1.28515035e-01, -4.69962627e-01,\n",
      "        -1.54817089e-01,  5.36357164e-01,  3.13233227e-01,\n",
      "        -7.76002586e-01,  7.31840193e-01],\n",
      "       [-3.70800078e-01,  2.67025858e-01,  9.16407779e-02,\n",
      "         6.74595460e-02, -2.74039239e-01,  3.88330251e-01,\n",
      "        -7.29155362e-01,  1.05169070e+00],\n",
      "       [-2.41902903e-01, -4.94068526e-02, -1.66961759e-01,\n",
      "        -3.02063674e-01,  5.54609358e-01, -2.16260672e-01,\n",
      "         1.39305460e+00, -8.82404685e-01],\n",
      "       [ 2.53102243e-01,  5.83458602e-01, -2.55851120e-01,\n",
      "        -3.70137751e-01, -6.54597044e-01,  2.64679715e-02,\n",
      "        -8.04111958e-01,  7.41837621e-01],\n",
      "       [ 3.45283955e-01, -1.31513774e+00,  3.90285879e-01,\n",
      "        -1.37683287e-01,  4.17718053e-01, -2.11980641e-02,\n",
      "         1.32746780e+00, -1.57708037e+00],\n",
      "       [ 1.31853390e+00, -1.15692139e+00,  4.20707822e-01,\n",
      "        -2.45102882e-01, -2.71301419e-01,  1.26349360e-01,\n",
      "         1.17287052e+00, -1.51711082e+00],\n",
      "       [ 5.23152709e-01,  5.83458602e-01,  3.49397093e-01,\n",
      "        -1.06145307e-01, -6.76499665e-01,  6.76955208e-02,\n",
      "        -8.41591120e-01,  6.11897171e-01],\n",
      "       [-2.55258679e-01, -8.40488672e-01,  2.80466467e-01,\n",
      "         8.02463815e-02, -4.37396199e-01,  1.17488399e-01,\n",
      "         4.84205663e-01,  8.71404409e-02],\n",
      "       [-3.89707774e-01,  1.84918952e+00,  5.20540588e-02,\n",
      "        -2.85251409e-01, -4.07280117e-01, -4.45685834e-01,\n",
      "        -7.24471331e-01,  9.31747675e-01]], dtype=float32)>, <tf.Tensor: shape=(32, 1), dtype=float32, numpy=\n",
      "array([[3.151  ],\n",
      "       [2.226  ],\n",
      "       [2.141  ],\n",
      "       [1.141  ],\n",
      "       [1.228  ],\n",
      "       [3.923  ],\n",
      "       [0.864  ],\n",
      "       [1.918  ],\n",
      "       [2.231  ],\n",
      "       [0.723  ],\n",
      "       [2.724  ],\n",
      "       [0.734  ],\n",
      "       [5.00001],\n",
      "       [1.986  ],\n",
      "       [1.601  ],\n",
      "       [0.529  ],\n",
      "       [2.125  ],\n",
      "       [2.545  ],\n",
      "       [1.911  ],\n",
      "       [2.539  ],\n",
      "       [2.156  ],\n",
      "       [1.164  ],\n",
      "       [1.514  ],\n",
      "       [1.768  ],\n",
      "       [0.986  ],\n",
      "       [1.64   ],\n",
      "       [1.745  ],\n",
      "       [1.783  ],\n",
      "       [3.349  ],\n",
      "       [3.344  ],\n",
      "       [1.153  ],\n",
      "       [2.912  ]], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(32, 8), dtype=float32, numpy=\n",
      "array([[-0.39965922,  1.6909732 , -0.38753408, -0.14806423, -0.49397793,\n",
      "         0.02320052, -0.7104158 ,  0.6968566 ],\n",
      "       [-0.21686716,  1.4536486 , -0.22849748, -0.07112679,  0.1028681 ,\n",
      "         0.10017852, -0.68699217,  0.7318402 ],\n",
      "       [ 0.645241  ,  1.8491895 ,  0.128179  , -0.27741444, -0.3862901 ,\n",
      "        -0.11655063, -0.82753557,  0.82679707],\n",
      "       [ 1.9263043 , -1.9480032 ,  1.0077876 ,  0.12339026, -0.80243963,\n",
      "        -0.0446618 , -0.3637422 , -0.43261376],\n",
      "       [-0.8723521 , -1.9480032 , -0.5661001 ,  0.02117113, -0.35982445,\n",
      "        -0.19174539, -0.9352855 ,  0.8717781 ],\n",
      "       [ 1.0126582 , -1.7106786 , -0.12214744, -0.07160956,  0.9753219 ,\n",
      "        -0.29413363, -0.9259175 ,  0.8018072 ],\n",
      "       [-0.39997354, -0.7613805 , -0.01095384, -0.16249451,  0.36387417,\n",
      "         0.29098797, -0.13418664,  0.3220315 ],\n",
      "       [ 0.19046068,  1.6909732 ,  0.3565931 , -0.247109  , -0.68653834,\n",
      "        -0.15848827, -0.76194876,  0.63188833],\n",
      "       [-1.6179761 , -0.44494775, -0.03399715,  0.10985789, -0.33792186,\n",
      "         0.12035774,  1.0135876 , -1.3521868 ],\n",
      "       [-1.0205761 ,  0.82078314,  0.04300878, -0.11334971, -0.5323075 ,\n",
      "        -0.14006282, -0.70573175,  1.1416489 ],\n",
      "       [-1.235527  ,  0.5834586 , -1.1312624 ,  0.13113786,  1.4653927 ,\n",
      "         0.18871489, -0.72447133,  0.6368871 ],\n",
      "       [-0.36975253,  0.42524222,  0.34905273,  0.4965719 , -0.97583526,\n",
      "        -0.09659495,  1.4071101 , -0.8973971 ],\n",
      "       [-0.7741472 , -0.60316414, -0.02739217,  0.071492  , -0.07052753,\n",
      "         0.55213106,  0.5076293 , -0.12276073],\n",
      "       [ 0.05234518, -0.91959685, -0.4163298 , -0.19726102,  1.1532806 ,\n",
      "        -0.51144934, -0.94465536,  0.81680346],\n",
      "       [-1.6073438 ,  0.10880951, -0.6634764 , -0.05211595, -0.8097405 ,\n",
      "        -0.11026349,  0.2640199 ,  0.12212779],\n",
      "       [-0.26248664,  1.5327568 ,  0.10838237, -0.41625994, -0.5487344 ,\n",
      "        -0.22795069, -0.76194876,  0.63188833],\n",
      "       [-0.24153627,  1.6118649 , -0.22316031, -0.12487724, -0.60166574,\n",
      "        -0.03052205, -0.75726473,  0.62189466],\n",
      "       [-0.03302755,  0.5043504 , -0.23478593, -0.01420415,  0.22880809,\n",
      "        -0.07473364, -0.86969876,  0.63188833],\n",
      "       [ 2.363591  , -1.7106786 ,  0.85449886, -0.11943591,  9.836751  ,\n",
      "         0.14328495,  0.8824122 , -1.1672716 ],\n",
      "       [ 0.2772476 ,  0.5043504 , -0.05880151, -0.15526913,  0.04446115,\n",
      "         0.2986865 , -0.9352855 ,  0.82679707],\n",
      "       [ 0.5287568 ,  1.2954322 ,  0.07029681, -0.32890868, -0.5432588 ,\n",
      "        -0.14904343,  0.8964678 , -1.3621805 ],\n",
      "       [-0.64048386, -1.3151377 , -0.9906055 , -0.06704336,  5.479958  ,\n",
      "        -0.3290766 , -0.81348175,  0.62189466],\n",
      "       [-1.0179049 , -0.998705  , -0.4859051 , -0.24854141, -0.33792186,\n",
      "        -0.5365729 ,  0.54979247, -0.06778607],\n",
      "       [ 0.4411842 , -1.9480032 , -0.07104149,  0.06660695,  3.0460308 ,\n",
      "        -0.20760317, -0.93060154,  0.9567376 ],\n",
      "       [ 0.62140983, -0.04940685,  0.11451133, -0.2140565 , -0.12528405,\n",
      "        -0.15419309, -0.7994279 ,  0.81680346],\n",
      "       [ 0.27237654,  0.1879177 , -0.3330575 , -0.199481  ,  0.4213685 ,\n",
      "        -0.16932614, -0.80411196,  0.7868148 ],\n",
      "       [-0.6609628 , -1.1569214 ,  1.5562632 ,  1.9773234 ,  0.261662  ,\n",
      "        -0.5284479 , -0.86969876,  1.5514575 ],\n",
      "       [-0.6912886 ,  0.5043504 , -0.12633327,  0.06020879,  0.04628637,\n",
      "         0.64556134,  0.39987928,  0.16210623],\n",
      "       [ 2.2584202 , -1.7106786 ,  0.21660301, -0.193111  ,  0.2507107 ,\n",
      "        -0.2509427 , -0.8181658 ,  0.5969048 ],\n",
      "       [ 1.1431266 , -2.0271113 ,  0.43965957, -0.03938879, -0.6518592 ,\n",
      "        -0.03078184, -0.9821345 ,  0.9467401 ],\n",
      "       [-0.829142  ,  1.8491895 , -0.55567265, -0.07249442,  0.01251985,\n",
      "        -0.0728578 ,  0.9807942 , -1.4171551 ],\n",
      "       [-1.21531   ,  0.74167496, -0.5974942 ,  0.34293905, -0.6801501 ,\n",
      "         0.52193683, -0.7994279 ,  0.65187943]], dtype=float32)>, <tf.Tensor: shape=(32, 1), dtype=float32, numpy=\n",
      "array([[1.98   ],\n",
      "       [2.306  ],\n",
      "       [2.4    ],\n",
      "       [3.287  ],\n",
      "       [2.25   ],\n",
      "       [2.647  ],\n",
      "       [0.762  ],\n",
      "       [1.943  ],\n",
      "       [1.125  ],\n",
      "       [0.89   ],\n",
      "       [2.5    ],\n",
      "       [1.095  ],\n",
      "       [0.621  ],\n",
      "       [2.716  ],\n",
      "       [0.684  ],\n",
      "       [1.897  ],\n",
      "       [1.302  ],\n",
      "       [2.799  ],\n",
      "       [4.511  ],\n",
      "       [2.152  ],\n",
      "       [3.301  ],\n",
      "       [1.923  ],\n",
      "       [1.125  ],\n",
      "       [2.374  ],\n",
      "       [2.641  ],\n",
      "       [1.744  ],\n",
      "       [1.452  ],\n",
      "       [0.743  ],\n",
      "       [5.00001],\n",
      "       [2.743  ],\n",
      "       [2.586  ],\n",
      "       [0.897  ]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "icount = 0\n",
    "for tmp in train_set.take(2):\n",
    "    print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 次にSequential API を使ってNeuralNetモデルを作成する\n",
    "\n",
    "このステップは従来どおりである"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://docs.google.com/drawings/d/e/2PACX-1vSiIQ399T-rsCxEeqT4aD1vTE7YFMjmQRXDfz-4T3PmWcFAl_RYkyeyKzwozmJAFWfMrH949cPjMCN-/pub?w=583&h=402)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                270       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習の開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 従来方法 (10.2.3 参照)\n",
    "\n",
    "- 従来方法は、引数に `X_train, y_train`, `validation_data=(X_varid, y_valid)` と値を渡している\n",
    "- 今回はデータとラベルが１つにまとまっている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "従来の前処理は以下\n",
    "\n",
    "```python\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "```\n",
    "\n",
    "モデル作成方法は今回と同様で、学習開始の`fit()`メソッドおける引数の渡し方が従来方法と異なる\n",
    "\n",
    "```python\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(X_valid, y_valid))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 本章で作成したデータセットを使った学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 13:21:30.568727: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349/362 [===========================>..] - ETA: 0s - loss: 1.8470"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 13:21:31.937482: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362/362 [==============================] - 2s 4ms/step - loss: 1.8140 - val_loss: 0.7915\n",
      "Epoch 2/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.7298 - val_loss: 0.6896\n",
      "Epoch 3/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.6636 - val_loss: 0.6292\n",
      "Epoch 4/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.5946 - val_loss: 0.5972\n",
      "Epoch 5/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.6025 - val_loss: 0.5323\n",
      "Epoch 6/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.5323 - val_loss: 0.5470\n",
      "Epoch 7/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.5284 - val_loss: 0.4969\n",
      "Epoch 8/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.4961 - val_loss: 0.4723\n",
      "Epoch 9/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.4918 - val_loss: 0.4528\n",
      "Epoch 10/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.4831 - val_loss: 0.4556\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "res = model.fit(train_set,                                           # 学習データ\n",
    "                steps_per_epoch=(len(X_train) // batch_size),    # エポックあたり、なんステップあるか？\n",
    "                epochs=num_epochs,                               # エポック数\n",
    "                validation_data=valid_set)                       # 検証用データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(range(1, num_epochs+1), res.history['loss'], label=\"training\")\n",
    "plt.plot(range(1, num_epochs+1), res.history['val_loss'], label=\"validation\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### この前処理したデータは`evaluate()`, `predict()` でも使うことができる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学習モデルの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 2ms/step - loss: 0.4630\n"
     ]
    }
   ],
   "source": [
    "# \"//\" であまりは無視\n",
    "res = model.evaluate(test_set, steps=len(X_test) // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 推論時はラベル情報はいらない。もしラベル情報を削除したいなら以下のように処理する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/161 [======================>.......] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 13:21:43.599939: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.033296 ],\n",
       "       [2.454239 ],\n",
       "       [1.0878233],\n",
       "       ...,\n",
       "       [3.4149544],\n",
       "       [1.3142306],\n",
       "       [3.264001 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_set = test_set.map(lambda X, y: X) \n",
    "X_new = X_test\n",
    "model.predict(new_set, steps=len(X_new) // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kerasはラベルを無視することができる。めんどくさければそのままでもOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/161 [======================>.......] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 13:21:43.889126: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.5429145 ],\n",
       "       [2.9991615 ],\n",
       "       [3.181871  ],\n",
       "       ...,\n",
       "       [2.8207943 ],\n",
       "       [1.5774097 ],\n",
       "       [0.99716055]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_set, steps=len(X_new) // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 独自ループを作りたい場合、ごく自然に訓練セットを反復処理できる (12.3.9 参照)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12.3.9 のコード 抜粋\n",
    "\n",
    "```python\n",
    "# エポックのループ\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    # バッチのループ\n",
    "    for step in range(1, n_steps + 1):\n",
    "        # 適当にバッチサイズを取得, デフォルトは32に設定\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 順伝搬\n",
    "            y_pred = model(X_batch)\n",
    "            # lossの計算, reduce_meanでバッチ毎の平均ロスを計算\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            # メインのロスの他に、レイヤ毎の正則化ロスを加えている\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        # 逆伝搬の計算\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        # オプティマイザー従って重みなど値を更新する\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.1.6のコード\n",
    "\n",
    "- ループ処理の工程が簡単にかけるようになっていることに注目する\n",
    "- ちゃんと学習工程を動かすには、12.3.9のコードを参照して付け加えること"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step 1810/1810"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps_per_epoch = len(X_train) // batch_size\n",
    "total_steps = n_epochs * n_steps_per_epoch\n",
    "global_step = 0\n",
    "for X_batch, y_batch in train_set.take(total_steps):                          # ここが異なる\n",
    "    global_step += 1                                                          # ここが異なる\n",
    "    print(\"\\rGlobal step {}/{}\".format(global_step, total_steps), end=\"\")\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X_batch)\n",
    "        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "        loss = tf.add_n([main_loss] + model.losses)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練ループ全体を実行するTF関数にも対応可能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python関数からTF関数に変換することで、計算グラフが最適化され、高速に計算することができる\n",
    "- とりあえず、前処理も含めて`@tf.function`のデコレータを用いて、tf関数化した。データAPIはtf関数化をサポートしていることを知っていればOK\n",
    "- 以下、なぜ２つのTF関数が紹介されているかはよくわからない。２つ目のコードのほうを見ればよいと思う。そちらはちゃんと学習の動作をする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 13:21:59.914553: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-02 13:21:59.952410: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-02 13:21:59.988098: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# こっちではなく、次のコードを参照したほうが参考になる\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "@tf.function\n",
    "def train(model, n_epochs, batch_size=32,\n",
    "          n_readers=5, n_read_threads=5, shuffle_buffer_size=10000, n_parse_threads=5):\n",
    "    train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs, n_readers=n_readers,\n",
    "                       n_read_threads=n_read_threads, shuffle_buffer_size=shuffle_buffer_size,\n",
    "                       n_parse_threads=n_parse_threads, batch_size=batch_size)\n",
    "    for X_batch, y_batch in train_set:\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "train(model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 13:22:09.417006: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-02 13:22:09.462983: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-02 13:22:09.498938: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step 100 / 1810\n",
      "Global step 200 / 1810\n",
      "Global step 300 / 1810\n",
      "Global step 400 / 1810\n",
      "Global step 500 / 1810\n",
      "Global step 600 / 1810\n",
      "Global step 700 / 1810\n",
      "Global step 800 / 1810\n",
      "Global step 900 / 1810\n",
      "Global step 1000 / 1810\n",
      "Global step 1100 / 1810\n",
      "Global step 1200 / 1810\n",
      "Global step 1300 / 1810\n",
      "Global step 1400 / 1810\n",
      "Global step 1500 / 1810\n",
      "Global step 1600 / 1810\n",
      "Global step 1700 / 1810\n",
      "Global step 1800 / 1810\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "@tf.function\n",
    "def train(model, n_epochs, batch_size=32,\n",
    "          n_readers=5, n_read_threads=5, shuffle_buffer_size=10000, n_parse_threads=5):\n",
    "    train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs, n_readers=n_readers,\n",
    "                       n_read_threads=n_read_threads, shuffle_buffer_size=shuffle_buffer_size,\n",
    "                       n_parse_threads=n_parse_threads, batch_size=batch_size)\n",
    "    n_steps_per_epoch = len(X_train) // batch_size                      # 追加\n",
    "    total_steps = n_epochs * n_steps_per_epoch                          # 追加\n",
    "    global_step = 0                                                     # 追加\n",
    "    for X_batch, y_batch in train_set.take(total_steps):                # 変更\n",
    "        global_step += 1                                                # 追加\n",
    "        if tf.equal(global_step % 100, 0):                              # 追加\n",
    "            tf.print(\"\\rGlobal step\", global_step, \"/\", total_steps)    # 追加\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "train(model, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以下 `Dataset` クラスの各メソッドの簡単な説明\n",
    "\n",
    "- 以下のコードは便利かも。いろいろ使えそう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "● apply()              Applies a transformation function to this dataset.\n",
      "● as_numpy_iterator()  Returns an iterator which converts all elements of the dataset to numpy.\n",
      "● batch()              Combines consecutive elements of this dataset into batches.\n",
      "● bucket_by_sequence_length()A transformation that buckets elements in a `Dataset` by length.\n",
      "● cache()              Caches the elements in this dataset.\n",
      "● cardinality()        Returns the cardinality of the dataset, if known.\n",
      "● choose_from_datasets()Creates a dataset that deterministically chooses elements from `datasets`.\n",
      "● concatenate()        Creates a `Dataset` by concatenating the given dataset with this dataset.\n",
      "● element_spec()       The type specification of an element of this dataset.\n",
      "● enumerate()          Enumerates the elements of this dataset.\n",
      "● filter()             Filters this dataset according to `predicate`.\n",
      "● flat_map()           Maps `map_func` across this dataset and flattens the result.\n",
      "● from_generator()     Creates a `Dataset` whose elements are generated by `generator`. (deprecated arguments)\n",
      "● from_tensor_slices() Creates a `Dataset` whose elements are slices of the given tensors.\n",
      "● from_tensors()       Creates a `Dataset` with a single element, comprising the given tensors.\n",
      "● get_single_element() Returns the single element of the `dataset`.\n",
      "● group_by_window()    Groups windows of elements by key and reduces them.\n",
      "● interleave()         Maps `map_func` across this dataset, and interleaves the results.\n",
      "● list_files()         A dataset of all files matching one or more glob patterns.\n",
      "● load()               Loads a previously saved dataset.\n",
      "● map()                Maps `map_func` across the elements of this dataset.\n",
      "● options()            Returns the options for this dataset and its inputs.\n",
      "● padded_batch()       Combines consecutive elements of this dataset into padded batches.\n",
      "● prefetch()           Creates a `Dataset` that prefetches elements from this dataset.\n",
      "● random()             Creates a `Dataset` of pseudorandom values.\n",
      "● range()              Creates a `Dataset` of a step-separated range of values.\n",
      "● reduce()             Reduces the input dataset to a single element.\n",
      "● rejection_resample() A transformation that resamples a dataset to a target distribution.\n",
      "● repeat()             Repeats this dataset so each original value is seen `count` times.\n",
      "● sample_from_datasets()Samples elements at random from the datasets in `datasets`.\n",
      "● save()               Saves the content of the given dataset.\n",
      "● scan()               A transformation that scans a function across an input dataset.\n",
      "● shard()              Creates a `Dataset` that includes only 1/`num_shards` of this dataset.\n",
      "● shuffle()            Randomly shuffles the elements of this dataset.\n",
      "● skip()               Creates a `Dataset` that skips `count` elements from this dataset.\n",
      "● snapshot()           API to persist the output of the input dataset.\n",
      "● take()               Creates a `Dataset` with at most `count` elements from this dataset.\n",
      "● take_while()         A transformation that stops dataset iteration based on a `predicate`.\n",
      "● unbatch()            Splits elements of a dataset into multiple elements.\n",
      "● unique()             A transformation that discards duplicate elements of a `Dataset`.\n",
      "● window()             Returns a dataset of \"windows\".\n",
      "● with_options()       Returns a new `tf.data.Dataset` with the given options set.\n",
      "● zip()                Creates a `Dataset` by zipping together the given datasets.\n"
     ]
    }
   ],
   "source": [
    "for m in dir(tf.data.Dataset):\n",
    "    if not (m.startswith(\"_\") or m.endswith(\"_\")):\n",
    "        func = getattr(tf.data.Dataset, m)\n",
    "        if hasattr(func, \"__doc__\"):\n",
    "            print(\"● {:21s}{}\".format(m + \"()\", func.__doc__.split(\"\\n\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 補足"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演算子 `//` の挙動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362.8125\n",
      "362\n",
      "362\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "print(len(X_train) / batch_size)\n",
    "print(len(X_train) // batch_size)\n",
    "print(int(len(X_train) / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考\n",
    "\n",
    "- https://qiita.com/typecprint/items/3d10e77e76e74db6e9e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## メモ\n",
    "\n",
    "- `repeat()`メソッドの使い所がよくわからない\n",
    "- TF関数の使い所。Pythonコードは高速化のためにとりあえず変換しちゃえば良い？\n",
    "    - ルールはあるので注意"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('kinocode')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c222fa9c04e7ed09ba82d4b2c90d6d09380978bc4549bc0b0460fb9c58f648a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
